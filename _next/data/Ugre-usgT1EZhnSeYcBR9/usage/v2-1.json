{"pageProps":{"title":"What's New in v2.1","teaser":"New features, backwards incompatibilities and migration guide","menu":[["New Features","features"],["Backwards Incompatibilities","incompat"]],"slug":"/usage/v2-1","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    h2: \"h2\",\n    p: \"p\",\n    a: \"a\",\n    h3: \"h3\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    pre: \"pre\",\n    code: \"code\",\n    strong: \"strong\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components), {InlineCode, Infobox} = _components;\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      id: \"section-features\",\n      children: [_jsx(_components.h2, {\n        id: \"features\",\n        hidden: \"true\",\n        children: \"New Features \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.1 has focussed primarily on stability and performance, solidifying the\\ndesign changes introduced in \", _jsx(_components.a, {\n          href: \"/usage/v2\",\n          children: \"v2.0\"\n        }), \". As well as smaller models,\\nfaster runtime, and many bug fixes, v2.1 also introduces experimental support\\nfor some exciting new NLP innovations. For the full changelog, see the\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spaCy/releases/tag/v2.1.0\",\n          children: \"release notes on GitHub\"\n        }), \".\\nFor more details and a behind-the-scenes look at the new release,\\n\", _jsx(_components.a, {\n          href: \"https://explosion.ai/blog/spacy-v2-1\",\n          children: \"see our blog post\"\n        }), \".\"]\n      }), _jsx(_components.h3, {\n        id: \"pretraining\",\n        tag: \"experimental\",\n        children: \"BERT/ULMFit/Elmo-style pre-training \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"$ python -m spacy pretrain ./raw_text.jsonl\\nen_core_web_lg ./pretrained-model\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.1 introduces a new CLI command, \", _jsx(InlineCode, {\n          children: \"spacy pretrain\"\n        }), \", that can make your\\nmodels much more accurate. It’s especially useful when you have \", _jsx(_components.strong, {\n          children: \"limited\\ntraining data\"\n        }), \". The \", _jsx(InlineCode, {\n          children: \"spacy pretrain\"\n        }), \" command lets you use transfer learning to\\ninitialize your models with information from raw text, using a language model\\nobjective similar to the one used in Google’s BERT system. We’ve taken\\nparticular care to ensure that pretraining works well even with spaCy’s small\\ndefault architecture sizes, so you don’t have to compromise on efficiency to use\\nit.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/cli#pretrain\",\n            children: _jsx(InlineCode, {\n              children: \"spacy pretrain\"\n            })\n          }), \" **Usage: **\\n\", _jsx(_components.a, {\n            href: \"/usage/training#transfer-learning\",\n            children: \"Improving accuracy with transfer learning\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"matcher-api\",\n        children: \"Extended match pattern API \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"# Matches \\\"love cats\\\" or \\\"likes flowers\\\"\\npattern1 = [{\\\"LEMMA\\\": {\\\"IN\\\": [\\\"like\\\", \\\"love\\\"]}}, {\\\"POS\\\": \\\"NOUN\\\"}]\\n# Matches tokens of length >= 10\\npattern2 = [{\\\"LENGTH\\\": {\\\">=\\\": 10}}]\\n# Matches custom attribute with regex\\npattern3 = [{\\\"_\\\": {\\\"country\\\": {\\\"REGEX\\\": \\\"^([Uu](\\\\\\\\.?|nited) ?[Ss](\\\\\\\\.?|tates)\\\"}}}]\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Instead of mapping to a single value, token patterns can now also map to a\\n\", _jsx(_components.strong, {\n          children: \"dictionary of properties\"\n        }), \". For example, to specify that the value of a lemma\\nshould be part of a list of values, or to set a minimum character length. It now\\nalso supports a \", _jsx(InlineCode, {\n          children: \"REGEX\"\n        }), \" property, as well as set membership via \", _jsx(InlineCode, {\n          children: \"IN\"\n        }), \" and\\n\", _jsx(InlineCode, {\n          children: \"NOT_IN\"\n        }), \", custom extension attributes via \", _jsx(InlineCode, {\n          children: \"_\"\n        }), \" and rich comparison for numeric\\nvalues.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/matcher\",\n            children: _jsx(InlineCode, {\n              children: \"Matcher\"\n            })\n          }), \" **Usage: **\\n\", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching#adding-patterns-attributes-extended\",\n            children: \"Extended pattern syntax and attributes\"\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching#regex\",\n            children: \"Regular expressions\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"entity-ruler\",\n        children: \"Easy rule-based entity recognition \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy.pipeline import EntityRuler\\nruler = EntityRuler(nlp)\\nruler.add_patterns([{\\\"label\\\": \\\"ORG\\\", \\\"pattern\\\": \\\"Apple\\\"}])\\nnlp.add_pipe(ruler, before=\\\"ner\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(InlineCode, {\n          children: \"EntityRuler\"\n        }), \" is an exciting new component that lets you add named entities\\nbased on pattern dictionaries, and makes it easy to combine rule-based and\\nstatistical named entity recognition for even more powerful models. Entity rules\\ncan be phrase patterns for exact string matches, or token patterns for full\\nflexibility.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/entityruler\",\n            children: _jsx(InlineCode, {\n              children: \"EntityRuler\"\n            })\n          }), \" **Usage: **\\n\", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching#entityruler\",\n            children: \"Rule-based entity recognition\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"phrasematcher\",\n        children: \"Phrase matching with other attributes \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"matcher = PhraseMatcher(nlp.vocab, attr=\\\"POS\\\")\\nmatcher.add(\\\"PATTERN\\\", None, nlp(\\\"I love cats\\\"))\\ndoc = nlp(\\\"You like dogs\\\")\\nmatches = matcher(doc)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"By default, the \", _jsx(InlineCode, {\n          children: \"PhraseMatcher\"\n        }), \" will match on the verbatim token text, e.g.\\n\", _jsx(InlineCode, {\n          children: \"Token.text\"\n        }), \". By setting the \", _jsx(InlineCode, {\n          children: \"attr\"\n        }), \" argument on initialization, you can change\\n\", _jsx(_components.strong, {\n          children: \"which token attribute the matcher should use\"\n        }), \" when comparing the phrase\\npattern to the matched \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \". For example, \", _jsx(InlineCode, {\n          children: \"LOWER\"\n        }), \" for case-insensitive matches\\nor \", _jsx(InlineCode, {\n          children: \"POS\"\n        }), \" for finding sequences of the same part-of-speech tags.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/phrasematcher\",\n            children: _jsx(InlineCode, {\n              children: \"PhraseMatcher\"\n            })\n          }), \" **Usage: **\\n\", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching#phrasematcher-attrs\",\n            children: \"Matching on other token attributes\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"retokenizer\",\n        children: \"Retokenizer for merging and splitting \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"doc = nlp(\\\"I like David Bowie\\\")\\nwith doc.retokenize() as retokenizer:\\n    attrs = {\\\"LEMMA\\\": \\\"David Bowie\\\"}\\n    retokenizer.merge(doc[2:4], attrs=attrs)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The new \", _jsx(InlineCode, {\n          children: \"Doc.retokenize\"\n        }), \" context manager allows merging spans of multiple tokens\\ninto one single token, and splitting single tokens into multiple tokens.\\nModifications to the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"’s tokenization are stored, and then made all at once\\nwhen the context manager exits. This is much more efficient, and less\\nerror-prone. \", _jsx(InlineCode, {\n          children: \"Doc.merge\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"Span.merge\"\n        }), \" still work, but they’re considered\\ndeprecated.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/doc#retokenize\",\n            children: _jsx(InlineCode, {\n              children: \"Doc.retokenize\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/doc#retokenizer.merge\",\n            children: _jsx(InlineCode, {\n              children: \"Retokenizer.merge\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/doc#retokenizer.split\",\n            children: _jsx(InlineCode, {\n              children: \"Retokenizer.split\"\n            })\n          }), _jsx(\"br\", {}), \"**Usage:\\n**\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#retokenization\",\n            children: \"Merging and splitting\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"entry-points\",\n        children: \"Components and languages via entry points \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from setuptools import setup\\nsetup(\\n    name=\\\"custom_extension_package\\\",\\n    entry_points={\\n        \\\"spacy_factories\\\": [\\\"your_component = component:ComponentFactory\\\"]\\n        \\\"spacy_languages\\\": [\\\"xyz = language:XYZLanguage\\\"]\\n   }\\n)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Using entry points, model packages and extension packages can now define their\\nown \", _jsx(InlineCode, {\n          children: \"\\\"spacy_factories\\\"\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"\\\"spacy_languages\\\"\"\n        }), \", which will be added to the\\nbuilt-in factories and languages. If a package in the same environment exposes\\nspaCy entry points, all of this happens automatically and no further user action\\nis required.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/usage/saving-loading#entry-points\",\n            children: \"Using entry points\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"docs\",\n        children: \"Improved documentation \"\n      }), _jsxs(_components.p, {\n        children: [\"Although it looks pretty much the same, we’ve rebuilt the entire documentation\\nusing \", _jsx(_components.a, {\n          href: \"https://www.gatsbyjs.org/\",\n          children: \"Gatsby\"\n        }), \" and \", _jsx(_components.a, {\n          href: \"https://mdxjs.com/\",\n          children: \"MDX\"\n        }), \". It’s\\nnow an even faster progressive web app and allows us to write all content\\nentirely \", _jsx(_components.strong, {\n          children: \"in Markdown\"\n        }), \", without having to compromise on easy-to-use custom UI\\ncomponents. We’re hoping that the Markdown source will make it even easier to\\ncontribute to the documentation. For more details, check out the\\n\", _jsx(_components.a, {\n          href: \"/styleguide\",\n          children: \"styleguide\"\n        }), \" and\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy/tree/v2.x/website\",\n          children: \"source\"\n        }), \". While converting\\nthe pages to Markdown, we’ve also fixed a bunch of typos, improved the existing\\npages and added some new content:\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Usage Guide:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching\",\n            children: \"Rule-based Matching\"\n          }), _jsx(\"br\", {}), \"How to\\nuse the \", _jsx(InlineCode, {\n            children: \"Matcher\"\n          }), \", \", _jsx(InlineCode, {\n            children: \"PhraseMatcher\"\n          }), \" and the new \", _jsx(InlineCode, {\n            children: \"EntityRuler\"\n          }), \", and write\\npowerful components to combine statistical models and rules.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Usage Guide:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/usage/saving-loading\",\n            children: \"Saving and Loading\"\n          }), _jsx(\"br\", {}), \"Everything\\nyou need to know about serialization, and how to save and load pipeline\\ncomponents, package your spaCy models as Python modules and use entry points.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"**Usage Guide: **\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#retokenization\",\n            children: \"Merging and Splitting\"\n          }), _jsx(\"br\", {}), \"How to\\nretokenize a \", _jsx(InlineCode, {\n            children: \"Doc\"\n          }), \" using the new \", _jsx(InlineCode, {\n            children: \"retokenize\"\n          }), \" context manager and merge spans\\ninto single tokens and split single tokens into multiple.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Universe:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/universe/category/videos\",\n            children: \"Videos\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/universe/category/podcasts\",\n            children: \"Podcasts\"\n          })]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/entityruler\",\n            children: _jsx(InlineCode, {\n              children: \"EntityRuler\"\n            })\n          })]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/sentencizer\",\n            children: _jsx(InlineCode, {\n              children: \"Sentencizer\"\n            })\n          })]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/pipeline-functions\",\n            children: \"Pipeline functions\"\n          })]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-incompat\",\n      children: [_jsx(_components.h2, {\n        id: \"incompat\",\n        children: \"Backwards incompatibilities \"\n      }), _jsx(Infobox, {\n        title: \"Important note on models\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"If you’ve been training \", _jsx(_components.strong, {\n            children: \"your own models\"\n          }), \", you’ll need to \", _jsx(_components.strong, {\n            children: \"retrain\"\n          }), \" them\\nwith the new version. Also don’t forget to upgrade all models to the latest\\nversions. Models for v2.0.x aren’t compatible with models for v2.1.x. To check\\nif all of your models are up to date, you can run the\\n\", _jsx(_components.a, {\n            href: \"/api/cli#validate\",\n            children: _jsx(InlineCode, {\n              children: \"spacy validate\"\n            })\n          }), \" command.\"]\n        })\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"Due to difficulties linking our new\\n\", _jsx(_components.a, {\n              href: \"https://github.com/explosion/cython-blis\",\n              children: _jsx(InlineCode, {\n                children: \"blis\"\n              })\n            }), \" for faster\\nplatform-independent matrix multiplication, this release currently \", _jsx(_components.strong, {\n              children: \"doesn’t\\nwork on Python 2.7 on Windows\"\n            }), \". We expect this to be corrected in the future.\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"While the \", _jsx(_components.a, {\n              href: \"/api/matcher\",\n              children: _jsx(InlineCode, {\n                children: \"Matcher\"\n              })\n            }), \" API is fully backwards compatible, its\\nalgorithm has changed to fix a number of bugs and performance issues. This\\nmeans that the \", _jsx(InlineCode, {\n              children: \"Matcher\"\n            }), \" in v2.1.x may produce different results compared to\\nthe \", _jsx(InlineCode, {\n              children: \"Matcher\"\n            }), \" in v2.0.x.\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The deprecated \", _jsx(_components.a, {\n              href: \"/api/doc#merge\",\n              children: _jsx(InlineCode, {\n                children: \"Doc.merge\"\n              })\n            }), \" and\\n\", _jsx(_components.a, {\n              href: \"/api/span#merge\",\n              children: _jsx(InlineCode, {\n                children: \"Span.merge\"\n              })\n            }), \" methods still work, but you may notice that\\nthey now run slower when merging many objects in a row. That’s because the\\nmerging engine was rewritten to be more reliable and to support more efficient\\nmerging \", _jsx(_components.strong, {\n              children: \"in bulk\"\n            }), \". To take advantage of this, you should rewrite your logic\\nto use the \", _jsx(_components.a, {\n              href: \"/api/doc#retokenize\",\n              children: _jsx(InlineCode, {\n                children: \"Doc.retokenize\"\n              })\n            }), \" context manager and perform\\nas many merges as possible together in the \", _jsx(InlineCode, {\n              children: \"with\"\n            }), \" block.\"]\n          }), \"\\n\", _jsx(_components.pre, {\n            children: _jsx(_components.code, {\n              className: \"language-diff\",\n              lang: \"diff\",\n              children: \"- doc[1:5].merge()\\n- doc[6:8].merge()\\n+ with doc.retokenize() as retokenizer:\\n+     retokenizer.merge(doc[1:5])\\n+     retokenizer.merge(doc[6:8])\\n\"\n            })\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The serialization methods \", _jsx(InlineCode, {\n              children: \"to_disk\"\n            }), \", \", _jsx(InlineCode, {\n              children: \"from_disk\"\n            }), \", \", _jsx(InlineCode, {\n              children: \"to_bytes\"\n            }), \" and \", _jsx(InlineCode, {\n              children: \"from_bytes\"\n            }), \"\\nnow support a single \", _jsx(InlineCode, {\n              children: \"exclude\"\n            }), \" argument to provide a list of string names to\\nexclude. The docs have been updated to list the available serialization fields\\nfor each class. The \", _jsx(InlineCode, {\n              children: \"disable\"\n            }), \" argument on the \", _jsx(_components.a, {\n              href: \"/api/language\",\n              children: _jsx(InlineCode, {\n                children: \"Language\"\n              })\n            }), \"\\nserialization methods has been renamed to \", _jsx(InlineCode, {\n              children: \"exclude\"\n            }), \" for consistency.\"]\n          }), \"\\n\", _jsx(_components.pre, {\n            children: _jsx(_components.code, {\n              className: \"language-diff\",\n              lang: \"diff\",\n              children: \"- nlp.to_disk(\\\"/path\\\", disable=[\\\"parser\\\", \\\"ner\\\"])\\n+ nlp.to_disk(\\\"/path\\\", exclude=[\\\"parser\\\", \\\"ner\\\"])\\n- data = nlp.tokenizer.to_bytes(vocab=False)\\n+ data = nlp.tokenizer.to_bytes(exclude=[\\\"vocab\\\"])\\n\"\n            })\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The .pos value for several common English words has changed, due to\\ncorrections to long-standing mistakes in the English tag map (see\\n\", _jsx(_components.a, {\n              href: \"https://github.com/explosion/spaCy/issues/593\",\n              children: \"issue #593\"\n            }), \" and\\n\", _jsx(_components.a, {\n              href: \"https://github.com/explosion/spaCy/issues/3311\",\n              children: \"issue #3311\"\n            }), \" for details).\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"For better compatibility with the Universal Dependencies data, the lemmatizer\\nnow preserves capitalization, e.g. for proper nouns. See\\n\", _jsx(_components.a, {\n              href: \"https://github.com/explosion/spaCy/issues/3256\",\n              children: \"issue #3256\"\n            }), \" for details.\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The built-in rule-based sentence boundary detector is now only called\\n\", _jsx(InlineCode, {\n              children: \"\\\"sentencizer\\\"\"\n            }), \" – the name \", _jsx(InlineCode, {\n              children: \"\\\"sbd\\\"\"\n            }), \" is deprecated.\"]\n          }), \"\\n\", _jsx(_components.pre, {\n            children: _jsx(_components.code, {\n              className: \"language-diff\",\n              lang: \"diff\",\n              children: \"- sentence_splitter = nlp.create_pipe(\\\"sbd\\\")\\n+ sentence_splitter = nlp.create_pipe(\\\"sentencizer\\\")\\n\"\n            })\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"is_sent_start\"\n            }), \" attribute of the first token in a \", _jsx(InlineCode, {\n              children: \"Doc\"\n            }), \" now correctly\\ndefaults to \", _jsx(InlineCode, {\n              children: \"True\"\n            }), \". It previously defaulted to \", _jsx(InlineCode, {\n              children: \"None\"\n            }), \".\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The keyword argument \", _jsx(InlineCode, {\n              children: \"n_threads\"\n            }), \" on the \", _jsx(InlineCode, {\n              children: \".pipe\"\n            }), \" methods is now deprecated, as\\nthe v2.x models cannot release the global interpreter lock. (Future versions\\nmay introduce a \", _jsx(InlineCode, {\n              children: \"n_process\"\n            }), \" argument for parallel inference via\\nmultiprocessing.)\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"Doc.print_tree\"\n            }), \" method is now deprecated. If you need a custom nested\\nJSON representation of a \", _jsx(InlineCode, {\n              children: \"Doc\"\n            }), \" object, you might want to write your own helper\\nfunction. For a simple and consistent JSON representation of the \", _jsx(InlineCode, {\n              children: \"Doc\"\n            }), \" object\\nand its annotations, you can now use the \", _jsx(_components.a, {\n              href: \"/api/doc#to_json\",\n              children: _jsx(InlineCode, {\n                children: \"Doc.to_json\"\n              })\n            }), \"\\nmethod. Going forward, this method will output the same format as the JSON\\ntraining data expected by \", _jsx(_components.a, {\n              href: \"/api/cli#train\",\n              children: _jsx(InlineCode, {\n                children: \"spacy train\"\n              })\n            }), \".\"]\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The \", _jsx(_components.a, {\n              href: \"/api/cli#train\",\n              children: _jsx(InlineCode, {\n                children: \"spacy train\"\n              })\n            }), \" command now lets you specify a\\ncomma-separated list of pipeline component names, instead of separate flags\\nlike \", _jsx(InlineCode, {\n              children: \"--no-parser\"\n            }), \" to disable components. This is more flexible and also\\nhandles custom components out-of-the-box.\"]\n          }), \"\\n\", _jsx(_components.pre, {\n            children: _jsx(_components.code, {\n              className: \"language-diff\",\n              lang: \"diff\",\n              children: \"- $ spacy train en /output train_data.json dev_data.json --no-parser\\n+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner\\n\"\n            })\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"The \", _jsx(_components.a, {\n              href: \"/api/cli#init-model\",\n              children: _jsx(InlineCode, {\n                children: \"spacy init-model\"\n              })\n            }), \" command now uses a \", _jsx(InlineCode, {\n              children: \"--jsonl-loc\"\n            }), \"\\nargument to pass in a a newline-delimited JSON (JSONL) file containing one\\nlexical entry per line instead of a separate \", _jsx(InlineCode, {\n              children: \"--freqs-loc\"\n            }), \" and\\n\", _jsx(InlineCode, {\n              children: \"--clusters-loc\"\n            }), \".\"]\n          }), \"\\n\", _jsx(_components.pre, {\n            children: _jsx(_components.code, {\n              className: \"language-diff\",\n              lang: \"diff\",\n              children: \"- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt\\n+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl\\n\"\n            })\n          }), \"\\n\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"\\n\", _jsxs(_components.p, {\n            children: [\"Also note that some of the model licenses have changed:\\n\", _jsx(_components.a, {\n              href: \"/models/it#it_core_news_sm\",\n              children: _jsx(InlineCode, {\n                children: \"it_core_news_sm\"\n              })\n            }), \" is now correctly licensed\\nunder CC BY-NC-SA 3.0, and all \", _jsx(_components.a, {\n              href: \"/models/en\",\n              children: \"English\"\n            }), \" and \", _jsx(_components.a, {\n              href: \"/models/de\",\n              children: \"German\"\n            }), \"\\nmodels are now published under the MIT license.\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"What's New in v2.1","teaser":"New features, backwards incompatibilities and migration guide","menu":[["New Features","features"],["Backwards Incompatibilities","incompat"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":null},"__N_SSG":true}