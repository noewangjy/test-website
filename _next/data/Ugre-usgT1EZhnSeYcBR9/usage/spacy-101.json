{"pageProps":{"title":"spaCy 101: Everything you need to know","teaser":"The most important concepts, explained in simple terms","menu":[["What's spaCy?","whats-spacy"],["Features","features"],["Linguistic Annotations","annotations"],["Pipelines","pipelines"],["Architecture","architecture"],["Vocab","vocab"],["Serialization","serialization"],["Training","training"],["Language Data","language-data"],["Community & FAQ","community-faq"]],"slug":"/usage/spacy-101","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    p: \"p\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    a: \"a\",\n    h2: \"h2\",\n    strong: \"strong\",\n    ul: \"ul\",\n    li: \"li\",\n    h3: \"h3\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    pre: \"pre\",\n    code: \"code\",\n    em: \"em\",\n    img: \"img\"\n  }, _provideComponents(), props.components), {Infobox, Image, Button, Grid, InlineCode, Tokenization101, PosDeps101, NER101, Vectors101, Pipelines101, Architecture101, Serialization101, Training101, LanguageData101} = _components;\n  if (!Architecture101) _missingMdxReference(\"Architecture101\", true);\n  if (!Button) _missingMdxReference(\"Button\", true);\n  if (!Grid) _missingMdxReference(\"Grid\", true);\n  if (!Image) _missingMdxReference(\"Image\", true);\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  if (!LanguageData101) _missingMdxReference(\"LanguageData101\", true);\n  if (!NER101) _missingMdxReference(\"NER101\", true);\n  if (!Pipelines101) _missingMdxReference(\"Pipelines101\", true);\n  if (!PosDeps101) _missingMdxReference(\"PosDeps101\", true);\n  if (!Serialization101) _missingMdxReference(\"Serialization101\", true);\n  if (!Tokenization101) _missingMdxReference(\"Tokenization101\", true);\n  if (!Training101) _missingMdxReference(\"Training101\", true);\n  if (!Vectors101) _missingMdxReference(\"Vectors101\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      children: [_jsx(_components.p, {\n        children: \"Whether you’re new to spaCy, or just want to brush up on some NLP basics and\\nimplementation details – this page should have you covered. Each section will\\nexplain one of spaCy’s features in simple terms and with examples or\\nillustrations. Some sections will also reappear across the usage guides as a\\nquick introduction.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Help us improve the docs\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Did you spot a mistake or come across explanations that are unclear? We always\\nappreciate improvement\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/issues\",\n            children: \"suggestions\"\n          }), \" or\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/pulls\",\n            children: \"pull requests\"\n          }), \". You can find a\\n“Suggest edits” link at the bottom of each page that points you to the source.\"]\n        }), \"\\n\"]\n      }), _jsxs(Infobox, {\n        title: \"Take the free interactive course\",\n        children: [_jsx(Image, {\n          src: \"/images/course.jpg\",\n          href: \"https://course.spacy.io\",\n          alt: \"Advanced NLP with spaCy\"\n        }), _jsx(_components.p, {\n          children: \"In this course you’ll learn how to use spaCy to build advanced natural language\\nunderstanding systems, using both rule-based and machine learning approaches. It\\nincludes 55 exercises featuring interactive coding practice, multiple-choice\\nquestions and slide decks.\"\n        }), _jsx(Button, {\n          to: \"https://course.spacy.io\",\n          variant: \"primary\",\n          children: 'Start the course'\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-whats-spacy\",\n      children: [_jsx(_components.h2, {\n        id: \"whats-spacy\",\n        children: \"What’s spaCy? \"\n      }), _jsxs(Grid, {\n        cols: 2,\n        children: [_jsxs(\"div\", {\n          children: [_jsxs(_components.p, {\n            children: [\"spaCy is a \", _jsx(_components.strong, {\n              children: \"free, open-source library\"\n            }), \" for advanced \", _jsx(_components.strong, {\n              children: \"Natural Language\\nProcessing\"\n            }), \" (NLP) in Python.\"]\n          }), _jsx(_components.p, {\n            children: \"If you’re working with a lot of text, you’ll eventually want to know more about\\nit. For example, what’s it about? What do the words mean in context? Who is\\ndoing what to whom? What companies and products are mentioned? Which texts are\\nsimilar to each other?\"\n          }), _jsxs(_components.p, {\n            children: [\"spaCy is designed specifically for \", _jsx(_components.strong, {\n              children: \"production use\"\n            }), \" and helps you build\\napplications that process and “understand” large volumes of text. It can be used\\nto build \", _jsx(_components.strong, {\n              children: \"information extraction\"\n            }), \" or \", _jsx(_components.strong, {\n              children: \"natural language understanding\"\n            }), \"\\nsystems, or to pre-process text for \", _jsx(_components.strong, {\n              children: \"deep learning\"\n            }), \".\"]\n          })]\n        }), _jsx(Infobox, {\n          title: \"Table of contents\",\n          id: \"toc\",\n          children: _jsxs(_components.ul, {\n            children: [\"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features\",\n                children: \"Features\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations\",\n                children: \"Linguistic annotations\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-token\",\n                children: \"Tokenization\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-pos-deps\",\n                children: \"POS tags and dependencies\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-ner\",\n                children: \"Named entities\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#vectors-similarity\",\n                children: \"Word vectors and similarity\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#pipelines\",\n                children: \"Pipelines\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#architecture\",\n                children: \"Library architecture\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#vocab\",\n                children: \"Vocab, hashes and lexemes\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#serialization\",\n                children: \"Serialization\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#training\",\n                children: \"Training\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#language-data\",\n                children: \"Language data\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#community\",\n                children: \"Community & FAQ\"\n              })\n            }), \"\\n\"]\n          })\n        })]\n      }), _jsx(_components.h3, {\n        id: \"what-spacy-isnt\",\n        children: \"What spaCy isn’t \"\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not a platform or “an API”\"\n          }), \". Unlike a platform, spaCy does not\\nprovide a software as a service, or a web application. It’s an open-source\\nlibrary designed to help you build NLP applications, not a consumable service.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not an out-of-the-box chat bot engine\"\n          }), \". While spaCy can be used\\nto power conversational applications, it’s not designed specifically for chat\\nbots, and only provides the underlying text processing capabilities.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌\", _jsx(_components.strong, {\n            children: \"spaCy is not research software\"\n          }), \". It’s built on the latest research, but\\nit’s designed to get things done. This leads to fairly different design\\ndecisions than \", _jsx(_components.a, {\n            href: \"https://github.com/nltk/nltk\",\n            children: \"NLTK\"\n          }), \" or\\n\", _jsx(_components.a, {\n            href: \"https://stanfordnlp.github.io/CoreNLP/\",\n            children: \"CoreNLP\"\n          }), \", which were created as\\nplatforms for teaching and research. The main difference is that spaCy is\\nintegrated and opinionated. spaCy tries to avoid asking the user to choose\\nbetween multiple algorithms that deliver equivalent functionality. Keeping the\\nmenu small lets spaCy deliver generally better performance and developer\\nexperience.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not a company\"\n          }), \". It’s an open-source library. Our company\\npublishing spaCy and other software is called\\n\", _jsx(_components.a, {\n            href: \"https://explosion.ai\",\n            children: \"Explosion\"\n          }), \".\"]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-features\",\n      children: [_jsx(_components.h2, {\n        id: \"features\",\n        children: \"Features \"\n      }), _jsx(_components.p, {\n        children: \"In the documentation, you’ll come across mentions of spaCy’s features and\\ncapabilities. Some of them refer to linguistic concepts, while others are\\nrelated to more general machine learning functionality.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Tokenization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Segmenting text into words, punctuations marks etc.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Part-of-speech\"\n              }), \" (POS) \", _jsx(_components.strong, {\n                children: \"Tagging\"\n              })]\n            }), _jsx(_components.td, {\n              children: \"Assigning word types to tokens, like verb or noun.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Dependency Parsing\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Lemmatization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Sentence Boundary Detection\"\n              }), \" (SBD)\"]\n            }), _jsx(_components.td, {\n              children: \"Finding and segmenting individual sentences.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Named Entity Recognition\"\n              }), \" (NER)\"]\n            }), _jsx(_components.td, {\n              children: \"Labelling named “real-world” objects, like persons, companies or locations.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Entity Linking\"\n              }), \" (EL)\"]\n            }), _jsx(_components.td, {\n              children: \"Disambiguating textual entities to unique identifiers in a knowledge base.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Similarity\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Comparing words, text spans and documents and how similar they are to each other.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Text Classification\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning categories or labels to a whole document, or parts of a document.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Rule-based Matching\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Training\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Updating and improving a statistical model’s predictions.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Serialization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Saving objects to files or byte strings.\"\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"statistical-models\",\n        children: \"Statistical models \"\n      }), _jsxs(_components.p, {\n        children: [\"While some of spaCy’s features work independently, others require\\n\", _jsx(_components.a, {\n          href: \"/models\",\n          children: \"trained pipelines\"\n        }), \" to be loaded, which enable spaCy to \", _jsx(_components.strong, {\n          children: \"predict\"\n        }), \"\\nlinguistic annotations – for example, whether a word is a verb or a noun. A\\ntrained pipeline can consist of multiple components that use a statistical model\\ntrained on labeled data. spaCy currently offers trained pipelines for a variety\\nof languages, which can be installed as individual Python modules. Pipeline\\npackages can differ in size, speed, memory usage, accuracy and the data they\\ninclude. The package you choose always depends on your use case and the texts\\nyou’re working with. For a general-purpose use case, the small, default packages\\nare always a good start. They typically include the following components:\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Binary weights\"\n          }), \" for the part-of-speech tagger, dependency parser and named\\nentity recognizer to predict those annotations in context.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Lexical entries\"\n          }), \" in the vocabulary, i.e. words and their\\ncontext-independent attributes like the shape or spelling.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Data files\"\n          }), \" like lemmatization rules and lookup tables.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Word vectors\"\n          }), \", i.e. multi-dimensional meaning representations of words that\\nlet you determine how similar they are to each other.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Configuration\"\n          }), \" options, like the language and processing pipeline settings\\nand model implementations to use, to put spaCy in the correct state when you\\nload the pipeline.\"]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-annotations\",\n      children: [_jsx(_components.h2, {\n        id: \"annotations\",\n        children: \"Linguistic annotations \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy provides a variety of linguistic annotations to give you \", _jsx(_components.strong, {\n          children: \"insights into a\\ntext’s grammatical structure\"\n        }), \". This includes the word types, like the parts of\\nspeech, and how the words are related to each other. For example, if you’re\\nanalyzing text, it makes a huge difference whether a noun is the subject of a\\nsentence, or the object – or whether “google” is used as a verb, or refers to\\nthe website or company in a specific context.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Loading pipelines\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"$ python -m spacy download en_core_web_sm\\n\\n>>> import spacy\\n>>> nlp = spacy.load(\\\"en_core_web_sm\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Once you’ve \", _jsx(_components.a, {\n          href: \"/usage/models\",\n          children: \"downloaded and installed\"\n        }), \" a trained pipeline, you\\ncan load it via \", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.load\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.load\"\n          })\n        }), \". This will return a\\n\", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" object containing all components and data needed to process text. We\\nusually call it \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \". Calling the \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object on a string of text will return\\na processed \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \":\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"Apple is looking at buying U.K. startup for $1 billion\\\")\\nfor token in doc:\\n    print(token.text, token.pos_, token.dep_)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Even though a \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" is processed – e.g. split into individual words and\\nannotated – it still holds \", _jsx(_components.strong, {\n          children: \"all information of the original text\"\n        }), \", like\\nwhitespace characters. You can always get the offset of a token into the\\noriginal string, or reconstruct the original by joining the tokens and their\\ntrailing whitespace. This way, you’ll never lose any information when processing\\ntext with spaCy.\"]\n      }), _jsx(_components.h3, {\n        id: \"annotations-token\",\n        children: \"Tokenization \"\n      }), _jsx(Tokenization101, {}), _jsx(Infobox, {\n        title: \"Tokenization rules\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how spaCy’s tokenization rules work in detail, how to\\n\", _jsx(_components.strong, {\n            children: \"customize and replace\"\n          }), \" the default tokenizer and how to \", _jsx(_components.strong, {\n            children: \"add\\nlanguage-specific data\"\n          }), \", see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#language-data\",\n            children: \"language data\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#tokenization\",\n            children: \"customizing the tokenizer\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"annotations-pos-deps\",\n        model: \"parser\",\n        children: \"Part-of-speech tags and dependencies \"\n      }), _jsx(PosDeps101, {}), _jsx(Infobox, {\n        title: \"Part-of-speech tagging and morphology\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"part-of-speech tagging\"\n          }), \" and rule-based morphology, and\\nhow to \", _jsx(_components.strong, {\n            children: \"navigate and use the parse tree\"\n          }), \" effectively, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#pos-tagging\",\n            children: \"part-of-speech tagging\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#dependency-parse\",\n            children: \"using the dependency parse\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"annotations-ner\",\n        model: \"ner\",\n        children: \"Named Entities \"\n      }), _jsx(NER101, {}), _jsx(Infobox, {\n        title: \"Named Entity Recognition\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about entity recognition in spaCy, how to \", _jsx(_components.strong, {\n            children: \"add your own\\nentities\"\n          }), \" to a document and how to \", _jsx(_components.strong, {\n            children: \"train and update\"\n          }), \" the entity predictions\\nof a model, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#named-entities\",\n            children: \"named entity recognition\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/training\",\n            children: \"training pipelines\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"vectors-similarity\",\n        model: \"vectors\",\n        children: \"Word vectors and similarity \"\n      }), _jsx(Vectors101, {}), _jsx(Infobox, {\n        title: \"Word vectors\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about word vectors, how to \", _jsx(_components.strong, {\n            children: \"customize them\"\n          }), \" and how to load\\n\", _jsx(_components.strong, {\n            children: \"your own vectors\"\n          }), \" into spaCy, see the usage guide on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#vectors-similarity\",\n            children: \"using word vectors and semantic similarities\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-pipelines\",\n      children: [_jsx(_components.h2, {\n        id: \"pipelines\",\n        children: \"Pipelines \"\n      }), _jsx(Pipelines101, {}), _jsx(Infobox, {\n        title: \"Processing pipelines\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"how processing pipelines work\"\n          }), \" in detail, how to enable\\nand disable their components, and how to \", _jsx(_components.strong, {\n            children: \"create your own\"\n          }), \", see the usage\\nguide on \", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines\",\n            children: \"language processing pipelines\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-architecture\",\n      children: [_jsx(_components.h2, {\n        id: \"architecture\",\n        children: \"Architecture \"\n      }), _jsx(Architecture101, {})]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-vocab\",\n      children: [_jsx(_components.h2, {\n        id: \"vocab\",\n        children: \"Vocab, hashes and lexemes \"\n      }), _jsxs(_components.p, {\n        children: [\"Whenever possible, spaCy tries to store data in a vocabulary, the\\n\", _jsx(_components.a, {\n          href: \"/api/vocab\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab\"\n          })\n        }), \", that will be \", _jsx(_components.strong, {\n          children: \"shared by multiple documents\"\n        }), \". To save\\nmemory, spaCy also encodes all strings to \", _jsx(_components.strong, {\n          children: \"hash values\"\n        }), \" – in this case for\\nexample, “coffee” has the hash \", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \". Entity labels like “ORG”\\nand part-of-speech tags like “VERB” are also encoded. Internally, spaCy only\\n“speaks” in hash values.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Token\"\n            }), \": A word, punctuation mark etc. \", _jsx(_components.em, {\n              children: \"in context\"\n            }), \", including its\\nattributes, tags and dependencies.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Lexeme\"\n            }), \": A “word type” with no context. Includes the word shape and\\nflags, e.g. if it’s lowercase, a digit or punctuation.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Doc\"\n            }), \": A processed container of tokens in context.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Vocab\"\n            }), \": The collection of lexemes.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"StringStore\"\n            }), \": The dictionary mapping hash values to strings, for example\\n\", _jsx(InlineCode, {\n              children: \"3197928453018144401\"\n            }), \" → “coffee”.\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/vocab_stringstore.svg\",\n        alt: \"Doc, Vocab, Lexeme and StringStore\"\n      }), _jsxs(_components.p, {\n        children: [\"If you process lots of documents containing the word “coffee” in all kinds of\\ndifferent contexts, storing the exact string “coffee” every time would take up\\nway too much space. So instead, spaCy hashes the string and stores it in the\\n\", _jsx(_components.a, {\n          href: \"/api/stringstore\",\n          children: _jsx(InlineCode, {\n            children: \"StringStore\"\n          })\n        }), \". You can think of the \", _jsx(InlineCode, {\n          children: \"StringStore\"\n        }), \" as a\\n\", _jsx(_components.strong, {\n          children: \"lookup table that works in both directions\"\n        }), \" – you can look up a string to get\\nits hash, or a hash to get its string:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")\\nprint(doc.vocab.strings[\\\"coffee\\\"])  # 3197928453018144401\\nprint(doc.vocab.strings[3197928453018144401])  # 'coffee'\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Now that all strings are encoded, the entries in the vocabulary \", _jsx(_components.strong, {\n          children: \"don’t need to\\ninclude the word text\"\n        }), \" themselves. Instead, they can look it up in the\\n\", _jsx(InlineCode, {\n          children: \"StringStore\"\n        }), \" via its hash value. Each entry in the vocabulary, also called\\n\", _jsx(_components.a, {\n          href: \"/api/lexeme\",\n          children: _jsx(InlineCode, {\n            children: \"Lexeme\"\n          })\n        }), \", contains the \", _jsx(_components.strong, {\n          children: \"context-independent\"\n        }), \" information about\\na word. For example, no matter if “love” is used as a verb or a noun in some\\ncontext, its spelling and whether it consists of alphabetic characters won’t\\never change. Its hash value will also always be the same.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")\\nfor word in doc:\\n    lexeme = doc.vocab[word.text]\\n    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\\n            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)\\n\"\n        })\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Text\"\n            }), \": The original text of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Orth\"\n            }), \": The hash value of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Shape\"\n            }), \": The abstract word shape of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Prefix\"\n            }), \": By default, the first letter of the word string.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Suffix\"\n            }), \": By default, the last three letters of the word string.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"is alpha\"\n            }), \": Does the lexeme consist of alphabetic characters?\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"is digit\"\n            }), \": Does the lexeme consist of digits?\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Text\"\n            }), _jsx(_components.th, {\n              children: \"Orth\"\n            }), _jsx(_components.th, {\n              children: \"Shape\"\n            }), _jsx(_components.th, {\n              children: \"Prefix\"\n            }), _jsx(_components.th, {\n              children: \"Suffix\"\n            }), _jsx(_components.th, {\n              children: \"is_alpha\"\n            }), _jsx(_components.th, {\n              children: \"is_digit\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"4690420944186131903\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"X\"\n              })\n            }), _jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"love\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"3702023516439754181\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"xxxx\"\n              })\n            }), _jsx(_components.td, {\n              children: \"l\"\n            }), _jsx(_components.td, {\n              children: \"ove\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"coffee\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"3197928453018144401\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"xxxx\"\n              })\n            }), _jsx(_components.td, {\n              children: \"c\"\n            }), _jsx(_components.td, {\n              children: \"fee\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          })]\n        })]\n      }), _jsxs(_components.p, {\n        children: [\"The mapping of words to hashes doesn’t depend on any state. To make sure each\\nvalue is unique, spaCy uses a\\n\", _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Hash_function\",\n          children: \"hash function\"\n        }), \" to calculate the\\nhash \", _jsx(_components.strong, {\n          children: \"based on the word string\"\n        }), \". This also means that the hash for “coffee”\\nwill always be the same, no matter which pipeline you’re using or how you’ve\\nconfigured spaCy.\"]\n      }), _jsxs(_components.p, {\n        children: [\"However, hashes \", _jsx(_components.strong, {\n          children: \"cannot be reversed\"\n        }), \" and there’s no way to resolve\\n\", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \" back to “coffee”. All spaCy can do is look it up in the\\nvocabulary. That’s why you always need to make sure all objects you create have\\naccess to the same vocabulary. If they don’t, spaCy might not be able to find\\nthe strings it needs.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\nfrom spacy.tokens import Doc\\nfrom spacy.vocab import Vocab\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")  # Original Doc\\nprint(doc.vocab.strings[\\\"coffee\\\"])  # 3197928453018144401\\nprint(doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\\nempty_doc = Doc(Vocab())  # New Doc with empty Vocab\\n# empty_doc.vocab.strings[3197928453018144401] will raise an error :(\\n\\nempty_doc.vocab.strings.add(\\\"coffee\\\")  # Add \\\"coffee\\\" and generate hash\\nprint(empty_doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\\nnew_doc = Doc(doc.vocab)  # Create new doc with first doc's vocab\\nprint(new_doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If the vocabulary doesn’t contain a string for \", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \", spaCy will\\nraise an error. You can re-add “coffee” manually, but this only works if you\\nactually \", _jsx(_components.em, {\n          children: \"know\"\n        }), \" that the document contains that word. To prevent this problem,\\nspaCy will also export the \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \" when you save a \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object. This\\nwill give you the object and its encoded annotations, plus the “key” to decode\\nit.\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-serialization\",\n      children: [_jsx(_components.h2, {\n        id: \"serialization\",\n        children: \"Serialization \"\n      }), _jsx(Serialization101, {}), _jsx(Infobox, {\n        title: \"Saving and loading\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how to \", _jsx(_components.strong, {\n            children: \"save and load your own pipelines\"\n          }), \", see the usage\\nguide on \", _jsx(_components.a, {\n            href: \"/usage/saving-loading#models\",\n            children: \"saving and loading\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-training\",\n      children: [_jsx(_components.h2, {\n        id: \"training\",\n        children: \"Training \"\n      }), _jsx(Training101, {}), _jsx(Infobox, {\n        title: \"Training pipelines and models\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"training and updating\"\n          }), \" pipelines, how to create training\\ndata and how to improve spaCy’s named models, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/training\",\n            children: \"training\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"training-config\",\n        children: \"Training config and lifecycle \"\n      }), _jsxs(_components.p, {\n        children: [\"Training config files include all \", _jsx(_components.strong, {\n          children: \"settings and hyperparameters\"\n        }), \" for training\\nyour pipeline. Instead of providing lots of arguments on the command line, you\\nonly need to pass your \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" file to \", _jsx(_components.a, {\n          href: \"/api/cli#train\",\n          children: _jsx(InlineCode, {\n            children: \"spacy train\"\n          })\n        }), \".\\nThis also makes it easy to integrate custom models and architectures, written in\\nyour framework of choice. A pipeline’s \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" is considered the “single\\nsource of truth”, both at \", _jsx(_components.strong, {\n          children: \"training\"\n        }), \" and \", _jsx(_components.strong, {\n          children: \"runtime\"\n        }), \".\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            title: \"config.cfg (excerpt)\",\n            children: \"[training]\\naccumulate_gradient = 3\\n\\n[training.optimizer]\\n@optimizers = \\\"Adam.v1\\\"\\n\\n[training.optimizer.learn_rate]\\n@schedules = \\\"warmup_linear.v1\\\"\\nwarmup_steps = 250\\ntotal_steps = 20000\\ninitial_rate = 0.01\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/lifecycle.svg\",\n        alt: \"Illustration of pipeline lifecycle\"\n      }), _jsx(Infobox, {\n        title: \"Training configuration system\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"For more details on spaCy’s \", _jsx(_components.strong, {\n            children: \"configuration system\"\n          }), \" and how to use it to\\ncustomize your pipeline components, component models, training settings and\\nhyperparameters, see the \", _jsx(_components.a, {\n            href: \"/usage/training#config\",\n            children: \"training config\"\n          }), \" usage guide.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"training-components\",\n        children: \"Trainable components \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy’s \", _jsx(_components.a, {\n          href: \"/api/pipe\",\n          children: _jsx(InlineCode, {\n            children: \"Pipe\"\n          })\n        }), \" class helps you implement your own trainable\\ncomponents that have their own model instance, make predictions over \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"\\nobjects and can be updated using \", _jsx(_components.a, {\n          href: \"/api/cli#train\",\n          children: _jsx(InlineCode, {\n            children: \"spacy train\"\n          })\n        }), \". This lets you\\nplug fully custom machine learning components into your pipeline that can be\\nconfigured via a single training config.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"config.cfg (excerpt)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[components.my_component]\\nfactory = \\\"my_component\\\"\\n\\n[components.my_component.model]\\n@architectures = \\\"my_model.v1\\\"\\nwidth = 128\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/trainable_component.svg\",\n        alt: \"Illustration of Pipe methods\"\n      }), _jsx(Infobox, {\n        title: \"Custom trainable components\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how to implement your own \", _jsx(_components.strong, {\n            children: \"model architectures\"\n          }), \" and use\\nthem to power custom \", _jsx(_components.strong, {\n            children: \"trainable components\"\n          }), \", see the usage guides on the\\n\", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines#trainable-components\",\n            children: \"trainable component API\"\n          }), \" and\\nimplementing \", _jsx(_components.a, {\n            href: \"/usage/layers-architectures#components\",\n            children: \"layers and architectures\"\n          }), \"\\nfor trainable components.\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-language-data\",\n      children: [_jsx(_components.h2, {\n        id: \"language-data\",\n        children: \"Language data \"\n      }), _jsx(LanguageData101, {})]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-community-faq\",\n      children: [_jsx(_components.h2, {\n        id: \"community-faq\",\n        children: \"Community & FAQ \"\n      }), _jsx(_components.p, {\n        children: \"We’re very happy to see the spaCy community grow and include a mix of people\\nfrom all kinds of different backgrounds – computational linguistics, data\\nscience, deep learning, research and more. If you’d like to get involved, below\\nare some answers to the most important questions and resources for further\\nreading.\"\n      }), _jsx(_components.h3, {\n        id: \"faq-help-code\",\n        children: \"Help, my code isn’t working! \"\n      }), _jsxs(_components.p, {\n        children: [\"Bugs suck, and we’re doing our best to continuously improve the tests and fix\\nbugs as soon as possible. Before you submit an issue, do a quick search and\\ncheck if the problem has already been reported. If you’re having installation or\\nloading problems, make sure to also check out the\\n\", _jsx(_components.a, {\n          href: \"/usage/#troubleshooting\",\n          children: \"troubleshooting guide\"\n        }), \". Help with spaCy is available\\nvia the following platforms:\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"How do I know if something is a bug?\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Of course, it’s always hard to know for sure, so don’t worry – we’re not going\\nto be mad if a bug report turns out to be a typo in your code. As a simple\\nrule, any C-level error without a Python traceback, like a \", _jsx(_components.strong, {\n            children: \"segmentation\\nfault\"\n          }), \" or \", _jsx(_components.strong, {\n            children: \"memory error\"\n          }), \", is \", _jsx(_components.strong, {\n            children: \"always\"\n          }), \" a spaCy bug.\"]\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Because models are statistical, their performance will never be \", _jsx(_components.em, {\n            children: \"perfect\"\n          }), \".\\nHowever, if you come across \", _jsx(_components.strong, {\n            children: \"patterns that might indicate an underlying\\nissue\"\n          }), \", please do file a report. Similarly, we also care about behaviors that\\n\", _jsx(_components.strong, {\n            children: \"contradict our docs\"\n          }), \".\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://stackoverflow.com/questions/tagged/spacy\",\n            children: \"Stack Overflow\"\n          }), \": \", _jsx(_components.strong, {\n            children: \"Usage\\nquestions\"\n          }), \" and everything related to problems with your specific code. The\\nStack Overflow community is much larger than ours, so if your problem can be\\nsolved by others, you’ll receive help much quicker.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/discussions\",\n            children: \"GitHub discussions\"\n          }), \":\\n\", _jsx(_components.strong, {\n            children: \"General discussion\"\n          }), \", \", _jsx(_components.strong, {\n            children: \"project ideas\"\n          }), \" and \", _jsx(_components.strong, {\n            children: \"usage questions\"\n          }), \". Meet other\\ncommunity members to get help with a specific code implementation, discuss\\nideas for new projects/plugins, support more languages, and share best\\npractices.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/issues\",\n            children: \"GitHub issue tracker\"\n          }), \": \", _jsx(_components.strong, {\n            children: \"Bug\\nreports\"\n          }), \" and \", _jsx(_components.strong, {\n            children: \"improvement suggestions\"\n          }), \", i.e. everything that’s likely\\nspaCy’s fault. This also includes problems with the trained pipelines beyond\\nstatistical imprecisions, like patterns that point to a bug.\"]\n        }), \"\\n\"]\n      }), _jsx(Infobox, {\n        title: \"Important note\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"Please understand that we won’t be able to provide individual support via email.\\nWe also believe that help is much more valuable if it’s shared publicly, so that\\n\", _jsx(_components.strong, {\n            children: \"more people can benefit from it\"\n          }), \". If you come across an issue and you think\\nyou might be able to help, consider posting a quick update with your solution.\\nNo matter how simple, it can easily save someone a lot of time and headache –\\nand the next time you need help, they might repay the favor.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"faq-contributing\",\n        children: \"How can I contribute to spaCy? \"\n      }), _jsxs(_components.p, {\n        children: [\"You don’t have to be an NLP expert or Python pro to contribute, and we’re happy\\nto help you get started. If you’re new to spaCy, a good place to start is the\\n\", _jsxs(_components.a, {\n          href: \"https://github.com/explosion/spaCy/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted+%28easy%29%22\",\n          children: [_jsx(InlineCode, {\n            children: \"help wanted (easy)\"\n          }), \" label\"]\n        }), \"\\non GitHub, which we use to tag bugs and feature requests that are easy and\\nself-contained. We also appreciate contributions to the docs – whether it’s\\nfixing a typo, improving an example or adding additional explanations. You’ll\\nfind a “Suggest edits” link at the bottom of each page that points you to the\\nsource.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Another way of getting involved is to help us improve the\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#language-data\",\n          children: \"language data\"\n        }), \" – especially if you\\nhappen to speak one of the languages currently in\\n\", _jsx(_components.a, {\n          href: \"/usage/models#languages\",\n          children: \"alpha support\"\n        }), \". Even adding simple tokenizer\\nexceptions, stop words or lemmatizer data can make a big difference. It will\\nalso make it easier for us to provide a trained pipeline for the language in the\\nfuture. Submitting a test that documents a bug or performance issue, or covers\\nfunctionality that’s especially important for your application is also very\\nhelpful. This way, you’ll also make sure we never accidentally introduce\\nregressions to the parts of the library that you care about the most.\"]\n      }), _jsx(_components.p, {\n        children: _jsxs(_components.strong, {\n          children: [\"For more details on the types of contributions we’re looking for, the code\\nconventions and other useful tips, make sure to check out the\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/tree/master/CONTRIBUTING.md\",\n            children: \"contributing guidelines\"\n          }), \".\"]\n        })\n      }), _jsx(Infobox, {\n        title: \"Code of Conduct\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"spaCy adheres to the\\n\", _jsx(_components.a, {\n            href: \"http://contributor-covenant.org/version/1/4/\",\n            children: \"Contributor Covenant Code of Conduct\"\n          }), \".\\nBy participating, you are expected to uphold this code.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"faq-project-with-spacy\",\n        children: \"I’ve built something cool with spaCy – how can I get the word out? \"\n      }), _jsxs(_components.p, {\n        children: [\"First, congrats – we’d love to check it out! When you share your project on\\nTwitter, don’t forget to tag \", _jsx(_components.a, {\n          href: \"https://twitter.com/spacy_io\",\n          children: \"@spacy_io\"\n        }), \" so we\\ndon’t miss it. If you think your project would be a good fit for the\\n\", _jsx(_components.a, {\n          href: \"/universe\",\n          children: \"spaCy Universe\"\n        }), \", \", _jsx(_components.strong, {\n          children: \"feel free to submit it!\"\n        }), \" Tutorials are also\\nincredibly valuable to other users and a great way to get exposure. So we\\nstrongly encourage \", _jsx(_components.strong, {\n          children: \"writing up your experiences\"\n        }), \", or sharing your code and\\nsome tips and tricks on your blog. Since our website is open-source, you can add\\nyour project or tutorial by making a pull request on GitHub.\"]\n      }), _jsxs(_components.p, {\n        children: [\"If you would like to use the spaCy logo on your site, please get in touch and\\nask us first. However, if you want to show support and tell others that your\\nproject is using spaCy, you can grab one of our \", _jsx(_components.strong, {\n          children: \"spaCy badges\"\n        }), \" here:\"]\n      }), _jsx(\"img\", {\n        src: `https://img.shields.io/badge/built%20with-spaCy-09a3d5.svg`,\n        alt: \"Built with spaCy\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-markdown\",\n          lang: \"markdown\",\n          children: \"[![Built with spaCy](https://img.shields.io/badge/built%20with-spaCy-09a3d5.svg)](https://spacy.io)\\n\"\n        })\n      }), _jsx(\"img\", {\n        src: `https://img.shields.io/badge/made%20with%20❤%20and-spaCy-09a3d5.svg`,\n        alt: \"Made with love and spaCy\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-markdown\",\n          lang: \"markdown\",\n          children: \"[![Made with love and spaCy](https://img.shields.io/badge/made%20with%20❤%20and-spaCy-09a3d5.svg)](https://spacy.io)\\n\"\n        })\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"spaCy 101: Everything you need to know","teaser":"The most important concepts, explained in simple terms","menu":[["What's spaCy?","whats-spacy"],["Features","features"],["Linguistic Annotations","annotations"],["Pipelines","pipelines"],["Architecture","architecture"],["Vocab","vocab"],["Serialization","serialization"],["Training","training"],["Language Data","language-data"],["Community & FAQ","community-faq"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":{"slug":"/usage/v3","title":"New in v3.0"}},"__N_SSG":true}