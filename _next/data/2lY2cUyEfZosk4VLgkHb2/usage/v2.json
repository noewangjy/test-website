{"pageProps":{"title":"What's New in v2.0","teaser":"New features, backwards incompatibilities and migration guide","menu":[["Summary","summary"],["New Features","features"],["Backwards Incompatibilities","incompat"],["Migrating from v1.x","migrating"]],"slug":"/usage/v2","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    p: \"p\",\n    strong: \"strong\",\n    a: \"a\",\n    h2: \"h2\",\n    ul: \"ul\",\n    li: \"li\",\n    h3: \"h3\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    pre: \"pre\",\n    code: \"code\",\n    img: \"img\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    em: \"em\"\n  }, _provideComponents(), props.components), {Grid, InlineCode, Infobox} = _components;\n  if (!Grid) _missingMdxReference(\"Grid\", true);\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.section, {\n      children: _jsxs(_components.p, {\n        children: [\"We’re very excited to finally introduce spaCy v2.0! On this page, you’ll find a\\nsummary of the new features, information on the backwards incompatibilities,\\nincluding a handy overview of what’s been renamed or deprecated. To help you\\nmake the most of v2.0, we also \", _jsx(_components.strong, {\n          children: \"re-wrote almost all of the usage guides and API\\ndocs\"\n        }), \", and added more \", _jsx(_components.a, {\n          href: \"/usage/examples\",\n          children: \"real-world examples\"\n        }), \". If you’re new to\\nspaCy, or just want to brush up on some NLP basics and the details of the\\nlibrary, check out the \", _jsx(_components.a, {\n          href: \"/usage/spacy-101\",\n          children: \"spaCy 101 guide\"\n        }), \" that explains the\\nmost important concepts with examples and illustrations.\"]\n      })\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-summary\",\n      children: [_jsx(_components.h2, {\n        id: \"summary\",\n        children: \"Summary \"\n      }), _jsxs(Grid, {\n        cols: 2,\n        children: [_jsxs(\"div\", {\n          children: [_jsxs(_components.p, {\n            children: [\"This release features entirely new \", _jsx(_components.strong, {\n              children: \"deep learning-powered models\"\n            }), \" for spaCy’s\\ntagger, parser and entity recognizer. The new models are \", _jsx(_components.strong, {\n              children: \"10× smaller\"\n            }), \", \", _jsx(_components.strong, {\n              children: \"20%\\nmore accurate\"\n            }), \" and \", _jsx(_components.strong, {\n              children: \"even cheaper to run\"\n            }), \" than the previous generation.\"]\n          }), _jsxs(_components.p, {\n            children: [\"We’ve also made several usability improvements that are particularly helpful for\\n\", _jsx(_components.strong, {\n              children: \"production deployments\"\n            }), \". spaCy v2 now fully supports the Pickle protocol,\\nmaking it easy to use spaCy with \", _jsx(_components.a, {\n              href: \"https://spark.apache.org/\",\n              children: \"Apache Spark\"\n            }), \". The\\nstring-to-integer mapping is \", _jsx(_components.strong, {\n              children: \"no longer stateful\"\n            }), \", making it easy to reconcile\\nannotations made in different processes. Models are smaller and use less memory,\\nand the APIs for serialization are now much more consistent. Custom pipeline\\ncomponents let you modify the \", _jsx(InlineCode, {\n              children: \"Doc\"\n            }), \" at any stage in the pipeline. You can now\\nalso add your own custom attributes, properties and methods to the \", _jsx(InlineCode, {\n              children: \"Doc\"\n            }), \",\\n\", _jsx(InlineCode, {\n              children: \"Token\"\n            }), \" and \", _jsx(InlineCode, {\n              children: \"Span\"\n            }), \".\"]\n          })]\n        }), _jsx(Infobox, {\n          title: \"Table of Contents\",\n          id: \"toc\",\n          children: _jsxs(_components.ul, {\n            children: [\"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#summary\",\n                children: \"Summary\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features\",\n                children: \"New features\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-models\",\n                children: \"Neural network models\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-pipelines\",\n                children: \"Improved processing pipelines\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-text-classification\",\n                children: \"Text classification\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-hash-ids\",\n                children: \"Hash values as IDs\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-vectors\",\n                children: \"Improved word vectors support\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-serializer\",\n                children: \"Saving, loading and serialization\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-displacy\",\n                children: \"displaCy visualizer\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-language\",\n                children: \"Language data and lazy loading\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features-matcher\",\n                children: \"Revised matcher API and phrase matcher\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#incompat\",\n                children: \"Backwards incompatibilities\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#migrating\",\n                children: \"Migrating from spaCy v1.x\"\n              })\n            }), \"\\n\"]\n          })\n        })]\n      }), _jsxs(_components.p, {\n        children: [\"The main usability improvements you’ll notice in spaCy v2.0 are around\\n\", _jsx(_components.strong, {\n          children: \"defining, training and loading your own models\"\n        }), \" and components. The new\\nneural network models make it much easier to train a model from scratch, or\\nupdate an existing model with a few examples. In v1.x, the statistical models\\ndepended on the state of the \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \". If you taught the model a new word, you\\nwould have to save and load a lot of data — otherwise the model wouldn’t\\ncorrectly recall the features of your new example. That’s no longer the case.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Due to some clever use of hashing, the statistical models \", _jsx(_components.strong, {\n          children: \"never change size\"\n        }), \",\\neven as they learn new vocabulary items. The whole pipeline is also now fully\\ndifferentiable. Even if you don’t have explicitly annotated data, you can update\\nspaCy using all the \", _jsx(_components.strong, {\n          children: \"latest deep learning tricks\"\n        }), \" like adversarial training,\\nnoise contrastive estimation or reinforcement learning.\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-features\",\n      children: [_jsx(_components.h2, {\n        id: \"features\",\n        children: \"New features \"\n      }), _jsxs(_components.p, {\n        children: [\"This section contains an overview of the most important \", _jsx(_components.strong, {\n          children: \"new features and\\nimprovements\"\n        }), \". The \", _jsx(_components.a, {\n          href: \"/api\",\n          children: \"API docs\"\n        }), \" include additional deprecation notes.\"]\n      }), _jsx(_components.h3, {\n        id: \"features-models\",\n        children: \"Convolutional neural network models \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"python -m spacy download en_core_web_sm\\npython -m spacy download de_core_news_sm\\npython -m spacy download xx_ent_wiki_sm\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.0 features new neural models for tagging, parsing and entity\\nrecognition. The models have been designed and implemented from scratch\\nspecifically for spaCy, to give you an unmatched balance of speed, size and\\naccuracy. The new models are \", _jsx(_components.strong, {\n          children: \"10× smaller\"\n        }), \", \", _jsx(_components.strong, {\n          children: \"20% more accurate\"\n        }), \", and \", _jsx(_components.strong, {\n          children: \"even\\ncheaper to run\"\n        }), \" than the previous generation.\"]\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.0’s new neural network models bring significant improvements in\\naccuracy, especially for English Named Entity Recognition. The new\\n\", _jsx(_components.a, {\n          href: \"/models/en#en_core_web_lg\",\n          children: _jsx(InlineCode, {\n            children: \"en_core_web_lg\"\n          })\n        }), \" model makes about \", _jsx(_components.strong, {\n          children: \"25% fewer\\nmistakes\"\n        }), \" than the corresponding v1.x model and is within \", _jsx(_components.strong, {\n          children: \"1% of the current\\nstate-of-the-art\"\n        }), \"\\n(\", _jsx(_components.a, {\n          href: \"https://arxiv.org/pdf/1702.02098.pdf\",\n          children: \"Strubell et al., 2017\"\n        }), \"). The v2.0 models\\nare also cheaper to run at scale, as they require \", _jsx(_components.strong, {\n          children: \"under 1 GB of memory\"\n        }), \" per\\nprocess.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/models\",\n            children: \"Models directory\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-pipelines\",\n        children: \"Improved processing pipelines \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"# Set custom attributes\\nDoc.set_extension(\\\"my_attr\\\", default=False)\\nToken.set_extension(\\\"my_attr\\\", getter=my_token_getter)\\nassert doc._.my_attr, token._.my_attr\\n\\n# Add components to the pipeline\\nmy_component = lambda doc: doc\\nnlp.add_pipe(my_component)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"It’s now much easier to \", _jsx(_components.strong, {\n          children: \"customize the pipeline\"\n        }), \" with your own components:\\nfunctions that receive a \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" object, modify and return it. Extensions let you\\nwrite any \", _jsx(_components.strong, {\n          children: \"attributes, properties and methods\"\n        }), \" to the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"Token\"\n        }), \" and\\n\", _jsx(InlineCode, {\n          children: \"Span\"\n        }), \". You can add data, implement new features, integrate other libraries with\\nspaCy or plug in your own machine learning models.\"]\n      }), _jsx(_components.img, {\n        src: \"/images/pipeline.svg\",\n        alt: \"The processing pipeline\"\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/language\",\n            children: _jsx(InlineCode, {\n              children: \"Language\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/doc#set_extension\",\n            children: _jsx(InlineCode, {\n              children: \"Doc.set_extension\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/span#set_extension\",\n            children: _jsx(InlineCode, {\n              children: \"Span.set_extension\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/token#set_extension\",\n            children: _jsx(InlineCode, {\n              children: \"Token.set_extension\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines\",\n            children: \"Processing pipelines\"\n          }), \" \", _jsx(_components.strong, {\n            children: \"Code:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/examples#section-pipeline\",\n            children: \"Pipeline examples\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-text-classification\",\n        children: \"Text classification \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"textcat = nlp.create_pipe(\\\"textcat\\\")\\nnlp.add_pipe(textcat, last=True)\\nnlp.begin_training()\\nfor itn in range(100):\\n   for doc, gold in train_data:\\n       nlp.update([doc], [gold])\\ndoc = nlp(\\\"This is a text.\\\")\\nprint(doc.cats)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.0 lets you add text categorization models to spaCy pipelines. The model\\nsupports classification with multiple, non-mutually exclusive labels – so\\nmultiple labels can apply at once. You can change the model architecture rather\\neasily, but by default, the \", _jsx(InlineCode, {\n          children: \"TextCategorizer\"\n        }), \" class uses a convolutional neural\\nnetwork to assign position-sensitive vectors to each word in the document.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/textcategorizer\",\n            children: _jsx(InlineCode, {\n              children: \"TextCategorizer\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/doc#attributes\",\n            children: _jsx(InlineCode, {\n              children: \"Doc.cats\"\n            })\n          }), \", \", _jsx(InlineCode, {\n            children: \"GoldParse.cats\"\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/training#textcat\",\n            children: \"Training a text classification model\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-hash-ids\",\n        children: \"Hash values instead of integer IDs \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"doc = nlp(\\\"I love coffee\\\")\\nassert doc.vocab.strings[\\\"coffee\\\"] == 3197928453018144401\\nassert doc.vocab.strings[3197928453018144401] == \\\"coffee\\\"\\n\\nbeer_hash = doc.vocab.strings.add(\\\"beer\\\")\\nassert doc.vocab.strings[\\\"beer\\\"] == beer_hash\\nassert doc.vocab.strings[beer_hash] == \\\"beer\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(_components.a, {\n          href: \"/api/stringstore\",\n          children: _jsx(InlineCode, {\n            children: \"StringStore\"\n          })\n        }), \" now resolves all strings to hash values\\ninstead of integer IDs. This means that the string-to-int mapping \", _jsx(_components.strong, {\n          children: \"no longer\\ndepends on the vocabulary state\"\n        }), \", making a lot of workflows much simpler,\\nespecially during training. Unlike integer IDs in spaCy v1.x, hash values will\\n\", _jsx(_components.strong, {\n          children: \"always match\"\n        }), \" – even across models. Strings can now be added explicitly using\\nthe new \", _jsx(_components.a, {\n          href: \"/api/stringstore#add\",\n          children: _jsx(InlineCode, {\n            children: \"Stringstore.add\"\n          })\n        }), \" method. A token’s hash is\\navailable via \", _jsx(InlineCode, {\n          children: \"token.orth\"\n        }), \".\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/stringstore\",\n            children: _jsx(InlineCode, {\n              children: \"StringStore\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/spacy-101#vocab\",\n            children: \"Vocab, hashes and lexemes 101\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-vectors\",\n        children: \"Improved word vectors support \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"for word, vector in vector_data:\\n    nlp.vocab.set_vector(word, vector)\\nnlp.vocab.vectors.from_glove(\\\"/path/to/vectors\\\")\\n# Keep 10000 unique vectors and remap the rest\\nnlp.vocab.prune_vectors(10000)\\nnlp.to_disk(\\\"/model\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The new \", _jsx(_components.a, {\n          href: \"/api/vectors\",\n          children: _jsx(InlineCode, {\n            children: \"Vectors\"\n          })\n        }), \" class helps the \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \" manage the vectors\\nassigned to strings, and lets you assign vectors individually, or\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#adding-vectors\",\n          children: \"load in GloVe vectors\"\n        }), \" from a\\ndirectory. To help you strike a good balance between coverage and memory usage,\\nthe \", _jsx(InlineCode, {\n          children: \"Vectors\"\n        }), \" class lets you map \", _jsx(_components.strong, {\n          children: \"multiple keys\"\n        }), \" to the \", _jsx(_components.strong, {\n          children: \"same row\"\n        }), \" of the\\ntable. If you’re using the \", _jsx(_components.a, {\n          href: \"/api/cli#init-model\",\n          children: _jsx(InlineCode, {\n            children: \"spacy init-model\"\n          })\n        }), \" command to\\ncreate a vocabulary, pruning the vectors will be taken care of automatically if\\nyou set the \", _jsx(InlineCode, {\n          children: \"--prune-vectors\"\n        }), \" flag. Otherwise, you can use the new\\n\", _jsx(_components.a, {\n          href: \"/api/vocab#prune_vectors\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab.prune_vectors\"\n          })\n        }), \".\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/vectors\",\n            children: _jsx(InlineCode, {\n              children: \"Vectors\"\n            })\n          }), \", \", _jsx(_components.a, {\n            href: \"/api/vocab\",\n            children: _jsx(InlineCode, {\n              children: \"Vocab\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/vectors-similarity\",\n            children: \"Word vectors and semantic similarity\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-serializer\",\n        children: \"Saving, loading and serialization \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"nlp = spacy.load(\\\"en\\\") # shortcut link\\nnlp = spacy.load(\\\"en_core_web_sm\\\") # package\\nnlp = spacy.load(\\\"/path/to/en\\\") # unicode path\\nnlp = spacy.load(Path(\\\"/path/to/en\\\")) # pathlib Path\\n\\nnlp.to_disk(\\\"/path/to/nlp\\\")\\nnlp = English().from_disk(\\\"/path/to/nlp\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"spaCy’s serialization API has been made consistent across classes and objects.\\nAll container classes, i.e. \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"StringStore\"\n        }), \" now\\nhave a \", _jsx(InlineCode, {\n          children: \"to_bytes()\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"from_bytes()\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"to_disk()\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"from_disk()\"\n        }), \" method that\\nsupports the Pickle protocol.\"]\n      }), _jsxs(_components.p, {\n        children: [\"The improved \", _jsx(InlineCode, {\n          children: \"spacy.load\"\n        }), \" makes loading models easier and more transparent. You\\ncan load a model by supplying its shortcut link, the name of an installed\\n\", _jsx(_components.a, {\n          href: \"/models\",\n          children: \"model package\"\n        }), \" or a path. The \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" class to initialize will be\\ndetermined based on the model’s settings. For a blank language, you can import\\nthe class directly, e.g. \", _jsx(InlineCode, {\n          children: \"from spacy.lang.en import English\"\n        }), \" or use\\n\", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.blank\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.blank()\"\n          })\n        }), \".\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/top-level#spacy.load\",\n            children: _jsx(InlineCode, {\n              children: \"spacy.load\"\n            })\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/api/language#to_disk\",\n            children: _jsx(InlineCode, {\n              children: \"Language.to_disk\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/models#usage\",\n            children: \"Models\"\n          }), \",\\n\", _jsx(_components.a, {\n            href: \"/usage/saving-loading#models\",\n            children: \"Saving and loading\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-displacy\",\n        children: \"displaCy visualizer with Jupyter support \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy import displacy\\ndoc = nlp(\\\"This is a sentence about Facebook.\\\")\\ndisplacy.serve(doc, style=\\\"dep\\\") # run the web server\\nhtml = displacy.render(doc, style=\\\"ent\\\") # generate HTML\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Our popular dependency and named entity visualizers are now an official part of\\nthe spaCy library. displaCy can run a simple web server, or generate raw HTML\\nmarkup or SVG files to be exported. You can pass in one or more docs, and\\ncustomize the style. displaCy also auto-detects whether you’re running\\n\", _jsx(_components.a, {\n          href: \"https://jupyter.org\",\n          children: \"Jupyter\"\n        }), \" and will render the visualizations in your\\nnotebook.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/top-level#displacy\",\n            children: _jsx(InlineCode, {\n              children: \"displacy\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/visualizers\",\n            children: \"Visualizing spaCy\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-language\",\n        children: \"Improved language data and lazy loading \"\n      }), _jsxs(_components.p, {\n        children: [\"Language-specific data now lives in its own submodule, \", _jsx(InlineCode, {\n          children: \"spacy.lang\"\n        }), \". Languages\\nare lazy-loaded, i.e. only loaded when you import a \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" class, or load a\\nmodel that initializes one. This allows languages to contain more custom data,\\ne.g. lemmatizer lookup tables, or complex regular expressions. The language data\\nhas also been tidied up and simplified. spaCy now also supports simple\\nlookup-based lemmatization – and \", _jsx(_components.strong, {\n          children: \"many new languages\"\n        }), \"!\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/language\",\n            children: _jsx(InlineCode, {\n              children: \"Language\"\n            })\n          }), \" \", _jsx(_components.strong, {\n            children: \"Code:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spacy/tree/v2.x/spacy/lang\",\n            children: _jsx(InlineCode, {\n              children: \"spacy/lang\"\n            })\n          }), \"\\n\", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/usage/adding-languages\",\n            children: \"Adding languages\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"features-matcher\",\n        children: \"Revised matcher API and phrase matcher \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy.matcher import Matcher, PhraseMatcher\\n\\nmatcher = Matcher(nlp.vocab)\\nmatcher.add('HEARTS', None, [{\\\"ORTH\\\": \\\"❤️\\\", \\\"OP\\\": '+'}])\\n\\nphrasematcher = PhraseMatcher(nlp.vocab)\\nphrasematcher.add(\\\"OBAMA\\\", None, nlp(\\\"Barack Obama\\\"))\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Patterns can now be added to the matcher by calling\\n\", _jsx(_components.a, {\n          href: \"/api/matcher#add\",\n          children: _jsx(InlineCode, {\n            children: \"matcher.add()\"\n          })\n        }), \" with a match ID, an optional callback\\nfunction to be invoked on each match, and one or more patterns. This allows you\\nto write powerful, pattern-specific logic using only one matcher. For example,\\nyou might only want to merge some entity types, and set custom flags for other\\nmatched patterns. The new \", _jsx(_components.a, {\n          href: \"/api/phrasematcher\",\n          children: _jsx(InlineCode, {\n            children: \"PhraseMatcher\"\n          })\n        }), \" lets you\\nefficiently match very large terminology lists using \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects as match\\npatterns.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"API:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/api/matcher\",\n            children: _jsx(InlineCode, {\n              children: \"Matcher\"\n            })\n          }), \", \", _jsx(_components.a, {\n            href: \"/api/phrasematcher\",\n            children: _jsx(InlineCode, {\n              children: \"PhraseMatcher\"\n            })\n          }), \"\\n\", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/usage/rule-based-matching\",\n            children: \"Rule-based matching\"\n          })]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-incompat\",\n      children: [_jsx(_components.h2, {\n        id: \"incompat\",\n        children: \"Backwards incompatibilities \"\n      }), _jsx(_components.p, {\n        children: \"The following modules, classes and methods have changed between v1.x and v2.0.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Old\"\n            }), _jsx(_components.th, {\n              children: \"New\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"spacy.download.en\"\n              }), \", \", _jsx(InlineCode, {\n                children: \"spacy.download.de\"\n              })]\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/cli#download\",\n                children: _jsx(InlineCode, {\n                  children: \"cli.download\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"spacy.en\"\n              }), \" etc.\"]\n            }), _jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"spacy.lang.en\"\n              }), \" etc.\"]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.en.word_sets\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.lang.en.stop_words\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.orth\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.lang.xx.lex_attrs\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.syntax.iterators\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.lang.xx.syntax_iterators\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.tagger.Tagger\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.pipeline.Tagger\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy.cli.model\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/cli#vocab\",\n                children: _jsx(InlineCode, {\n                  children: \"spacy.cli.vocab\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Language.save_to_directory\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/language#to_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Language.to_disk\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Language.end_training\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/language#begin_training\",\n                children: _jsx(InlineCode, {\n                  children: \"Language.begin_training\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Language.create_make_doc\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/language#attributes\",\n                children: _jsx(InlineCode, {\n                  children: \"Language.tokenizer\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Vocab.resize_vectors\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/vectors#resize\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.resize\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"Vocab.load\"\n              }), \" \", _jsx(InlineCode, {\n                children: \"Vocab.load_lexemes\"\n              })]\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/vocab#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Vocab.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/vocab#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Vocab.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Vocab.dump\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/vocab#to_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Vocab.to_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/vocab#to_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Vocab.to_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"Vocab.load_vectors\"\n              }), \" \", _jsx(InlineCode, {\n                children: \"Vocab.load_vectors_from_bin_loc\"\n              })]\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/vectors#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/vectors#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.from_bytes\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/vectors#from_glove\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.from_glove\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Vocab.dump_vectors\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/vectors#to_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.to_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/vectors#to_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Vectors.to_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"StringStore.load\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/stringstore#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"StringStore.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/stringstore#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"StringStore.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"StringStore.dump\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/stringstore#to_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"StringStore.to_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/stringstore#to_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"StringStore.to_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Tokenizer.load\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/tokenizer#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Tokenizer.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/tokenizer#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Tokenizer.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Tagger.load\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/tagger#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Tagger.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/tagger#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Tagger.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Tagger.tag_names\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Tagger.labels\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"DependencyParser.load\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/dependencyparser#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"DependencyParser.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/dependencyparser#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"DependencyParser.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"EntityRecognizer.load\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/entityrecognizer#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"EntityRecognizer.from_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/entityrecognizer#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"EntityRecognizer.from_bytes\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Matcher.load\"\n              })\n            }), _jsx(_components.td, {\n              children: \"-\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"Matcher.add_pattern\"\n              }), \" \", _jsx(InlineCode, {\n                children: \"Matcher.add_entity\"\n              })]\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/matcher#add\",\n                children: _jsx(InlineCode, {\n                  children: \"Matcher.add\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/phrasematcher#add\",\n                children: _jsx(InlineCode, {\n                  children: \"PhraseMatcher.add\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Matcher.get_entity\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/matcher#get\",\n                children: _jsx(InlineCode, {\n                  children: \"Matcher.get\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Matcher.has_entity\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/matcher#has_key\",\n                children: _jsx(InlineCode, {\n                  children: \"Matcher.has_key\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Doc.read_bytes\"\n              })\n            }), _jsxs(_components.td, {\n              children: [_jsx(_components.a, {\n                href: \"/api/doc#to_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc.to_bytes\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/doc#from_bytes\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc.from_bytes\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/doc#to_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc.to_disk\"\n                })\n              }), \" \", _jsx(_components.a, {\n                href: \"/api/doc#from_disk\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc.from_disk\"\n                })\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Token.is_ancestor_of\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/token#is_ancestor\",\n                children: _jsx(InlineCode, {\n                  children: \"Token.is_ancestor\"\n                })\n              })\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"deprecated\",\n        children: \"Deprecated \"\n      }), _jsx(_components.p, {\n        children: \"The following methods are deprecated. They can still be used, but should be\\nreplaced.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Old\"\n            }), _jsx(_components.th, {\n              children: \"New\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Tokenizer.tokens_from_list\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/doc\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc\"\n                })\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"Span.sent_start\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"/api/span#is_sent_start\",\n                children: _jsx(InlineCode, {\n                  children: \"Span.is_sent_start\"\n                })\n              })\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-migrating\",\n      children: [_jsx(_components.h2, {\n        id: \"migrating\",\n        children: \"Migrating from spaCy 1.x \"\n      }), _jsxs(_components.p, {\n        children: [\"Because we’e made so many architectural changes to the library, we’ve tried to\\n\", _jsx(_components.strong, {\n          children: \"keep breaking changes to a minimum\"\n        }), \". A lot of projects follow the philosophy\\nthat if you’re going to break anything, you may as well break everything. We\\nthink migration is easier if there’s a logic to what has changed. We’ve\\ntherefore followed a policy of avoiding breaking changes to the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"Span\"\n        }), \"\\nand \", _jsx(InlineCode, {\n          children: \"Token\"\n        }), \" objects. This way, you can focus on only migrating the code that\\ndoes training, loading and serialization — in other words, code that works with\\nthe \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object directly. Code that uses the annotations should continue to\\nwork.\"]\n      }), _jsx(Infobox, {\n        title: \"Important note\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"If you’ve trained your own models, keep in mind that your train and runtime\\ninputs must match. This means you’ll have to \", _jsx(_components.strong, {\n            children: \"retrain your models\"\n          }), \" with spaCy\\nv2.0.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"migrating-document-processing\",\n        children: \"Document processing \"\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(_components.a, {\n          href: \"/api/language#pipe\",\n          children: _jsx(InlineCode, {\n            children: \"Language.pipe\"\n          })\n        }), \" method allows spaCy to batch\\ndocuments, which brings a \", _jsx(_components.strong, {\n          children: \"significant performance advantage\"\n        }), \" in v2.0. The new\\nneural networks introduce some overhead per batch, so if you’re processing a\\nnumber of documents in a row, you should use \", _jsx(InlineCode, {\n          children: \"nlp.pipe\"\n        }), \" and process the texts as\\na stream.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- docs = (nlp(text) for text in texts)\\n\\n+ docs = nlp.pipe(texts)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"To make usage easier, there’s now a boolean \", _jsx(InlineCode, {\n          children: \"as_tuples\"\n        }), \" keyword argument, that\\nlets you pass in an iterator of \", _jsx(InlineCode, {\n          children: \"(text, context)\"\n        }), \" pairs, so you can get back an\\niterator of \", _jsx(InlineCode, {\n          children: \"(doc, context)\"\n        }), \" tuples.\"]\n      }), _jsx(_components.h3, {\n        id: \"migrating-saving-loading\",\n        children: \"Saving, loading and serialization \"\n      }), _jsxs(_components.p, {\n        children: [\"Double-check all calls to \", _jsx(InlineCode, {\n          children: \"spacy.load()\"\n        }), \" and make sure they don’t use the \", _jsx(InlineCode, {\n          children: \"path\"\n        }), \"\\nkeyword argument. If you’re only loading in binary data and not a model package\\nthat can construct its own \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" class and pipeline, you should now use the\\n\", _jsx(_components.a, {\n          href: \"/api/language#from_disk\",\n          children: _jsx(InlineCode, {\n            children: \"Language.from_disk\"\n          })\n        }), \" method.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- nlp = spacy.load(\\\"en\\\", path=\\\"/model\\\")\\n\\n+ nlp = spacy.load(\\\"/model\\\")\\n+ nlp = spacy.blank(\\\"en\\\").from_disk(\\\"/model/data\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Review all other code that writes state to disk or bytes. All containers, now\\nshare the same, consistent API for saving and loading. Replace saving with\\n\", _jsx(InlineCode, {\n          children: \"to_disk()\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"to_bytes()\"\n        }), \", and loading with \", _jsx(InlineCode, {\n          children: \"from_disk()\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"from_bytes()\"\n        }), \".\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- nlp.save_to_directory(\\\"/model\\\")\\n- nlp.vocab.dump(\\\"/vocab\\\")\\n\\n+ nlp.to_disk(\\\"/model\\\")\\n+ nlp.vocab.to_disk(\\\"/vocab\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If you’ve trained models with input from v1.x, you’ll need to \", _jsx(_components.strong, {\n          children: \"retrain them\"\n        }), \"\\nwith spaCy v2.0. All previous models will not be compatible with the new\\nversion.\"]\n      }), _jsx(_components.h3, {\n        id: \"migrating-languages\",\n        children: \"Processing pipelines and language data \"\n      }), _jsxs(_components.p, {\n        children: [\"If you’re importing language data or \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" classes, make sure to change\\nyour import statements to import from \", _jsx(InlineCode, {\n          children: \"spacy.lang\"\n        }), \". If you’ve added your own\\ncustom language, it needs to be moved to \", _jsx(InlineCode, {\n          children: \"spacy/lang/xx\"\n        }), \" and adjusted\\naccordingly.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- from spacy.en import English\\n\\n+ from spacy.lang.en import English\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If you’ve been using custom pipeline components, check out the new guide on\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines\",\n          children: \"processing pipelines\"\n        }), \". Pipeline components are now\\n\", _jsx(InlineCode, {\n          children: \"(name, func)\"\n        }), \" tuples. Appending them to the pipeline still works – but the\\n\", _jsx(_components.a, {\n          href: \"/api/language#add_pipe\",\n          children: _jsx(InlineCode, {\n            children: \"add_pipe\"\n          })\n        }), \" method now makes this much more convenient.\\nMethods for removing, renaming, replacing and retrieving components have been\\nadded as well. Components can now be disabled by passing a list of their names\\nto the \", _jsx(InlineCode, {\n          children: \"disable\"\n        }), \" keyword argument on load, or by using\\n\", _jsx(_components.a, {\n          href: \"/api/language#disable_pipes\",\n          children: _jsx(InlineCode, {\n            children: \"disable_pipes\"\n          })\n        }), \" as a method or context manager:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- nlp = spacy.load(\\\"en_core_web_sm\\\", tagger=False, entity=False)\\n- doc = nlp(\\\"I don't want parsed\\\", parse=False)\\n\\n+ nlp = spacy.load(\\\"en_core_web_sm\\\", disable=[\\\"tagger\\\", \\\"ner\\\"])\\n+ with nlp.disable_pipes(\\\"parser\\\"):\\n+    doc = nlp(\\\"I don't want parsed\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"To add spaCy’s built-in pipeline components to your pipeline, you can still\\nimport and instantiate them directly – but it’s more convenient to use the new\\n\", _jsx(_components.a, {\n          href: \"/api/language#create_pipe\",\n          children: _jsx(InlineCode, {\n            children: \"create_pipe\"\n          })\n        }), \" method with the component name, i.e.\\n\", _jsx(InlineCode, {\n          children: \"'tagger'\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"'parser'\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"'ner'\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"'textcat'\"\n        }), \".\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- from spacy.pipeline import Tagger\\n- tagger = Tagger(nlp.vocab)\\n- nlp.pipeline.insert(0, tagger)\\n\\n+ tagger = nlp.create_pipe(\\\"tagger\\\")\\n+ nlp.add_pipe(tagger, first=True)\\n\"\n        })\n      }), _jsx(_components.h3, {\n        id: \"migrating-training\",\n        children: \"Training \"\n      }), _jsxs(_components.p, {\n        children: [\"All built-in pipeline components are now subclasses of \", _jsx(_components.a, {\n          href: \"/api/pipe\",\n          children: _jsx(InlineCode, {\n            children: \"Pipe\"\n          })\n        }), \",\\nfully trainable and serializable, and follow the same API. Instead of updating\\nthe model and telling spaCy when to \", _jsx(_components.em, {\n          children: \"stop\"\n        }), \", you can now explicitly call\\n\", _jsx(_components.a, {\n          href: \"/api/language#begin_training\",\n          children: _jsx(InlineCode, {\n            children: \"begin_training\"\n          })\n        }), \", which returns an optimizer you\\ncan pass into the \", _jsx(_components.a, {\n          href: \"/api/language#update\",\n          children: _jsx(InlineCode, {\n            children: \"update\"\n          })\n        }), \" function. While \", _jsx(InlineCode, {\n          children: \"update\"\n        }), \"\\nstill accepts sequences of \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"GoldParse\"\n        }), \" objects, you can now also pass\\nin a list of strings and dictionaries describing the annotations. We call this\\nthe \", _jsx(_components.a, {\n          href: \"/usage/training#training-simple-style\",\n          children: \"“simple training style”\"\n        }), \". This is\\nalso the recommended usage, as it removes one layer of abstraction from the\\ntraining.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- for itn in range(1000):\\n-     for text, entities in train_data:\\n-         doc = Doc(text)\\n-         gold = GoldParse(doc, entities=entities)\\n-         nlp.update(doc, gold)\\n- nlp.end_training()\\n- nlp.save_to_directory(\\\"/model\\\")\\n\\n+ nlp.begin_training()\\n+ for itn in range(1000):\\n+     for texts, annotations in train_data:\\n+         nlp.update(texts, annotations)\\n+ nlp.to_disk(\\\"/model\\\")\\n\"\n        })\n      }), _jsx(_components.h3, {\n        id: \"migrating-doc\",\n        children: \"Attaching custom data to the Doc \"\n      }), _jsxs(_components.p, {\n        children: [\"Previously, you had to create a new container in order to attach custom data to\\na \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" object. This often required converting the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects to and from\\narrays. In spaCy v2.0, you can set your own attributes, properties and methods\\non the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"Token\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"Span\"\n        }), \" via\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components-attributes\",\n          children: \"custom extensions\"\n        }), \".\\nThis means that your application can – and should – only pass around \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"\\nobjects and refer to them as the single source of truth.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- doc = nlp(\\\"This is a regular doc\\\")\\n- doc_array = doc.to_array([\\\"ORTH\\\", \\\"POS\\\"])\\n- doc_with_meta = {\\\"doc_array\\\": doc_array, \\\"meta\\\": get_doc_meta(doc_array)}\\n\\n+ Doc.set_extension(\\\"meta\\\", getter=get_doc_meta)\\n+ doc_with_meta = nlp(u'This is a doc with meta data')\\n+ meta = doc._.meta\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If you wrap your extension attributes in a\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components\",\n          children: \"custom pipeline component\"\n        }), \", they\\nwill be assigned automatically when you call \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" on a text. If your\\napplication assigns custom data to spaCy’s container objects, or includes other\\nutilities that interact with the pipeline, consider moving this logic into its\\nown extension module.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- doc = nlp(\\\"Doc with a standard pipeline\\\")\\n- meta = get_meta(doc)\\n\\n+ nlp.add_pipe(meta_component)\\n+ doc = nlp(\\\"Doc with a custom pipeline that assigns meta\\\")\\n+ meta = doc._.meta\\n\"\n        })\n      }), _jsx(_components.h3, {\n        id: \"migrating-strings\",\n        children: \"Strings and hash values \"\n      }), _jsxs(_components.p, {\n        children: [\"The change from integer IDs to hash values may not actually affect your code\\nvery much. However, if you’re adding strings to the vocab manually, you now need\\nto call \", _jsx(_components.a, {\n          href: \"/api/stringstore#add\",\n          children: _jsx(InlineCode, {\n            children: \"StringStore.add\"\n          })\n        }), \" explicitly. You can also now\\nbe sure that the string-to-hash mapping will always match across vocabularies.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- nlp.vocab.strings[\\\"coffee\\\"]       # 3672\\n- other_nlp.vocab.strings[\\\"coffee\\\"] # 40259\\n\\n+ nlp.vocab.strings.add(\\\"coffee\\\")\\n+ nlp.vocab.strings[\\\"coffee\\\"]       # 3197928453018144401\\n+ other_nlp.vocab.strings[\\\"coffee\\\"] # 3197928453018144401\\n\"\n        })\n      }), _jsx(_components.h3, {\n        id: \"migrating-matcher\",\n        children: \"Adding patterns and callbacks to the matcher \"\n      }), _jsxs(_components.p, {\n        children: [\"If you’re using the matcher, you can now add patterns in one step. This should\\nbe easy to update – simply merge the ID, callback and patterns into one call to\\n\", _jsx(_components.a, {\n          href: \"/api/matcher#add\",\n          children: _jsx(InlineCode, {\n            children: \"Matcher.add()\"\n          })\n        }), \". The matcher now also supports string keys,\\nwhich saves you an extra import. If you’ve been using \", _jsx(_components.strong, {\n          children: \"acceptor functions\"\n        }), \",\\nyou’ll need to move this logic into the\\n\", _jsxs(_components.a, {\n          href: \"/usage/linguistic-features#on_match\",\n          children: [_jsx(InlineCode, {\n            children: \"on_match\"\n          }), \" callbacks\"]\n        }), \". The callback\\nfunction is invoked on every match and will give you access to the doc, the\\nindex of the current match and all total matches. This lets you both accept or\\nreject the match, and define the actions to be triggered.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- matcher.add_entity(\\\"GoogleNow\\\", on_match=merge_phrases)\\n- matcher.add_pattern(\\\"GoogleNow\\\", [{ORTH: \\\"Google\\\"}, {ORTH: \\\"Now\\\"}])\\n\\n+ matcher.add(\\\"GoogleNow\\\", merge_phrases, [{\\\"ORTH\\\": \\\"Google\\\"}, {\\\"ORTH\\\": \\\"Now\\\"}])\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If you need to match large terminology lists, you can now also use the\\n\", _jsx(_components.a, {\n          href: \"/api/phrasematcher\",\n          children: _jsx(InlineCode, {\n            children: \"PhraseMatcher\"\n          })\n        }), \", which accepts \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects as match\\npatterns and is more efficient than the regular, rule-based matcher.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- matcher = Matcher(nlp.vocab)\\n- matcher.add_entity(\\\"PRODUCT\\\")\\n- for text in large_terminology_list\\n-     matcher.add_pattern(\\\"PRODUCT\\\", [{ORTH: text}])\\n\\n+ from spacy.matcher import PhraseMatcher\\n+ matcher = PhraseMatcher(nlp.vocab)\\n+ patterns = [nlp.make_doc(text) for text in large_terminology_list]\\n+ matcher.add(\\\"PRODUCT\\\", None, *patterns)\\n\"\n        })\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"What's New in v2.0","teaser":"New features, backwards incompatibilities and migration guide","menu":[["Summary","summary"],["New Features","features"],["Backwards Incompatibilities","incompat"],["Migrating from v1.x","migrating"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":null},"__N_SSG":true}