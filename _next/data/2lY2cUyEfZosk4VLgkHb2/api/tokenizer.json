{"pageProps":{"title":"Tokenizer","teaser":"Segment text into words, punctuations marks, etc.","tag":"class","source":"spacy/tokenizer.pyx","slug":"/api/tokenizer","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    pre: \"pre\",\n    code: \"code\",\n    p: \"p\",\n    a: \"a\",\n    h2: \"h2\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    del: \"del\",\n    strong: \"strong\",\n    em: \"em\"\n  }, _provideComponents(), props.components), {InlineCode, Tag} = _components;\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  if (!Tag) _missingMdxReference(\"Tag\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      children: [_jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Default config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[nlp.tokenizer]\\n@tokenizers = \\\"spacy.Tokenizer.v1\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Segment text, and create \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects with the discovered segment boundaries.\\nFor a deeper understanding, see the docs on\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#how-tokenizer-works\",\n          children: \"how spaCyâ€™s tokenizer works\"\n        }), \".\\nThe tokenizer is typically created automatically when a\\n\", _jsx(_components.a, {\n          href: \"/api/language\",\n          children: _jsx(InlineCode, {\n            children: \"Language\"\n          })\n        }), \" subclass is initialized and it reads its settings\\nlike punctuation and special case rules from the\\n\", _jsx(_components.a, {\n          href: \"/api/language#defaults\",\n          children: _jsx(InlineCode, {\n            children: \"Language.Defaults\"\n          })\n        }), \" provided by the language subclass.\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-init\",\n      children: [_jsx(_components.h2, {\n        id: \"init\",\n        tag: \"method\",\n        children: \"Tokenizer.__init__ \"\n      }), _jsxs(_components.p, {\n        children: [\"Create a \", _jsx(InlineCode, {\n          children: \"Tokenizer\"\n        }), \" to create \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects given unicode text. For examples of\\nhow to construct a custom tokenizer with different tokenization rules, see the\\n\", _jsx(_components.a, {\n          href: \"https://spacy.io/usage/linguistic-features#native-tokenizers\",\n          children: \"usage documentation\"\n        }), \".\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"# Construction 1\\nfrom spacy.tokenizer import Tokenizer\\nfrom spacy.lang.en import English\\nnlp = English()\\n# Create a blank Tokenizer with just the English vocab\\ntokenizer = Tokenizer(nlp.vocab)\\n\\n# Construction 2\\nfrom spacy.lang.en import English\\nnlp = English()\\n# Create a Tokenizer with the default settings for English\\n# including punctuation rules and exceptions\\ntokenizer = nlp.tokenizer\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"vocab\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A storage container for lexical types. \", _jsx(_components.del, {\n                children: \"Vocab\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"rules\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Exceptions and special-cases for the tokenizer. \", _jsx(_components.del, {\n                children: \"Optional[Dict[str, List[Dict[int, str]]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"prefix_search\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).search\"\n              }), \" to match prefixes. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"suffix_search\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).search\"\n              }), \" to match suffixes. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"infix_finditer\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).finditer\"\n              }), \" to find infixes. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Iterator[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"token_match\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).match\"\n              }), \" to find token matches. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"url_match\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).match\"\n              }), \" to find token matches after considering prefixes and suffixes. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(InlineCode, {\n                children: \"faster_heuristics\"\n              }), \" \", _jsx(Tag, {\n                variant: \"new\",\n                children: \"3.3.0\"\n              })]\n            }), _jsxs(_components.td, {\n              children: [\"Whether to restrict the final \", _jsx(InlineCode, {\n                children: \"Matcher\"\n              }), \"-based pass for rules to those containing affixes or space. Defaults to \", _jsx(InlineCode, {\n                children: \"True\"\n              }), \". \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-call\",\n      children: [_jsx(_components.h2, {\n        id: \"call\",\n        tag: \"method\",\n        children: \"Tokenizer.__call__ \"\n      }), _jsx(_components.p, {\n        children: \"Tokenize a string.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tokens = tokenizer(\\\"This is a sentence\\\")\\nassert len(tokens) == 4\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to tokenize. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A container for linguistic annotations. \", _jsx(_components.del, {\n                children: \"Doc\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-pipe\",\n      children: [_jsx(_components.h2, {\n        id: \"pipe\",\n        tag: \"method\",\n        children: \"Tokenizer.pipe \"\n      }), _jsx(_components.p, {\n        children: \"Tokenize a stream of texts.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"texts = [\\\"One document.\\\", \\\"...\\\", \\\"Lots of documents\\\"]\\nfor doc in tokenizer.pipe(texts, batch_size=50):\\n    pass\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"texts\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A sequence of unicode texts. \", _jsx(_components.del, {\n                children: \"Iterable[str]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"batch_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of texts to accumulate in an internal buffer. Defaults to \", _jsx(InlineCode, {\n                children: \"1000\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"YIELDS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The tokenized \", _jsx(InlineCode, {\n                children: \"Doc\"\n              }), \" objects, in order. \", _jsx(_components.del, {\n                children: \"Doc\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-find_infix\",\n      children: [_jsx(_components.h2, {\n        id: \"find_infix\",\n        tag: \"method\",\n        children: \"Tokenizer.find_infix \"\n      }), _jsx(_components.p, {\n        children: \"Find internal split points of the string.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to split. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A list of \", _jsx(InlineCode, {\n                children: \"re.MatchObject\"\n              }), \" objects that have \", _jsx(InlineCode, {\n                children: \".start()\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \".end()\"\n              }), \" methods, denoting the placement of internal segment separators, e.g. hyphens. \", _jsx(_components.del, {\n                children: \"List[Match]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-find_prefix\",\n      children: [_jsx(_components.h2, {\n        id: \"find_prefix\",\n        tag: \"method\",\n        children: \"Tokenizer.find_prefix \"\n      }), _jsxs(_components.p, {\n        children: [\"Find the length of a prefix that should be segmented from the string, or \", _jsx(InlineCode, {\n          children: \"None\"\n        }), \"\\nif no prefix rules match.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to segment. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The length of the prefix if present, otherwise \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-find_suffix\",\n      children: [_jsx(_components.h2, {\n        id: \"find_suffix\",\n        tag: \"method\",\n        children: \"Tokenizer.find_suffix \"\n      }), _jsxs(_components.p, {\n        children: [\"Find the length of a suffix that should be segmented from the string, or \", _jsx(InlineCode, {\n          children: \"None\"\n        }), \"\\nif no suffix rules match.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to segment. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The length of the suffix if present, otherwise \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-add_special_case\",\n      children: [_jsx(_components.h2, {\n        id: \"add_special_case\",\n        tag: \"method\",\n        children: \"Tokenizer.add_special_case \"\n      }), _jsxs(_components.p, {\n        children: [\"Add a special-case tokenization rule. This mechanism is also used to add custom\\ntokenizer exceptions to the language data. See the usage guide on the\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#language-data\",\n          children: \"languages data\"\n        }), \" and\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#special-cases\",\n          children: \"tokenizer special cases\"\n        }), \" for more\\ndetails and examples.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy.attrs import ORTH, NORM\\ncase = [{ORTH: \\\"do\\\"}, {ORTH: \\\"n't\\\", NORM: \\\"not\\\"}]\\ntokenizer.add_special_case(\\\"don't\\\", case)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to specially tokenize. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"token_attrs\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A sequence of dicts, where each dict describes a token and its attributes. The \", _jsx(InlineCode, {\n                children: \"ORTH\"\n              }), \" fields of the attributes must exactly match the string when they are concatenated. \", _jsx(_components.del, {\n                children: \"Iterable[Dict[int, str]]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-explain\",\n      children: [_jsx(_components.h2, {\n        id: \"explain\",\n        tag: \"method\",\n        children: \"Tokenizer.explain \"\n      }), _jsxs(_components.p, {\n        children: [\"Tokenize a string with a slow debugging tokenizer that provides information\\nabout which tokenizer rule or pattern was matched for each token. The tokens\\nproduced are identical to \", _jsx(InlineCode, {\n          children: \"Tokenizer.__call__\"\n        }), \" except for whitespace tokens.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tok_exp = nlp.tokenizer.explain(\\\"(don't)\\\")\\nassert [t[0] for t in tok_exp] == [\\\"PREFIX\\\", \\\"SPECIAL-1\\\", \\\"SPECIAL-2\\\", \\\"SUFFIX\\\"]\\nassert [t[1] for t in tok_exp] == [\\\"(\\\", \\\"do\\\", \\\"n't\\\", \\\")\\\"]\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"string\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The string to tokenize with the debugging tokenizer. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A list of \", _jsx(InlineCode, {\n                children: \"(pattern_string, token_string)\"\n              }), \" tuples. \", _jsx(_components.del, {\n                children: \"List[Tuple[str, str]]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-to_disk\",\n      children: [_jsx(_components.h2, {\n        id: \"to_disk\",\n        tag: \"method\",\n        children: \"Tokenizer.to_disk \"\n      }), _jsx(_components.p, {\n        children: \"Serialize the tokenizer to disk.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tokenizer = Tokenizer(nlp.vocab)\\ntokenizer.to_disk(\\\"/path/to/tokenizer\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"path\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A path to a directory, which will be created if it doesnâ€™t exist. Paths may be either strings or \", _jsx(InlineCode, {\n                children: \"Path\"\n              }), \"-like objects. \", _jsx(_components.del, {\n                children: \"Union[str, Path]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.em, {\n                children: \"keyword-only\"\n              })\n            }), _jsx(_components.td, {})]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclude\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"String names of \", _jsx(_components.a, {\n                href: \"#serialization-fields\",\n                children: \"serialization fields\"\n              }), \" to exclude. \", _jsx(_components.del, {\n                children: \"Iterable[str]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-from_disk\",\n      children: [_jsx(_components.h2, {\n        id: \"from_disk\",\n        tag: \"method\",\n        children: \"Tokenizer.from_disk \"\n      }), _jsx(_components.p, {\n        children: \"Load the tokenizer from disk. Modifies the object in place and returns it.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tokenizer = Tokenizer(nlp.vocab)\\ntokenizer.from_disk(\\\"/path/to/tokenizer\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"path\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A path to a directory. Paths may be either strings or \", _jsx(InlineCode, {\n                children: \"Path\"\n              }), \"-like objects. \", _jsx(_components.del, {\n                children: \"Union[str, Path]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.em, {\n                children: \"keyword-only\"\n              })\n            }), _jsx(_components.td, {})]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclude\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"String names of \", _jsx(_components.a, {\n                href: \"#serialization-fields\",\n                children: \"serialization fields\"\n              }), \" to exclude. \", _jsx(_components.del, {\n                children: \"Iterable[str]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The modified \", _jsx(InlineCode, {\n                children: \"Tokenizer\"\n              }), \" object. \", _jsx(_components.del, {\n                children: \"Tokenizer\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-to_bytes\",\n      children: [_jsx(_components.h2, {\n        id: \"to_bytes\",\n        tag: \"method\",\n        children: \"Tokenizer.to_bytes \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tokenizer = tokenizer(nlp.vocab)\\ntokenizer_bytes = tokenizer.to_bytes()\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"Serialize the tokenizer to a bytestring.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.em, {\n                children: \"keyword-only\"\n              })\n            }), _jsx(_components.td, {})]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclude\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"String names of \", _jsx(_components.a, {\n                href: \"#serialization-fields\",\n                children: \"serialization fields\"\n              }), \" to exclude. \", _jsx(_components.del, {\n                children: \"Iterable[str]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The serialized form of the \", _jsx(InlineCode, {\n                children: \"Tokenizer\"\n              }), \" object. \", _jsx(_components.del, {\n                children: \"bytes\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-from_bytes\",\n      children: [_jsx(_components.h2, {\n        id: \"from_bytes\",\n        tag: \"method\",\n        children: \"Tokenizer.from_bytes \"\n      }), _jsx(_components.p, {\n        children: \"Load the tokenizer from a bytestring. Modifies the object in place and returns\\nit.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"tokenizer_bytes = tokenizer.to_bytes()\\ntokenizer = Tokenizer(nlp.vocab)\\ntokenizer.from_bytes(tokenizer_bytes)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"bytes_data\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The data to load from. \", _jsx(_components.del, {\n                children: \"bytes\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.em, {\n                children: \"keyword-only\"\n              })\n            }), _jsx(_components.td, {})]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclude\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"String names of \", _jsx(_components.a, {\n                href: \"#serialization-fields\",\n                children: \"serialization fields\"\n              }), \" to exclude. \", _jsx(_components.del, {\n                children: \"Iterable[str]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"RETURNS\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(InlineCode, {\n                children: \"Tokenizer\"\n              }), \" object. \", _jsx(_components.del, {\n                children: \"Tokenizer\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-attributes\",\n      children: [_jsx(_components.h2, {\n        id: \"attributes\",\n        children: \"Attributes \"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"vocab\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The vocab object of the parent \", _jsx(InlineCode, {\n                children: \"Doc\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Vocab\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"prefix_search\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function to find segment boundaries from the start of a string. Returns the length of the segment, or \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"suffix_search\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function to find segment boundaries from the end of a string. Returns the length of the segment, or \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"infix_finditer\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function to find internal segment separators, e.g. hyphens. Returns a (possibly empty) sequence of \", _jsx(InlineCode, {\n                children: \"re.MatchObject\"\n              }), \" objects. \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Iterator[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"token_match\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A function matching the signature of \", _jsx(InlineCode, {\n                children: \"re.compile(string).match\"\n              }), \" to find token matches. Returns an \", _jsx(InlineCode, {\n                children: \"re.MatchObject\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[Callable[[str], Optional[Match]]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"rules\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A dictionary of tokenizer exceptions and special cases. \", _jsx(_components.del, {\n                children: \"Optional[Dict[str, List[Dict[int, str]]]]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-serialization-fields\",\n      children: [_jsx(_components.h2, {\n        id: \"serialization-fields\",\n        children: \"Serialization fields \"\n      }), _jsxs(_components.p, {\n        children: [\"During serialization, spaCy will export several data fields used to restore\\ndifferent aspects of the object. If needed, you can exclude them from\\nserialization by passing in the string names via the \", _jsx(InlineCode, {\n          children: \"exclude\"\n        }), \" argument.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"data = tokenizer.to_bytes(exclude=[\\\"vocab\\\", \\\"exceptions\\\"])\\ntokenizer.from_disk(\\\"./data\\\", exclude=[\\\"token_match\\\"])\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"vocab\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The shared \", _jsx(_components.a, {\n                href: \"/api/vocab\",\n                children: _jsx(InlineCode, {\n                  children: \"Vocab\"\n                })\n              }), \".\"]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"prefix_search\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The prefix rules.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"suffix_search\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The suffix rules.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"infix_finditer\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The infix rules.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"token_match\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The token match expression.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exceptions\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The tokenizer exception rules.\"\n            })]\n          })]\n        })]\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"Tokenizer","teaser":"Segment text into words, punctuations marks, etc.","tag":"class","source":"spacy/tokenizer.pyx"},"scope":{}},"sectionTitle":"API Documentation","theme":"green","section":"api","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":null},"__N_SSG":true}