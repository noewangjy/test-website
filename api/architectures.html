<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="shortcut icon" href="/icons/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=5.0, shrink-to-fit=no, viewport-fit=cover"/><meta name="theme-color" content="#09a3d5"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png"/><title>Model Architectures · spaCy API Documentation</title><meta name="description" content="Pre-defined model architectures included with the core library"/><meta property="og:title" content="Model Architectures · spaCy API Documentation"/><meta property="og:description" content="Pre-defined model architectures included with the core library"/><meta property="og:type" content="website"/><meta property="og:site_name" content="Model Architectures"/><meta property="og:image" content="[object Object]"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:image" content="[object Object]"/><meta name="twitter:creator" content="@spacy_io"/><meta name="twitter:site" content="@spacy_io"/><meta name="twitter:title" content="Model Architectures · spaCy API Documentation"/><meta name="twitter:description" content="Pre-defined model architectures included with the core library"/><meta name="docsearch:language" content="en"/><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/8f0b94edbc18d62d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f0b94edbc18d62d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e6995e0e8addcf99.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e6995e0e8addcf99.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/262.c647d33d06232ef6.js"></script><script defer="" src="/_next/static/chunks/728.cf6ba0da2700fa1b.js"></script><script src="/_next/static/chunks/webpack-8161fc2bb14cec39.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-a0f603ce323043fd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb3ea1261af64e73.js" defer=""></script><script src="/_next/static/chunks/94-57434c8b7a6c3878.js" defer=""></script><script src="/_next/static/chunks/128-76b45627a109219b.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...listPathPage%5D-45eea57fe8c2902c.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_buildManifest.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_ssgManifest.js" defer=""></script></head><body class="theme-blue"><div id="__next"><div class="theme-green"><nav class="navigation_root__yPL8O"><span class="navigation_has-alert__s0Drf"><a class="link_root__1Me7D link_no-link-layout__RPvod" aria-label="spaCy" href="/"><h1 class="navigation_title__pm49s">spaCy</h1></a> <span class="navigation_alert__ZOXon"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage/v3-5"><strong>💥 Out now:</strong> spaCy v3.5</a></span></span><div class="navigation_menu__ZMJxN"><select class="dropdown_root__3uiQq navigation_dropdown__4j4pI"><option value="title" disabled="">Menu</option><option value="/usage">Usage</option><option value="/models">Models</option><option value="/api" selected="">API</option><option value="/universe">Universe</option></select><ul class="navigation_list__DCzqi"><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage">Usage</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li class="navigation_item__ln1O1 navigation_is-active__RjVJG"><a class="link_root__1Me7D link_no-link-layout__RPvod" tabindex="-1" href="/api">API</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li class="navigation_item__ln1O1 navigation_github__MpFNv"><span><a href="https://github.com/explosion/spaCy" data-size="large" data-show-count="true" aria-label="Star spaCy on GitHub"></a></span></li></ul><div class="navigation_search__BKZCn"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div><progress class="progress_root__9huWN" value="0" max="100"></progress></nav><menu class="sidebar sidebar_root__s2No7"><h1 hidden="" aria-hidden="true" class="h0 sidebar_active-heading___dkf9">Overview</h1><div class="sidebar_dropdown__vyqjz"><select class="dropdown_root__3uiQq sidebar_dropdown-select__Nwbq9"><option disabled="">Select page...</option><option value="/api">Overview<!-- --> › <!-- -->Library Architecture</option><option value="/api/architectures" selected="">Overview<!-- --> › <!-- -->Model Architectures</option><option value="/api/data-formats">Overview<!-- --> › <!-- -->Data Formats</option><option value="/api/cli">Overview<!-- --> › <!-- -->Command Line</option><option value="/api/top-level">Overview<!-- --> › <!-- -->Functions</option><option value="/api/doc">Containers<!-- --> › <!-- -->Doc</option><option value="/api/docbin">Containers<!-- --> › <!-- -->DocBin</option><option value="/api/example">Containers<!-- --> › <!-- -->Example</option><option value="/api/language">Containers<!-- --> › <!-- -->Language</option><option value="/api/lexeme">Containers<!-- --> › <!-- -->Lexeme</option><option value="/api/span">Containers<!-- --> › <!-- -->Span</option><option value="/api/spangroup">Containers<!-- --> › <!-- -->SpanGroup</option><option value="/api/token">Containers<!-- --> › <!-- -->Token</option><option value="/api/attributeruler">Pipeline<!-- --> › <!-- -->AttributeRuler</option><option value="/api/coref">Pipeline<!-- --> › <!-- -->CoreferenceResolver</option><option value="/api/dependencyparser">Pipeline<!-- --> › <!-- -->DependencyParser</option><option value="/api/edittreelemmatizer">Pipeline<!-- --> › <!-- -->EditTreeLemmatizer</option><option value="/api/entitylinker">Pipeline<!-- --> › <!-- -->EntityLinker</option><option value="/api/entityrecognizer">Pipeline<!-- --> › <!-- -->EntityRecognizer</option><option value="/api/entityruler">Pipeline<!-- --> › <!-- -->EntityRuler</option><option value="/api/lemmatizer">Pipeline<!-- --> › <!-- -->Lemmatizer</option><option value="/api/morphologizer">Pipeline<!-- --> › <!-- -->Morphologizer</option><option value="/api/sentencerecognizer">Pipeline<!-- --> › <!-- -->SentenceRecognizer</option><option value="/api/sentencizer">Pipeline<!-- --> › <!-- -->Sentencizer</option><option value="/api/spancategorizer">Pipeline<!-- --> › <!-- -->SpanCategorizer</option><option value="/api/span-resolver">Pipeline<!-- --> › <!-- -->SpanResolver</option><option value="/api/spanruler">Pipeline<!-- --> › <!-- -->SpanRuler</option><option value="/api/tagger">Pipeline<!-- --> › <!-- -->Tagger</option><option value="/api/textcategorizer">Pipeline<!-- --> › <!-- -->TextCategorizer</option><option value="/api/tok2vec">Pipeline<!-- --> › <!-- -->Tok2Vec</option><option value="/api/tokenizer">Pipeline<!-- --> › <!-- -->Tokenizer</option><option value="/api/pipe">Pipeline<!-- --> › <!-- -->TrainablePipe</option><option value="/api/transformer">Pipeline<!-- --> › <!-- -->Transformer</option><option value="/api/pipeline-functions">Pipeline<!-- --> › <!-- -->Other Functions</option><option value="/api/dependencymatcher">Matchers<!-- --> › <!-- -->DependencyMatcher</option><option value="/api/matcher">Matchers<!-- --> › <!-- -->Matcher</option><option value="/api/phrasematcher">Matchers<!-- --> › <!-- -->PhraseMatcher</option><option value="/api/attributes">Other<!-- --> › <!-- -->Attributes</option><option value="/api/corpus">Other<!-- --> › <!-- -->Corpus</option><option value="/api/inmemorylookupkb">Other<!-- --> › <!-- -->InMemoryLookupKB</option><option value="/api/kb">Other<!-- --> › <!-- -->KnowledgeBase</option><option value="/api/lookups">Other<!-- --> › <!-- -->Lookups</option><option value="/api/morphology#morphanalysis">Other<!-- --> › <!-- -->MorphAnalysis</option><option value="/api/morphology">Other<!-- --> › <!-- -->Morphology</option><option value="/api/scorer">Other<!-- --> › <!-- -->Scorer</option><option value="/api/stringstore">Other<!-- --> › <!-- -->StringStore</option><option value="/api/vectors">Other<!-- --> › <!-- -->Vectors</option><option value="/api/vocab">Other<!-- --> › <!-- -->Vocab</option><option value="/api/cython">Cython<!-- --> › <!-- -->Architecture</option><option value="/api/cython-classes">Cython<!-- --> › <!-- -->Classes</option><option value="/api/cython-structs">Cython<!-- --> › <!-- -->Structs</option><option value="/api/legacy">Legacy<!-- --> › <!-- -->Legacy functions</option></select></div><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Overview</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api">Library Architecture</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP sidebar_is-active__yVTtL is-active" href="/api/architectures">Model Architectures</a><ul class="sidebar_crumbs__NhM2y"><li class="sidebar_crumb__tiiDl sidebar_crumb-active__zq8BI"><a href="#tok2vec-arch">Tok2Vec</a></li><li class="sidebar_crumb__tiiDl"><a href="#transformers">Transformers</a></li><li class="sidebar_crumb__tiiDl"><a href="#pretrain">Pretraining</a></li><li class="sidebar_crumb__tiiDl"><a href="#parser">Parser &amp; NER</a></li><li class="sidebar_crumb__tiiDl"><a href="#tagger">Tagging</a></li><li class="sidebar_crumb__tiiDl"><a href="#textcat">Text Classification</a></li><li class="sidebar_crumb__tiiDl"><a href="#spancat">Span Classification</a></li><li class="sidebar_crumb__tiiDl"><a href="#entitylinker">Entity Linking</a></li><li class="sidebar_crumb__tiiDl"><a href="#coref-architectures">Coreference</a></li></ul></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/data-formats">Data Formats</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/cli">Command Line</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/top-level">Functions</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Containers</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/doc">Doc</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/docbin">DocBin</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/example">Example</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/language">Language</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/lexeme">Lexeme</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/span">Span</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/spangroup">SpanGroup</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/token">Token</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Pipeline</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/attributeruler">AttributeRuler</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/coref">CoreferenceResolver</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/dependencyparser">DependencyParser</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/edittreelemmatizer">EditTreeLemmatizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/entitylinker">EntityLinker</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/entityrecognizer">EntityRecognizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/entityruler">EntityRuler</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/lemmatizer">Lemmatizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/morphologizer">Morphologizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/sentencerecognizer">SentenceRecognizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/sentencizer">Sentencizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/spancategorizer">SpanCategorizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/span-resolver">SpanResolver</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/spanruler">SpanRuler</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/tagger">Tagger</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/textcategorizer">TextCategorizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/tok2vec">Tok2Vec</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/tokenizer">Tokenizer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/pipe">TrainablePipe</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/transformer">Transformer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/pipeline-functions">Other Functions</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Matchers</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/dependencymatcher">DependencyMatcher</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/matcher">Matcher</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/phrasematcher">PhraseMatcher</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Other</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/attributes">Attributes</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/corpus">Corpus</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/inmemorylookupkb">InMemoryLookupKB</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/kb">KnowledgeBase</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/lookups">Lookups</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/morphology#morphanalysis">MorphAnalysis</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/morphology">Morphology</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/scorer">Scorer</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/stringstore">StringStore</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/vectors">Vectors</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/vocab">Vocab</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Cython</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/cython">Architecture</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/cython-classes">Classes</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/cython-structs">Structs</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Legacy</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/api/legacy">Legacy functions</a></li></ul></menu><main class="main_root__7f6Tj main_with-sidebar__uH1df main_with-asides__ikQT6"><article class="main_content__8zFCH"><header class="title_root__pS2WQ"><div class="title_corner__S0Hac"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models">Source</a></div><h1 id="_title" class="typography_heading__D82WZ typography_h1__b7dt9 title_h1__l3CW1"><span class="heading-text">Model Architectures<!-- --> </span></h1><div class="heading-teaser title_teaser__QhwCH">Pre-defined model architectures included with the core library</div></header><section class="section_root__k1hUl"><p>A <strong>model architecture</strong> is a function that wires up a
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model"><code class="code_inline-code__Bq7ot">Model</code></a> instance, which you can then use in a
pipeline component or as a layer of a larger network. This page documents
spaCy’s built-in architectures that are used for different NLP tasks. All
trainable <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api#architecture-pipeline"><span class="link_source-text__VDP74">built-in components</span></a> expect a <code class="code_inline-code__Bq7ot">model</code>
argument defined in the config and document their the default architecture.
Custom architectures can be registered using the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/top-level#registry"><code class="code_inline-code__Bq7ot">@spacy.registry.architectures</code></a> decorator and used as
part of the <a class="link_root__1Me7D" href="/usage/training#custom-functions">training config</a>. Also see the
usage documentation on
<a class="link_root__1Me7D" href="/usage/layers-architectures">layers and model architectures</a>.</p></section>
<section id="section-tok2vec-arch" class="section_root__k1hUl"><h2 id="tok2vec-arch" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#tok2vec-arch" class="heading-text typography_permalink__UiIRy">Tok2Vec architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/tok2vec.py">Source</a></div></h2><h3 id="Tok2Vec" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#Tok2Vec" class="heading-text typography_permalink__UiIRy">spacy.Tok2Vec.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Construct a tok2vec model out of two subnetworks: one for embedding and one for
encoding. See the
<a class="link_root__1Me7D" href="https://explosion.ai/blog/deep-learning-formula-nlp">“Embed, Encode, Attend, Predict”</a>
blog post for background.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">embed</code></td><td class="table_td__rmpJx">Embed tokens into context-independent word vector representations. For example, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#CharacterEmbed"><span class="link_source-text__VDP74">CharacterEmbed</span></a> or <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#MultiHashEmbed"><span class="link_source-text__VDP74">MultiHashEmbed</span></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">encode</code></td><td class="table_td__rmpJx">Encode context into the embeddings, using an architecture such as a CNN, BiLSTM or transformer. For example, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#MaxoutWindowEncoder"><span class="link_source-text__VDP74">MaxoutWindowEncoder</span></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="HashEmbedCNN" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#HashEmbedCNN" class="heading-text typography_permalink__UiIRy">spacy.HashEmbedCNN.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Build spaCy’s “standard” tok2vec layer. This layer is defined by a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#MultiHashEmbed"><span class="link_source-text__VDP74">MultiHashEmbed</span></a> embedding layer that uses
subword features, and a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#MaxoutWindowEncoder"><span class="link_source-text__VDP74">MaxoutWindowEncoder</span></a> encoding layer
consisting of a CNN and a layer-normalized maxout activation function.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The width of the input and output. These are required to be the same, so that residual connections can be used. Recommended values are <code class="code_inline-code__Bq7ot">96</code>, <code class="code_inline-code__Bq7ot">128</code> or <code class="code_inline-code__Bq7ot">300</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">depth</code></td><td class="table_td__rmpJx">The number of convolutional layers to use. Recommended values are between <code class="code_inline-code__Bq7ot">2</code> and <code class="code_inline-code__Bq7ot">8</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">embed_size</code></td><td class="table_td__rmpJx">The number of rows in the hash embedding tables. This can be surprisingly small, due to the use of the hash embeddings. Recommended values are between <code class="code_inline-code__Bq7ot">2000</code> and <code class="code_inline-code__Bq7ot">10000</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">window_size</code></td><td class="table_td__rmpJx">The number of tokens on either side to concatenate during the convolutions. The receptive field of the CNN will be <code class="code_inline-code__Bq7ot">depth * (window_size * 2 + 1)</code>, so a 4-layer network with a window size of <code class="code_inline-code__Bq7ot">2</code> will be sensitive to 20 words at a time. Recommended value is <code class="code_inline-code__Bq7ot">1</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">maxout_pieces</code></td><td class="table_td__rmpJx">The number of pieces to use in the maxout non-linearity. If <code class="code_inline-code__Bq7ot">1</code>, the <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#mish"><code class="code_inline-code__Bq7ot">Mish</code></a> non-linearity is used instead. Recommended values are <code class="code_inline-code__Bq7ot">1</code>-<code class="code_inline-code__Bq7ot">3</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">subword_features</code></td><td class="table_td__rmpJx">Whether to also embed subword features, specifically the prefix, suffix and word shape. This is recommended for alphabetic languages like English, but not if single-character tokens are used for a language such as Chinese. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pretrained_vectors</code></td><td class="table_td__rmpJx">Whether to also use static vectors. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="Tok2VecListener" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#Tok2VecListener" class="heading-text typography_permalink__UiIRy">spacy.Tok2VecListener.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>A listener is used as a sublayer within a component such as a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/dependencyparser"><code class="code_inline-code__Bq7ot">DependencyParser</code></a>,
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityrecognizer"><code class="code_inline-code__Bq7ot">EntityRecognizer</code></a>or
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a>. Usually you’ll have multiple
listeners connecting to a single upstream <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tok2vec"><code class="code_inline-code__Bq7ot">Tok2Vec</code></a> component
that’s earlier in the pipeline. The listener layers act as <strong>proxies</strong>, passing
the predictions from the <code class="code_inline-code__Bq7ot">Tok2Vec</code> component into downstream components, and
communicating gradients back upstream.</p><p>Instead of defining its own <code class="code_inline-code__Bq7ot">Tok2Vec</code> instance, a model architecture like
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#tagger"><span class="link_source-text__VDP74">Tagger</span></a> can define a listener as its <code class="code_inline-code__Bq7ot">tok2vec</code>
argument that connects to the shared <code class="code_inline-code__Bq7ot">tok2vec</code> component in the pipeline.</p><p>Listeners work by caching the <code class="code_inline-code__Bq7ot">Tok2Vec</code> output for a given batch of <code class="code_inline-code__Bq7ot">Doc</code>s. This
means that in order for a component to work with the listener, the batch of
<code class="code_inline-code__Bq7ot">Doc</code>s passed to the listener must be the same as the batch of <code class="code_inline-code__Bq7ot">Doc</code>s passed to
the <code class="code_inline-code__Bq7ot">Tok2Vec</code>. As a result, any manipulation of the <code class="code_inline-code__Bq7ot">Doc</code>s which would affect
<code class="code_inline-code__Bq7ot">Tok2Vec</code> output, such as to create special contexts or remove <code class="code_inline-code__Bq7ot">Doc</code>s for which
no prediction can be made, must happen inside the model, <strong>after</strong> the call to
the <code class="code_inline-code__Bq7ot">Tok2Vec</code> component.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The width of the vectors produced by the “upstream” <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tok2vec"><code class="code_inline-code__Bq7ot">Tok2Vec</code></a> component. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">upstream</code></td><td class="table_td__rmpJx">A string to identify the “upstream” <code class="code_inline-code__Bq7ot">Tok2Vec</code> component to communicate with. By default, the upstream name is the wildcard string <code class="code_inline-code__Bq7ot">&quot;*&quot;</code>, but you could also specify the name of the <code class="code_inline-code__Bq7ot">Tok2Vec</code> component. You’ll almost never have multiple upstream <code class="code_inline-code__Bq7ot">Tok2Vec</code> components, so the wildcard string will almost always be fine. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">str</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="MultiHashEmbed" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#MultiHashEmbed" class="heading-text typography_permalink__UiIRy">spacy.MultiHashEmbed.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Construct an embedding layer that separately embeds a number of lexical
attributes using hash embedding, concatenates the results, and passes it through
a feed-forward subnetwork to build a mixed representation. The features used can
be configured with the <code class="code_inline-code__Bq7ot">attrs</code> argument. The suggested attributes are <code class="code_inline-code__Bq7ot">NORM</code>,
<code class="code_inline-code__Bq7ot">PREFIX</code>, <code class="code_inline-code__Bq7ot">SUFFIX</code> and <code class="code_inline-code__Bq7ot">SHAPE</code>. This lets the model take into account some
subword information, without construction a fully character-based
representation. If pretrained vectors are available, they can be included in the
representation as well, with the vectors table kept static (i.e. it’s not
updated).</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The output width. Also used as the width of the embedding tables. Recommended values are between <code class="code_inline-code__Bq7ot">64</code> and <code class="code_inline-code__Bq7ot">300</code>. If static vectors are included, a learned linear layer is used to map the vectors to the specified width before concatenating it with the other embedding outputs. A single maxout layer is then used to reduce the concatenated vectors to the final width. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">attrs</code></td><td class="table_td__rmpJx">The token attributes to embed. A separate embedding table will be constructed for each attribute. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">List<span class="code_cli-arg-subtle__IgB5m">[</span>Union<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">,</span> str<span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">rows</code></td><td class="table_td__rmpJx">The number of rows for each embedding tables. Can be low, due to the hashing trick. Recommended values are between <code class="code_inline-code__Bq7ot">1000</code> and <code class="code_inline-code__Bq7ot">10000</code>. The layer needs surprisingly few rows, due to its use of the hashing trick. Generally between 2000 and 10000 rows is sufficient, even for very large vocabularies. A number of rows must be specified for each table, so the <code class="code_inline-code__Bq7ot">rows</code> list must be of the same length as the <code class="code_inline-code__Bq7ot">attrs</code> parameter. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">List<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">include_static_vectors</code></td><td class="table_td__rmpJx">Whether to also use static word vectors. Requires a vectors table to be loaded in the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects’ vocab. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="CharacterEmbed" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#CharacterEmbed" class="heading-text typography_permalink__UiIRy">spacy.CharacterEmbed.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Construct an embedded representation based on character embeddings, using a
feed-forward network. A fixed number of UTF-8 byte characters are used for each
word, taken from the beginning and end of the word equally. Padding is used in
the center for words that are too short.</p><p>For instance, let’s say <code class="code_inline-code__Bq7ot">nC=4</code>, and the word is “jumping”. The characters used
will be <code class="code_inline-code__Bq7ot">&quot;jung&quot;</code> (two from the start, two from the end). If we had <code class="code_inline-code__Bq7ot">nC=8</code>, the
characters would be <code class="code_inline-code__Bq7ot">&quot;jumpping&quot;</code>: 4 from the start, 4 from the end. This ensures
that the final character is always in the last position, instead of being in an
arbitrary position depending on the word length.</p><p>The characters are embedded in a embedding table with a given number of rows,
and the vectors concatenated. A hash-embedded vector of the <code class="code_inline-code__Bq7ot">NORM</code> of the word
is also concatenated on, and the result is then passed through a feed-forward
network to construct a single vector to represent the information.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The width of the output vector and the <code class="code_inline-code__Bq7ot">NORM</code> hash embedding. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">rows</code></td><td class="table_td__rmpJx">The number of rows in the <code class="code_inline-code__Bq7ot">NORM</code> hash embedding table. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nM</code></td><td class="table_td__rmpJx">The dimensionality of the character embeddings. Recommended values are between <code class="code_inline-code__Bq7ot">16</code> and <code class="code_inline-code__Bq7ot">64</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nC</code></td><td class="table_td__rmpJx">The number of UTF-8 bytes to embed per word. Recommended values are between <code class="code_inline-code__Bq7ot">3</code> and <code class="code_inline-code__Bq7ot">8</code>, although it may depend on the length of words in the language. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="MaxoutWindowEncoder" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#MaxoutWindowEncoder" class="heading-text typography_permalink__UiIRy">spacy.MaxoutWindowEncoder.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Encode context using convolutions with maxout activation, layer normalization
and residual connections.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between <code class="code_inline-code__Bq7ot">64</code> and <code class="code_inline-code__Bq7ot">300</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">window_size</code></td><td class="table_td__rmpJx">The number of words to concatenate around each token to construct the convolution. Recommended value is <code class="code_inline-code__Bq7ot">1</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">maxout_pieces</code></td><td class="table_td__rmpJx">The number of maxout pieces to use. Recommended values are <code class="code_inline-code__Bq7ot">2</code> or <code class="code_inline-code__Bq7ot">3</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">depth</code></td><td class="table_td__rmpJx">The number of convolutional layers. Recommended value is <code class="code_inline-code__Bq7ot">4</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="MishWindowEncoder" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#MishWindowEncoder" class="heading-text typography_permalink__UiIRy">spacy.MishWindowEncoder.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Encode context using convolutions with
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#mish"><code class="code_inline-code__Bq7ot">Mish</code></a> activation, layer normalization
and residual connections.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between <code class="code_inline-code__Bq7ot">64</code> and <code class="code_inline-code__Bq7ot">300</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">window_size</code></td><td class="table_td__rmpJx">The number of words to concatenate around each token to construct the convolution. Recommended value is <code class="code_inline-code__Bq7ot">1</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">depth</code></td><td class="table_td__rmpJx">The number of convolutional layers. Recommended value is <code class="code_inline-code__Bq7ot">4</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="TorchBiLSTMEncoder" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TorchBiLSTMEncoder" class="heading-text typography_permalink__UiIRy">spacy.TorchBiLSTMEncoder.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Encode context using bidirectional LSTM layers. Requires
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://pytorch.org">PyTorch</a>.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between <code class="code_inline-code__Bq7ot">64</code> and <code class="code_inline-code__Bq7ot">300</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">depth</code></td><td class="table_td__rmpJx">The number of recurrent layers, for instance <code class="code_inline-code__Bq7ot">depth=2</code> results in stacking two LSTMs together. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">dropout</code></td><td class="table_td__rmpJx">Creates a Dropout layer on the outputs of each LSTM layer except the last layer. Set to 0.0 to disable this functionality. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">float</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="StaticVectors" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#StaticVectors" class="heading-text typography_permalink__UiIRy">spacy.StaticVectors.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Embed <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects with their vocab’s vectors table, applying a
learned linear projection to control the dimensionality. Unknown tokens are
mapped to a zero vector. See the documentation on
<a class="link_root__1Me7D" href="/usage/embeddings-transformers#static-vectors">static vectors</a> for details.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">The output width of the layer, after the linear projection. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nM</code></td><td class="table_td__rmpJx">The width of the static vectors. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">dropout</code></td><td class="table_td__rmpJx">Optional dropout rate. If set, it’s applied per dimension over the whole batch. Defaults to <code class="code_inline-code__Bq7ot">None</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>float<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">init_W</code></td><td class="table_td__rmpJx">The <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-initializers">initialization function</a>. Defaults to <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-initializers#glorot_uniform_init"><code class="code_inline-code__Bq7ot">glorot_uniform_init</code></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation">Callable<span class="code_cli-arg-subtle__IgB5m">[</span><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-backends#ops">Ops</a><span class="code_cli-arg-subtle__IgB5m">,</span> Tuple<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">,</span> …<span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">FloatsXd</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">key_attr</code></td><td class="table_td__rmpJx">Defaults to <code class="code_inline-code__Bq7ot">&quot;ORTH&quot;</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">str</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#ragged">Ragged</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="FeatureExtractor" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#FeatureExtractor" class="heading-text typography_permalink__UiIRy">spacy.FeatureExtractor.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Extract arrays of input features from <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects. Expects a list
of feature names to extract, which should refer to token attributes.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">columns</code></td><td class="table_td__rmpJx">The token attributes to extract. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">List<span class="code_cli-arg-subtle__IgB5m">[</span>Union<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">,</span> str<span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The created feature extraction layer. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Ints2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table></section>
<section id="section-transformers" class="section_root__k1hUl"><h2 id="transformers" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#transformers" class="heading-text typography_permalink__UiIRy">Transformer architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-transformers/blob/master/spacy_transformers/architectures.py">Source</a></div></h2><p>The following architectures are provided by the package
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-transformers"><code class="code_inline-code__Bq7ot">spacy-transformers</code></a>. See the
<a class="link_root__1Me7D" href="/usage/embeddings-transformers#transformers">usage documentation</a> for how to
integrate the architectures into your training config.</p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><p>Note that in order to use these architectures in your config, you need to
install the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-transformers"><code class="code_inline-code__Bq7ot">spacy-transformers</code></a>. See the
<a class="link_root__1Me7D" href="/usage/embeddings-transformers#transformers-installation">installation docs</a>
for details and system requirements.</p></aside><h3 id="TransformerModel" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TransformerModel" class="heading-text typography_permalink__UiIRy">spacy-transformers.TransformerModel.v3 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Load and wrap a transformer model from the
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://huggingface.co/transformers">HuggingFace <code class="code_inline-code__Bq7ot">transformers</code></a> library. You
can use any transformer that has pretrained weights and a PyTorch
implementation. The <code class="code_inline-code__Bq7ot">name</code> variable is passed through to the underlying library,
so it can be either a string or a path. If it’s a string, the pretrained weights
will be downloaded via the transformers library if they are not already
available locally.</p><p>In order to support longer documents, the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#TransformerModel"><span class="link_source-text__VDP74">TransformerModel</span></a> layer allows you to pass
in a <code class="code_inline-code__Bq7ot">get_spans</code> function that will divide up the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects
before passing them through the transformer. Your spans are allowed to overlap
or exclude tokens. This layer is usually used directly by the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/transformer"><code class="code_inline-code__Bq7ot">Transformer</code></a> component, which allows you to share the
transformer weights across your pipeline. For a layer that’s configured for use
in other components, see
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/architectures#Tok2VecTransformer"><span class="link_source-text__VDP74">Tok2VecTransformer</span></a>.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">name</code></td><td class="table_td__rmpJx">Any model name that can be loaded by <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoModel"><code class="code_inline-code__Bq7ot">transformers.AutoModel</code></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">str</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">get_spans</code></td><td class="table_td__rmpJx">Function that takes a batch of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> object and returns lists of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api"><code class="code_inline-code__Bq7ot">Span</code></a> objects to process by the transformer. <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/transformer#span_getters"><span class="link_source-text__VDP74">See here</span></a> for built-in options and examples. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation">Callable<span class="code_cli-arg-subtle__IgB5m">[</span><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/span">Span</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tokenizer_config</code></td><td class="table_td__rmpJx">Tokenizer settings passed to <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoTokenizer"><code class="code_inline-code__Bq7ot">transformers.AutoTokenizer</code></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">transformer_config</code></td><td class="table_td__rmpJx">Transformer settings passed to <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://huggingface.co/transformers/model_doc/auto.html?highlight=autoconfig#transformers.AutoConfig"><code class="code_inline-code__Bq7ot">transformers.AutoConfig</code></a> <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">mixed_precision</code></td><td class="table_td__rmpJx">Replace whitelisted ops by half-precision counterparts. Speeds up training and prediction on GPUs with <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://developer.nvidia.com/tensor-cores">Tensor Cores</a> and reduces GPU memory use. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">grad_scaler_config</code></td><td class="table_td__rmpJx">Configuration to pass to <code class="code_inline-code__Bq7ot">thinc.api.PyTorchGradScaler</code> during training when <code class="code_inline-code__Bq7ot">mixed_precision</code> is enabled. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" href="/api/transformer#fulltransformerbatch">FullTransformerBatch</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"></td><td class="table_td__rmpJx"></td></tr></tbody></table><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Mixed precision support</span></h4><p>Mixed-precision support is currently an experimental feature.</p></aside><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Previous versions of spacy-transformers.TransformerModel</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">The <code class="code_inline-code__Bq7ot">transformer_config</code> argument was added in
<code class="code_inline-code__Bq7ot code_wrap__b41os">spacy-transformers.TransformerModel.v2</code>.</li>
<li class="list_li__sfx_z">The <code class="code_inline-code__Bq7ot">mixed_precision</code> and <code class="code_inline-code__Bq7ot">grad_scaler_config</code> arguments were added in
<code class="code_inline-code__Bq7ot code_wrap__b41os">spacy-transformers.TransformerModel.v3</code>.</li>
</ul><p>The other arguments are shared between all versions.</p></div></div></section><h3 id="TransformerListener" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TransformerListener" class="heading-text typography_permalink__UiIRy">spacy-transformers.TransformerListener.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Create a <code class="code_inline-code__Bq7ot">TransformerListener</code> layer, which will connect to a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/transformer"><code class="code_inline-code__Bq7ot">Transformer</code></a> component earlier in the pipeline. The layer
takes a list of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects as input, and produces a list of
2-dimensional arrays as output, with each array having one row per token. Most
spaCy models expect a sublayer with this signature, making it easy to connect
them to a transformer model via this sublayer. Transformer models usually
operate over wordpieces, which usually don’t align one-to-one against spaCy
tokens. The layer therefore requires a reduction operation in order to calculate
a single token vector given zero or more wordpiece vectors.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pooling</code></td><td class="table_td__rmpJx">A reduction layer used to calculate the token vectors based on zero or more wordpiece vectors. If in doubt, mean pooling (see <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#reduce_mean"><code class="code_inline-code__Bq7ot">reduce_mean</code></a>) is usually a good choice. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#ragged">Ragged</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">grad_factor</code></td><td class="table_td__rmpJx">Reweight gradients from the component before passing them upstream. You can set this to <code class="code_inline-code__Bq7ot">0</code> to “freeze” the transformer weights with respect to the component, or use it to make some components more significant than others. Leaving it at <code class="code_inline-code__Bq7ot">1.0</code> is usually fine. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">float</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">upstream</code></td><td class="table_td__rmpJx">A string to identify the “upstream” <code class="code_inline-code__Bq7ot">Transformer</code> component to communicate with. By default, the upstream name is the wildcard string <code class="code_inline-code__Bq7ot">&quot;*&quot;</code>, but you could also specify the name of the <code class="code_inline-code__Bq7ot">Transformer</code> component. You’ll almost never have multiple upstream <code class="code_inline-code__Bq7ot">Transformer</code> components, so the wildcard string will almost always be fine. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">str</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="Tok2VecTransformer" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#Tok2VecTransformer" class="heading-text typography_permalink__UiIRy">spacy-transformers.Tok2VecTransformer.v3 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Use a transformer as a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tok2vec"><code class="code_inline-code__Bq7ot">Tok2Vec</code></a> layer directly. This does
<strong>not</strong> allow multiple components to share the transformer weights and does
<strong>not</strong> allow the transformer to set annotations into the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a>
object, but it’s a <strong>simpler solution</strong> if you only need the transformer within
one component.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">get_spans</code></td><td class="table_td__rmpJx">Function that takes a batch of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> object and returns lists of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api"><code class="code_inline-code__Bq7ot">Span</code></a> objects to process by the transformer. <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/transformer#span_getters"><span class="link_source-text__VDP74">See here</span></a> for built-in options and examples. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation">Callable<span class="code_cli-arg-subtle__IgB5m">[</span><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/span">Span</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tokenizer_config</code></td><td class="table_td__rmpJx">Tokenizer settings passed to <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoTokenizer"><code class="code_inline-code__Bq7ot">transformers.AutoTokenizer</code></a>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">transformer_config</code></td><td class="table_td__rmpJx">Settings to pass to the transformers forward pass. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pooling</code></td><td class="table_td__rmpJx">A reduction layer used to calculate the token vectors based on zero or more wordpiece vectors. If in doubt, mean pooling (see <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#reduce_mean"><code class="code_inline-code__Bq7ot">reduce_mean</code></a>) is usually a good choice. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#ragged">Ragged</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">grad_factor</code></td><td class="table_td__rmpJx">Reweight gradients from the component before passing them upstream. You can set this to <code class="code_inline-code__Bq7ot">0</code> to “freeze” the transformer weights with respect to the component, or use it to make some components more significant than others. Leaving it at <code class="code_inline-code__Bq7ot">1.0</code> is usually fine. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">float</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">mixed_precision</code></td><td class="table_td__rmpJx">Replace whitelisted ops by half-precision counterparts. Speeds up training and prediction on GPUs with <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://developer.nvidia.com/tensor-cores">Tensor Cores</a> and reduces GPU memory use. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">grad_scaler_config</code></td><td class="table_td__rmpJx">Configuration to pass to <code class="code_inline-code__Bq7ot">thinc.api.PyTorchGradScaler</code> during training when <code class="code_inline-code__Bq7ot">mixed_precision</code> is enabled. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Dict<span class="code_cli-arg-subtle__IgB5m">[</span>str<span class="code_cli-arg-subtle__IgB5m">,</span> Any<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Mixed precision support</span></h4><p>Mixed-precision support is currently an experimental feature.</p></aside><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Previous versions of spacy-transformers.Tok2VecTransformer</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">The <code class="code_inline-code__Bq7ot">transformer_config</code> argument was added in
<code class="code_inline-code__Bq7ot code_wrap__b41os">spacy-transformers.Tok2VecTransformer.v2</code>.</li>
<li class="list_li__sfx_z">The <code class="code_inline-code__Bq7ot">mixed_precision</code> and <code class="code_inline-code__Bq7ot">grad_scaler_config</code> arguments were added in
<code class="code_inline-code__Bq7ot code_wrap__b41os">spacy-transformers.Tok2VecTransformer.v3</code>.</li>
</ul><p>The other arguments are shared between all versions.</p></div></div></section></section>
<section id="section-pretrain" class="section_root__k1hUl"><h2 id="pretrain" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#pretrain" class="heading-text typography_permalink__UiIRy">Pretraining architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/multi_task.py">Source</a></div></h2><p>The spacy <code class="code_inline-code__Bq7ot">pretrain</code> command lets you initialize a <code class="code_inline-code__Bq7ot">Tok2Vec</code> layer in your
pipeline with information from raw text. To this end, additional layers are
added to build a network for a temporary task that forces the <code class="code_inline-code__Bq7ot">Tok2Vec</code> layer to
learn something about sentence structure and word cooccurrence statistics. Two
pretraining objectives are available, both of which are variants of the cloze
task <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://arxiv.org/abs/1810.04805">Devlin et al. (2018)</a> introduced for
BERT.</p><p>For more information, see the section on
<a class="link_root__1Me7D" href="/usage/embeddings-transformers#pretraining">pretraining</a>.</p><h3 id="pretrain_vectors" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#pretrain_vectors" class="heading-text typography_permalink__UiIRy">spacy.PretrainVectors.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Predict the word’s vector from a static embeddings table as pretraining
objective for a Tok2Vec layer. To use this objective, make sure that the
<code class="code_inline-code__Bq7ot">initialize.vectors</code> section in the config refers to a model with static
vectors.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">maxout_pieces</code></td><td class="table_td__rmpJx">The number of maxout pieces to use. Recommended values are <code class="code_inline-code__Bq7ot">2</code> or <code class="code_inline-code__Bq7ot">3</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_size</code></td><td class="table_td__rmpJx">Size of the hidden layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">loss</code></td><td class="table_td__rmpJx">The loss function can be either “cosine” or “L2”. We typically recommend to use “cosine”. ~~~str~~</td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">A callable function that can create the Model, given the <code class="code_inline-code__Bq7ot">vocab</code> of the pipeline and the <code class="code_inline-code__Bq7ot">tok2vec</code> layer to pretrain. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation">Callable<span class="code_cli-arg-subtle__IgB5m">[</span><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/vocab">Vocab</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="pretrain_chars" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#pretrain_chars" class="heading-text typography_permalink__UiIRy">spacy.PretrainCharacters.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Predict some number of leading and trailing UTF-8 bytes as pretraining objective
for a Tok2Vec layer.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">maxout_pieces</code></td><td class="table_td__rmpJx">The number of maxout pieces to use. Recommended values are <code class="code_inline-code__Bq7ot">2</code> or <code class="code_inline-code__Bq7ot">3</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_size</code></td><td class="table_td__rmpJx">Size of the hidden layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">n_characters</code></td><td class="table_td__rmpJx">The window of characters - e.g. if <code class="code_inline-code__Bq7ot">n_characters = 2</code>, the model will try to predict the first two and last two characters of the word. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">A callable function that can create the Model, given the <code class="code_inline-code__Bq7ot">vocab</code> of the pipeline and the <code class="code_inline-code__Bq7ot">tok2vec</code> layer to pretrain. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation">Callable<span class="code_cli-arg-subtle__IgB5m">[</span><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/vocab">Vocab</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table></section>
<section id="section-parser" class="section_root__k1hUl"><h2 id="parser" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#parser" class="heading-text typography_permalink__UiIRy">Parser &amp; NER architectures <!-- --> </a></h2><h3 id="TransitionBasedParser" class="typography_heading__D82WZ typography_h3__mPKmB typography_clear__LuXx9"><a href="#TransitionBasedParser" class="heading-text typography_permalink__UiIRy">spacy.TransitionBasedParser.v2 <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/parser.py">Source</a></div></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Build a transition-based parser model. Can apply to NER or dependency parsing.
Transition-based parsing is an approach to structured prediction where the task
of predicting the structure is mapped to a series of state transitions. You
might find <a class="link_root__1Me7D" href="https://explosion.ai/blog/parsing-english-in-python">this tutorial</a>
helpful for background information. The neural network state prediction model
consists of either two or three subnetworks:</p><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>tok2vec</strong>: Map each token into a vector representation. This subnetwork is
run once for each batch.</li>
<li class="list_li__sfx_z"><strong>lower</strong>: Construct a feature-specific vector for each <code class="code_inline-code__Bq7ot">(token, feature)</code>
pair. This is also run once for each batch. Constructing the state
representation is then a matter of summing the component features and applying
the non-linearity.</li>
<li class="list_li__sfx_z"><strong>upper</strong> (optional): A feed-forward network that predicts scores from the
state representation. If not present, the output from the lower model is used
as action scores directly.</li>
</ul><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">Subnetwork to map tokens into vector representations. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">state_type</code></td><td class="table_td__rmpJx">Which task to extract features for. Possible values are “ner” and “parser”. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">str</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">extra_state_tokens</code></td><td class="table_td__rmpJx">Whether to use an expanded feature set when extracting the state tokens. Slightly slower, but sometimes improves accuracy slightly. Defaults to <code class="code_inline-code__Bq7ot">False</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_width</code></td><td class="table_td__rmpJx">The width of the hidden layer. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">maxout_pieces</code></td><td class="table_td__rmpJx">How many pieces to use in the state prediction layer. Recommended values are <code class="code_inline-code__Bq7ot">1</code>, <code class="code_inline-code__Bq7ot">2</code> or <code class="code_inline-code__Bq7ot">3</code>. If <code class="code_inline-code__Bq7ot">1</code>, the maxout non-linearity is replaced with a <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#relu"><code class="code_inline-code__Bq7ot">Relu</code></a> non-linearity if <code class="code_inline-code__Bq7ot">use_upper</code> is <code class="code_inline-code__Bq7ot">True</code>, and no non-linearity if <code class="code_inline-code__Bq7ot">False</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">use_upper</code></td><td class="table_td__rmpJx">Whether to use an additional hidden layer after the state vector in order to predict the action scores. It is recommended to set this to <code class="code_inline-code__Bq7ot">False</code> for large pretrained models such as transformers, and <code class="code_inline-code__Bq7ot">True</code> for smaller networks. The upper layer is computed on CPU, which becomes a bottleneck on larger GPU-based models, where it’s also less necessary. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">The number of actions the model will predict between. Usually inferred from data at the beginning of training, or loaded from disk. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span>Docs<span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">spacy.TransitionBasedParser.v1 definition</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p><a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/legacy#TransitionBasedParser_v1"><span class="link_source-text__VDP74">TransitionBasedParser.v1</span></a> had the exact
same signature, but the <code class="code_inline-code__Bq7ot">use_upper</code> argument was <code class="code_inline-code__Bq7ot">True</code> by default.</p></div></div></section></section>
<section id="section-tagger" class="section_root__k1hUl"><h2 id="tagger" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#tagger" class="heading-text typography_permalink__UiIRy">Tagging architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/tagger.py">Source</a></div></h2><h3 id="Tagger" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#Tagger" class="heading-text typography_permalink__UiIRy">spacy.Tagger.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Build a tagger model, using a provided token-to-vector component. The tagger
model adds a linear layer with softmax activation to predict scores given the
token vectors.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">Subnetwork to map tokens into vector representations. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">The number of tags to output. Inferred from the data if <code class="code_inline-code__Bq7ot">None</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">normalize</code></td><td class="table_td__rmpJx">Normalize probabilities during inference. Defaults to <code class="code_inline-code__Bq7ot">False</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Previous versions of spacy.Tagger</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">The <code class="code_inline-code__Bq7ot">normalize</code> argument was added in <code class="code_inline-code__Bq7ot">spacy.Tagger.v2</code>. <code class="code_inline-code__Bq7ot">spacy.Tagger.v1</code>
always normalizes probabilities during inference.</li>
</ul><p>The other arguments are shared between all versions.</p></div></div></section></section>
<section id="section-textcat" class="section_root__k1hUl"><h2 id="textcat" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#textcat" class="heading-text typography_permalink__UiIRy">Text classification architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/textcat.py">Source</a></div></h2><p>A text classification architecture needs to take a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> as input,
and produce a score for each potential label class. Textcat challenges can be
binary (e.g. sentiment analysis) or involve multiple possible labels.
Multi-label challenges can either have mutually exclusive labels (each example
has exactly one label), or multiple labels may be applicable at the same time.</p><p>As the properties of text classification problems can vary widely, we provide
several different built-in architectures. It is recommended to experiment with
different architectures and settings to determine what works best on your
specific data and challenge.</p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Single-label vs. multi-label classification</span></h4><p>When the architecture for a text classification challenge contains a setting for
<code class="code_inline-code__Bq7ot">exclusive_classes</code>, it is important to use the correct value for the correct
pipeline component. The <code class="code_inline-code__Bq7ot">textcat</code> component should always be used for
single-label use-cases where <code class="code_inline-code__Bq7ot">exclusive_classes = true</code>, while the
<code class="code_inline-code__Bq7ot">textcat_multilabel</code> should be used for multi-label settings with
<code class="code_inline-code__Bq7ot">exclusive_classes = false</code>.</p></aside><h3 id="TextCatEnsemble" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TextCatEnsemble" class="heading-text typography_permalink__UiIRy">spacy.TextCatEnsemble.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Stacked ensemble of a linear bag-of-words model and a neural network model. The
neural network is built upon a Tok2Vec layer and uses attention. The setting for
whether or not this model should cater for multi-label classification, is taken
from the linear model, where it is stored in <code class="code_inline-code__Bq7ot">model.attrs[&quot;multi_label&quot;]</code>.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">linear_model</code></td><td class="table_td__rmpJx">The linear bag-of-words model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The <code class="code_inline-code__Bq7ot">tok2vec</code> layer to build the neural network upon. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">Output dimension, determined by the number of different labels. If not set, the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a> component will set it when <code class="code_inline-code__Bq7ot">initialize</code> is called. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">spacy.TextCatEnsemble.v1 definition</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p><a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/legacy#TextCatEnsemble_v1"><span class="link_source-text__VDP74">TextCatEnsemble.v1</span></a> was functionally similar,
but used an internal <code class="code_inline-code__Bq7ot">tok2vec</code> instead of taking it as argument:</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">exclusive_classes</code></td><td class="table_td__rmpJx">Whether or not categories are mutually exclusive. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pretrained_vectors</code></td><td class="table_td__rmpJx">Whether or not pretrained vectors will be used in addition to the feature vectors. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">width</code></td><td class="table_td__rmpJx">Output dimension of the feature encoding step. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">embed_size</code></td><td class="table_td__rmpJx">Input dimension of the feature encoding step. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">conv_depth</code></td><td class="table_td__rmpJx">Depth of the tok2vec layer. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">window_size</code></td><td class="table_td__rmpJx">The number of contextual vectors to <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-layers#expand_window">concatenate</a> from the left and from the right. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ngram_size</code></td><td class="table_td__rmpJx">Determines the maximum length of the n-grams in the BOW model. For instance, <code class="code_inline-code__Bq7ot">ngram_size=3</code>would give unigram, trigram and bigram features. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">dropout</code></td><td class="table_td__rmpJx">The dropout rate. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">float</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">Output dimension, determined by the number of different labels. If not set, the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a> component will set it when <code class="code_inline-code__Bq7ot">initialize</code> is called. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table></div></div></section><h3 id="TextCatCNN" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TextCatCNN" class="heading-text typography_permalink__UiIRy">spacy.TextCatCNN.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>A neural network model where token vectors are calculated using a CNN. The
vectors are mean pooled and used as features in a feed-forward network. This
architecture is usually less accurate than the ensemble, but runs faster.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">exclusive_classes</code></td><td class="table_td__rmpJx">Whether or not categories are mutually exclusive. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The <a class="link_root__1Me7D" href="/api/architectures#tok2vec"><code class="code_inline-code__Bq7ot">tok2vec</code></a> layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">Output dimension, determined by the number of different labels. If not set, the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a> component will set it when <code class="code_inline-code__Bq7ot">initialize</code> is called. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">spacy.TextCatCNN.v1 definition</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p><a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/legacy#TextCatCNN_v1"><span class="link_source-text__VDP74">TextCatCNN.v1</span></a> had the exact same signature, but was
not yet resizable. Since v2, new labels can be added to this component, even
after training.</p></div></div></section><h3 id="TextCatBOW" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#TextCatBOW" class="heading-text typography_permalink__UiIRy">spacy.TextCatBOW.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>An n-gram “bag-of-words” model. This architecture should run much faster than
the others, but may not be as accurate, especially if texts are short.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">exclusive_classes</code></td><td class="table_td__rmpJx">Whether or not categories are mutually exclusive. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ngram_size</code></td><td class="table_td__rmpJx">Determines the maximum length of the n-grams in the BOW model. For instance, <code class="code_inline-code__Bq7ot">ngram_size=3</code> would give unigram, trigram and bigram features. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">no_output_layer</code></td><td class="table_td__rmpJx">Whether or not to add an output layer to the model (<code class="code_inline-code__Bq7ot">Softmax</code> activation if <code class="code_inline-code__Bq7ot">exclusive_classes</code> is <code class="code_inline-code__Bq7ot">True</code>, else <code class="code_inline-code__Bq7ot">Logistic</code>). <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">bool</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">Output dimension, determined by the number of different labels. If not set, the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a> component will set it when <code class="code_inline-code__Bq7ot">initialize</code> is called. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><section class="accordion"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">spacy.TextCatBOW.v1 definition</span></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p><a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/legacy#TextCatBOW_v1"><span class="link_source-text__VDP74">TextCatBOW.v1</span></a> had the exact same signature, but was
not yet resizable. Since v2, new labels can be added to this component, even
after training.</p></div></div></section></section>
<section id="section-spancat" class="section_root__k1hUl"><h2 id="spancat" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#spancat" class="heading-text typography_permalink__UiIRy">Span classification architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/spancat.py">Source</a></div></h2><h3 id="SpanCategorizer" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#SpanCategorizer" class="heading-text typography_permalink__UiIRy">spacy.SpanCategorizer.v1 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>Build a span categorizer model to power a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/spancategorizer"><code class="code_inline-code__Bq7ot">SpanCategorizer</code></a> component, given a token-to-vector
model, a reducer model to map the sequence of vectors for each span down to a
single vector, and a scorer model to map the vectors to probabilities.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The token-to-vector model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">reducer</code></td><td class="table_td__rmpJx">The reducer model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#ragged">Ragged</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">scorer</code></td><td class="table_td__rmpJx">The scorer model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>Tuple<span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#ragged">Ragged</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="mean_max_reducer" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#mean_max_reducer" class="heading-text typography_permalink__UiIRy">spacy.mean_max_reducer.v1 <!-- --> </a></h3><p>Reduce sequences by concatenating their mean and max pooled vectors, and then
combine the concatenated vectors with a hidden layer.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_size</code></td><td class="table_td__rmpJx">The size of the hidden layer. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr></tbody></table></section>
<section id="section-entitylinker" class="section_root__k1hUl"><h2 id="entitylinker" class="typography_heading__D82WZ typography_h2__hzV3h typography_clear__LuXx9"><a href="#entitylinker" class="heading-text typography_permalink__UiIRy">Entity linking architectures <!-- --> </a><div class="typography_action__rv_MQ"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/ml/models/entity_linker.py">Source</a></div></h2><p>An <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entitylinker"><code class="code_inline-code__Bq7ot">EntityLinker</code></a> component disambiguates textual mentions
(tagged as named entities) to unique identifiers, grounding the named entities
into the “real world”. This requires 3 main components:</p><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">A <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/kb"><code class="code_inline-code__Bq7ot">KnowledgeBase</code></a> (KB) holding the unique identifiers, potential
synonyms and prior probabilities.</li>
<li class="list_li__sfx_z">A candidate generation step to produce a set of likely identifiers, given a
certain textual mention.</li>
<li class="list_li__sfx_z">A machine learning <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model"><code class="code_inline-code__Bq7ot">Model</code></a> that picks the
most plausible ID from the set of candidates.</li>
</ul><h3 id="EntityLinker" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#EntityLinker" class="heading-text typography_permalink__UiIRy">spacy.EntityLinker.v2 <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>The <code class="code_inline-code__Bq7ot">EntityLinker</code> model architecture is a Thinc <code class="code_inline-code__Bq7ot">Model</code> with a
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/api-layers#linear"><code class="code_inline-code__Bq7ot">Linear</code></a> output layer.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The <a class="link_root__1Me7D" href="/api/architectures#tok2vec"><code class="code_inline-code__Bq7ot">tok2vec</code></a> layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nO</code></td><td class="table_td__rmpJx">Output dimension, determined by the length of the vectors encoding each entity in the KB. If the <code class="code_inline-code__Bq7ot">nO</code> dimension is not set, the entity linking component will set it when <code class="code_inline-code__Bq7ot">initialize</code> is called. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">Optional<span class="code_cli-arg-subtle__IgB5m">[</span>int<span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="EmptyKB" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#EmptyKB" class="heading-text typography_permalink__UiIRy">spacy.EmptyKB.v1 <!-- --> </a></h3><p>A function that creates an empty <code class="code_inline-code__Bq7ot">KnowledgeBase</code> from a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a>
instance. This is the default when a new entity linker component is created.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">entity_vector_length</code></td><td class="table_td__rmpJx">The length of the vectors encoding each entity in the KB. Defaults to <code class="code_inline-code__Bq7ot">64</code>. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr></tbody></table><h3 id="KBFromFile" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#KBFromFile" class="heading-text typography_permalink__UiIRy">spacy.KBFromFile.v1 <!-- --> </a></h3><p>A function that reads an existing <code class="code_inline-code__Bq7ot">KnowledgeBase</code> from file.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">kb_path</code></td><td class="table_td__rmpJx">The location of the KB that was stored to file. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://docs.python.org/3/library/pathlib.html">Path</a></span></td></tr></tbody></table><h3 id="CandidateGenerator" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#CandidateGenerator" class="heading-text typography_permalink__UiIRy">spacy.CandidateGenerator.v1 <!-- --> </a></h3><p>A function that takes as input a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/kb"><code class="code_inline-code__Bq7ot">KnowledgeBase</code></a> and a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span"><code class="code_inline-code__Bq7ot">Span</code></a> object denoting a named entity, and returns a list of
plausible <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/kb#candidate"><code class="code_inline-code__Bq7ot">Candidate</code></a> objects. The default
<code class="code_inline-code__Bq7ot">CandidateGenerator</code> uses the text of a mention to find its potential aliases in
the <code class="code_inline-code__Bq7ot">KnowledgeBase</code>. Note that this function is case-dependent.</p></section>
<section id="section-coref-architectures" class="section_root__k1hUl"><h2 id="coref-architectures" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#coref-architectures" class="heading-text typography_permalink__UiIRy">Coreference <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH">experimental</span></h2><p>A <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/coref"><code class="code_inline-code__Bq7ot">CoreferenceResolver</code></a> component identifies tokens that refer to
the same entity. A <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span-resolver"><code class="code_inline-code__Bq7ot">SpanResolver</code></a> component infers spans
from single tokens. Together these components can be used to reproduce
traditional coreference models. You can also omit the <code class="code_inline-code__Bq7ot">SpanResolver</code> if working
with only token-level clusters is acceptable.</p><h3 id="Coref" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#Coref" class="heading-text typography_permalink__UiIRy">spacy-experimental.Coref.v1 <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH">experimental</span></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>The <code class="code_inline-code__Bq7ot">Coref</code> model architecture is a Thinc <code class="code_inline-code__Bq7ot">Model</code>.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The <a class="link_root__1Me7D" href="/api/architectures#tok2vec"><code class="code_inline-code__Bq7ot">tok2vec</code></a> layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">distance_embedding_size</code></td><td class="table_td__rmpJx">A representation of the distance between candidates. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">dropout</code></td><td class="table_td__rmpJx">The dropout to use internally. Unlike some Thinc models, this has separate dropout for the internal PyTorch layers. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">float</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_size</code></td><td class="table_td__rmpJx">Size of the main internal layers. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">depth</code></td><td class="table_td__rmpJx">Depth of the internal network. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">antecedent_limit</code></td><td class="table_td__rmpJx">How many candidate antecedents to keep after rough scoring. This has a significant effect on memory usage. Typical values would be 50 to 200, or higher for very long documents. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">antecedent_batch_size</code></td><td class="table_td__rmpJx">Internal batch size. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-types#types">Floats2d</a><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table><h3 id="SpanResolver" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#SpanResolver" class="heading-text typography_permalink__UiIRy">spacy-experimental.SpanResolver.v1 <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH">experimental</span></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example Config<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><p>The <code class="code_inline-code__Bq7ot">SpanResolver</code> model architecture is a Thinc <code class="code_inline-code__Bq7ot">Model</code>. Note that
<code class="code_inline-code__Bq7ot">MentionClusters</code> is <code class="code_inline-code__Bq7ot">List[List[Tuple[int, int]]]</code>.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">tok2vec</code></td><td class="table_td__rmpJx">The <a class="link_root__1Me7D" href="/api/architectures#tok2vec"><code class="code_inline-code__Bq7ot">tok2vec</code></a> layer of the model. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a></span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">hidden_size</code></td><td class="table_td__rmpJx">Size of the main internal layers. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">distance_embedding_size</code></td><td class="table_td__rmpJx">A representation of the distance between two candidates. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">conv_channels</code></td><td class="table_td__rmpJx">The number of channels in the internal CNN. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">window_size</code></td><td class="table_td__rmpJx">The number of neighboring tokens to consider in the internal CNN. <code class="code_inline-code__Bq7ot">1</code> means consider one token on each side. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">max_distance</code></td><td class="table_td__rmpJx">The longest possible length of a predicted span. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">int</span></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">prefix</code></td><td class="table_td__rmpJx">The prefix that indicates spans to use for input data. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM" role="code" aria-label="Type annotation">string</span></td></tr><tr class="table_tr__K_tkF table_footer__gJRIy table-footer"><td class="table_td__rmpJx"><strong>CREATES</strong></td><td class="table_td__rmpJx">The model using the architecture. <span class="type-annotation language-python code_inline-code__Bq7ot code_type-annotation__6N9RM code_wrap__b41os" role="code" aria-label="Type annotation"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/api-model">Model</a><span class="code_cli-arg-subtle__IgB5m">[</span>List<span class="code_cli-arg-subtle__IgB5m">[</span><a class="link_root__1Me7D" href="/api/doc">Doc</a><span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">,</span> List<span class="code_cli-arg-subtle__IgB5m">[</span>MentionClusters<span class="code_cli-arg-subtle__IgB5m">]</span><span class="code_cli-arg-subtle__IgB5m">]</span></span></td></tr></tbody></table></section><div class="grid_root__EfDZl grid_spacing__fhBCv grid_half__xoJZs"><div style="margin-top:var(--spacing-lg)"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/website/docs/api/architectures.mdx">Suggest edits</a></div></div></article><div class="main_asides__RITE5" style="background-image:url(/_next/static/media/pattern_green.92f07e1d.png"></div><footer class="footer_root__zlkjP"><div class="grid_root__EfDZl footer_content__LaE1F grid_narrow__x_6xS grid_spacing__fhBCv grid_third__edHuB"><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">spaCy</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage">Usage</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API Reference</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://course.spacy.io">Online Course</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Community</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/discussions">GitHub Discussions</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues">Issue Tracker</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="http://stackoverflow.com/questions/tagged/spacy">Stack Overflow</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Connect</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/spacy_io">Twitter</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy">GitHub</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://youtube.com/c/ExplosionAI">YouTube</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/blog">Blog</a></li></ul></section><section class="footer_full___icln"><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Stay in the loop!</li><li>Receive updates about new releases, tutorials and more.</li><li><form id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" action="//spacy.us12.list-manage.com/subscribe/post?u=83b0498b1e7fa3c91ce68c3f1&amp;amp;id=ecc82e0493" method="post" target="_blank" novalidate=""><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_83b0498b1e7fa3c91ce68c3f1_ecc82e0493" tabindex="-1" value=""/></div><div class="newsletter_root__uh6MU"><input class="newsletter_input___SMSB" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email" aria-label="Your email"/><button class="newsletter_button__gKW8E" id="mc-embedded-subscribe" type="submit" name="subscribe">Sign up</button></div></form></li></ul></section></div><div class="footer_content__LaE1F footer_copy__rbjvc"><span>© 2016-<!-- -->2023<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai">Explosion</a></span><a class="link_root__1Me7D footer_logo__BthsJ link_no-link-layout__RPvod" aria-label="Explosion" href="https://explosion.ai"></a><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/legal">Legal / Imprint</a></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Model Architectures","teaser":"Pre-defined model architectures included with the core library","source":"spacy/ml/models","menu":[["Tok2Vec","tok2vec-arch"],["Transformers","transformers"],["Pretraining","pretrain"],["Parser \u0026 NER","parser"],["Tagging","tagger"],["Text Classification","textcat"],["Span Classification","spancat"],["Entity Linking","entitylinker"],["Coreference","coref-architectures"]],"slug":"/api/architectures","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    p: \"p\",\n    strong: \"strong\",\n    a: \"a\",\n    h2: \"h2\",\n    h3: \"h3\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    pre: \"pre\",\n    code: \"code\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    del: \"del\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components), {InlineCode, Infobox, Accordion} = _components;\n  if (!Accordion) _missingMdxReference(\"Accordion\", true);\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.section, {\n      children: _jsxs(_components.p, {\n        children: [\"A \", _jsx(_components.strong, {\n          children: \"model architecture\"\n        }), \" is a function that wires up a\\n\", _jsx(_components.a, {\n          href: \"https://thinc.ai/docs/api-model\",\n          children: _jsx(InlineCode, {\n            children: \"Model\"\n          })\n        }), \" instance, which you can then use in a\\npipeline component or as a layer of a larger network. This page documents\\nspaCy’s built-in architectures that are used for different NLP tasks. All\\ntrainable \", _jsx(_components.a, {\n          href: \"/api#architecture-pipeline\",\n          children: \"built-in components\"\n        }), \" expect a \", _jsx(InlineCode, {\n          children: \"model\"\n        }), \"\\nargument defined in the config and document their the default architecture.\\nCustom architectures can be registered using the\\n\", _jsx(_components.a, {\n          href: \"/api/top-level#registry\",\n          children: _jsx(InlineCode, {\n            children: \"@spacy.registry.architectures\"\n          })\n        }), \" decorator and used as\\npart of the \", _jsx(_components.a, {\n          href: \"/usage/training#custom-functions\",\n          children: \"training config\"\n        }), \". Also see the\\nusage documentation on\\n\", _jsx(_components.a, {\n          href: \"/usage/layers-architectures\",\n          children: \"layers and model architectures\"\n        }), \".\"]\n      })\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-tok2vec-arch\",\n      children: [_jsx(_components.h2, {\n        id: \"tok2vec-arch\",\n        source: \"spacy/ml/models/tok2vec.py\",\n        children: \"Tok2Vec architectures \"\n      }), _jsx(_components.h3, {\n        id: \"Tok2Vec\",\n        children: \"spacy.Tok2Vec.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.Tok2Vec.v2\\\"\\n\\n[model.embed]\\n@architectures = \\\"spacy.CharacterEmbed.v2\\\"\\n# ...\\n\\n[model.encode]\\n@architectures = \\\"spacy.MaxoutWindowEncoder.v2\\\"\\n# ...\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Construct a tok2vec model out of two subnetworks: one for embedding and one for\\nencoding. See the\\n\", _jsx(_components.a, {\n          href: \"https://explosion.ai/blog/deep-learning-formula-nlp\",\n          children: \"“Embed, Encode, Attend, Predict”\"\n        }), \"\\nblog post for background.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"embed\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Embed tokens into context-independent word vector representations. For example, \", _jsx(_components.a, {\n                href: \"/api/architectures#CharacterEmbed\",\n                children: \"CharacterEmbed\"\n              }), \" or \", _jsx(_components.a, {\n                href: \"/api/architectures#MultiHashEmbed\",\n                children: \"MultiHashEmbed\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"encode\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Encode context into the embeddings, using an architecture such as a CNN, BiLSTM or transformer. For example, \", _jsx(_components.a, {\n                href: \"/api/architectures#MaxoutWindowEncoder\",\n                children: \"MaxoutWindowEncoder\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Model[List[Floats2d], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"HashEmbedCNN\",\n        children: \"spacy.HashEmbedCNN.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.HashEmbedCNN.v2\\\"\\npretrained_vectors = null\\nwidth = 96\\ndepth = 4\\nembed_size = 2000\\nwindow_size = 1\\nmaxout_pieces = 3\\nsubword_features = true\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Build spaCy’s “standard” tok2vec layer. This layer is defined by a\\n\", _jsx(_components.a, {\n          href: \"/api/architectures#MultiHashEmbed\",\n          children: \"MultiHashEmbed\"\n        }), \" embedding layer that uses\\nsubword features, and a\\n\", _jsx(_components.a, {\n          href: \"/api/architectures#MaxoutWindowEncoder\",\n          children: \"MaxoutWindowEncoder\"\n        }), \" encoding layer\\nconsisting of a CNN and a layer-normalized maxout activation function.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The width of the input and output. These are required to be the same, so that residual connections can be used. Recommended values are \", _jsx(InlineCode, {\n                children: \"96\"\n              }), \", \", _jsx(InlineCode, {\n                children: \"128\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"300\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"depth\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of convolutional layers to use. Recommended values are between \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"8\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"embed_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of rows in the hash embedding tables. This can be surprisingly small, due to the use of the hash embeddings. Recommended values are between \", _jsx(InlineCode, {\n                children: \"2000\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"10000\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"window_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of tokens on either side to concatenate during the convolutions. The receptive field of the CNN will be \", _jsx(InlineCode, {\n                children: \"depth * (window_size * 2 + 1)\"\n              }), \", so a 4-layer network with a window size of \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" will be sensitive to 20 words at a time. Recommended value is \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"maxout_pieces\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of pieces to use in the maxout non-linearity. If \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \", the \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-layers#mish\",\n                children: _jsx(InlineCode, {\n                  children: \"Mish\"\n                })\n              }), \" non-linearity is used instead. Recommended values are \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \"-\", _jsx(InlineCode, {\n                children: \"3\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"subword_features\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether to also embed subword features, specifically the prefix, suffix and word shape. This is recommended for alphabetic languages like English, but not if single-character tokens are used for a language such as Chinese. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"pretrained_vectors\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether to also use static vectors. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"Tok2VecListener\",\n        children: \"spacy.Tok2VecListener.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[components.tok2vec]\\nfactory = \\\"tok2vec\\\"\\n\\n[components.tok2vec.model]\\n@architectures = \\\"spacy.HashEmbedCNN.v2\\\"\\nwidth = 342\\n\\n[components.tagger]\\nfactory = \\\"tagger\\\"\\n\\n[components.tagger.model]\\n@architectures = \\\"spacy.Tagger.v2\\\"\\n\\n[components.tagger.model.tok2vec]\\n@architectures = \\\"spacy.Tok2VecListener.v1\\\"\\nwidth = ${components.tok2vec.model.width}\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"A listener is used as a sublayer within a component such as a\\n\", _jsx(_components.a, {\n          href: \"/api/dependencyparser\",\n          children: _jsx(InlineCode, {\n            children: \"DependencyParser\"\n          })\n        }), \",\\n\", _jsx(_components.a, {\n          href: \"/api/entityrecognizer\",\n          children: _jsx(InlineCode, {\n            children: \"EntityRecognizer\"\n          })\n        }), \"or\\n\", _jsx(_components.a, {\n          href: \"/api/textcategorizer\",\n          children: _jsx(InlineCode, {\n            children: \"TextCategorizer\"\n          })\n        }), \". Usually you’ll have multiple\\nlisteners connecting to a single upstream \", _jsx(_components.a, {\n          href: \"/api/tok2vec\",\n          children: _jsx(InlineCode, {\n            children: \"Tok2Vec\"\n          })\n        }), \" component\\nthat’s earlier in the pipeline. The listener layers act as \", _jsx(_components.strong, {\n          children: \"proxies\"\n        }), \", passing\\nthe predictions from the \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" component into downstream components, and\\ncommunicating gradients back upstream.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Instead of defining its own \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" instance, a model architecture like\\n\", _jsx(_components.a, {\n          href: \"/api/architectures#tagger\",\n          children: \"Tagger\"\n        }), \" can define a listener as its \", _jsx(InlineCode, {\n          children: \"tok2vec\"\n        }), \"\\nargument that connects to the shared \", _jsx(InlineCode, {\n          children: \"tok2vec\"\n        }), \" component in the pipeline.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Listeners work by caching the \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" output for a given batch of \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"s. This\\nmeans that in order for a component to work with the listener, the batch of\\n\", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"s passed to the listener must be the same as the batch of \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"s passed to\\nthe \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \". As a result, any manipulation of the \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"s which would affect\\n\", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" output, such as to create special contexts or remove \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"s for which\\nno prediction can be made, must happen inside the model, \", _jsx(_components.strong, {\n          children: \"after\"\n        }), \" the call to\\nthe \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" component.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The width of the vectors produced by the “upstream” \", _jsx(_components.a, {\n                href: \"/api/tok2vec\",\n                children: _jsx(InlineCode, {\n                  children: \"Tok2Vec\"\n                })\n              }), \" component. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"upstream\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A string to identify the “upstream” \", _jsx(InlineCode, {\n                children: \"Tok2Vec\"\n              }), \" component to communicate with. By default, the upstream name is the wildcard string \", _jsx(InlineCode, {\n                children: \"\\\"*\\\"\"\n              }), \", but you could also specify the name of the \", _jsx(InlineCode, {\n                children: \"Tok2Vec\"\n              }), \" component. You’ll almost never have multiple upstream \", _jsx(InlineCode, {\n                children: \"Tok2Vec\"\n              }), \" components, so the wildcard string will almost always be fine. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"MultiHashEmbed\",\n        children: \"spacy.MultiHashEmbed.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.MultiHashEmbed.v2\\\"\\nwidth = 64\\nattrs = [\\\"NORM\\\", \\\"PREFIX\\\", \\\"SUFFIX\\\", \\\"SHAPE\\\"]\\nrows = [2000, 1000, 1000, 1000]\\ninclude_static_vectors = true\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Construct an embedding layer that separately embeds a number of lexical\\nattributes using hash embedding, concatenates the results, and passes it through\\na feed-forward subnetwork to build a mixed representation. The features used can\\nbe configured with the \", _jsx(InlineCode, {\n          children: \"attrs\"\n        }), \" argument. The suggested attributes are \", _jsx(InlineCode, {\n          children: \"NORM\"\n        }), \",\\n\", _jsx(InlineCode, {\n          children: \"PREFIX\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"SUFFIX\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"SHAPE\"\n        }), \". This lets the model take into account some\\nsubword information, without construction a fully character-based\\nrepresentation. If pretrained vectors are available, they can be included in the\\nrepresentation as well, with the vectors table kept static (i.e. it’s not\\nupdated).\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The output width. Also used as the width of the embedding tables. Recommended values are between \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"300\"\n              }), \". If static vectors are included, a learned linear layer is used to map the vectors to the specified width before concatenating it with the other embedding outputs. A single maxout layer is then used to reduce the concatenated vectors to the final width. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"attrs\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The token attributes to embed. A separate embedding table will be constructed for each attribute. \", _jsx(_components.del, {\n                children: \"List[Union[int, str]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"rows\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of rows for each embedding tables. Can be low, due to the hashing trick. Recommended values are between \", _jsx(InlineCode, {\n                children: \"1000\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"10000\"\n              }), \". The layer needs surprisingly few rows, due to its use of the hashing trick. Generally between 2000 and 10000 rows is sufficient, even for very large vocabularies. A number of rows must be specified for each table, so the \", _jsx(InlineCode, {\n                children: \"rows\"\n              }), \" list must be of the same length as the \", _jsx(InlineCode, {\n                children: \"attrs\"\n              }), \" parameter. \", _jsx(_components.del, {\n                children: \"List[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"include_static_vectors\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether to also use static word vectors. Requires a vectors table to be loaded in the \", _jsx(_components.a, {\n                href: \"/api/doc\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc\"\n                })\n              }), \" objects’ vocab. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"CharacterEmbed\",\n        children: \"spacy.CharacterEmbed.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.CharacterEmbed.v2\\\"\\nwidth = 128\\nrows = 7000\\nnM = 64\\nnC = 8\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"Construct an embedded representation based on character embeddings, using a\\nfeed-forward network. A fixed number of UTF-8 byte characters are used for each\\nword, taken from the beginning and end of the word equally. Padding is used in\\nthe center for words that are too short.\"\n      }), _jsxs(_components.p, {\n        children: [\"For instance, let’s say \", _jsx(InlineCode, {\n          children: \"nC=4\"\n        }), \", and the word is “jumping”. The characters used\\nwill be \", _jsx(InlineCode, {\n          children: \"\\\"jung\\\"\"\n        }), \" (two from the start, two from the end). If we had \", _jsx(InlineCode, {\n          children: \"nC=8\"\n        }), \", the\\ncharacters would be \", _jsx(InlineCode, {\n          children: \"\\\"jumpping\\\"\"\n        }), \": 4 from the start, 4 from the end. This ensures\\nthat the final character is always in the last position, instead of being in an\\narbitrary position depending on the word length.\"]\n      }), _jsxs(_components.p, {\n        children: [\"The characters are embedded in a embedding table with a given number of rows,\\nand the vectors concatenated. A hash-embedded vector of the \", _jsx(InlineCode, {\n          children: \"NORM\"\n        }), \" of the word\\nis also concatenated on, and the result is then passed through a feed-forward\\nnetwork to construct a single vector to represent the information.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The width of the output vector and the \", _jsx(InlineCode, {\n                children: \"NORM\"\n              }), \" hash embedding. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"rows\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of rows in the \", _jsx(InlineCode, {\n                children: \"NORM\"\n              }), \" hash embedding table. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nM\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The dimensionality of the character embeddings. Recommended values are between \", _jsx(InlineCode, {\n                children: \"16\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nC\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of UTF-8 bytes to embed per word. Recommended values are between \", _jsx(InlineCode, {\n                children: \"3\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"8\"\n              }), \", although it may depend on the length of words in the language. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"MaxoutWindowEncoder\",\n        children: \"spacy.MaxoutWindowEncoder.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.MaxoutWindowEncoder.v2\\\"\\nwidth = 128\\nwindow_size = 1\\nmaxout_pieces = 3\\ndepth = 4\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"Encode context using convolutions with maxout activation, layer normalization\\nand residual connections.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"300\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"window_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of words to concatenate around each token to construct the convolution. Recommended value is \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"maxout_pieces\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of maxout pieces to use. Recommended values are \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"3\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"depth\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of convolutional layers. Recommended value is \", _jsx(InlineCode, {\n                children: \"4\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Floats2d], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"MishWindowEncoder\",\n        children: \"spacy.MishWindowEncoder.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.MishWindowEncoder.v2\\\"\\nwidth = 64\\nwindow_size = 1\\ndepth = 4\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Encode context using convolutions with\\n\", _jsx(_components.a, {\n          href: \"https://thinc.ai/docs/api-layers#mish\",\n          children: _jsx(InlineCode, {\n            children: \"Mish\"\n          })\n        }), \" activation, layer normalization\\nand residual connections.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"300\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"window_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of words to concatenate around each token to construct the convolution. Recommended value is \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"depth\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of convolutional layers. Recommended value is \", _jsx(InlineCode, {\n                children: \"4\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Floats2d], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"TorchBiLSTMEncoder\",\n        children: \"spacy.TorchBiLSTMEncoder.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.TorchBiLSTMEncoder.v1\\\"\\nwidth = 64\\ndepth = 2\\ndropout = 0.0\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Encode context using bidirectional LSTM layers. Requires\\n\", _jsx(_components.a, {\n          href: \"https://pytorch.org\",\n          children: \"PyTorch\"\n        }), \".\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The input and output width. These are required to be the same, to allow residual connections. This value will be determined by the width of the inputs. Recommended values are between \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \" and \", _jsx(InlineCode, {\n                children: \"300\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"depth\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of recurrent layers, for instance \", _jsx(InlineCode, {\n                children: \"depth=2\"\n              }), \" results in stacking two LSTMs together. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"dropout\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Creates a Dropout layer on the outputs of each LSTM layer except the last layer. Set to 0.0 to disable this functionality. \", _jsx(_components.del, {\n                children: \"float\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Floats2d], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"StaticVectors\",\n        children: \"spacy.StaticVectors.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.StaticVectors.v2\\\"\\nnO = null\\nnM = null\\ndropout = 0.2\\nkey_attr = \\\"ORTH\\\"\\n\\n[model.init_W]\\n@initializers = \\\"glorot_uniform_init.v1\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Embed \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" objects with their vocab’s vectors table, applying a\\nlearned linear projection to control the dimensionality. Unknown tokens are\\nmapped to a zero vector. See the documentation on\\n\", _jsx(_components.a, {\n          href: \"/usage/embeddings-transformers#static-vectors\",\n          children: \"static vectors\"\n        }), \" for details.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The output width of the layer, after the linear projection. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nM\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The width of the static vectors. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"dropout\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Optional dropout rate. If set, it’s applied per dimension over the whole batch. Defaults to \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[float]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"init_W\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-initializers\",\n                children: \"initialization function\"\n              }), \". Defaults to \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-initializers#glorot_uniform_init\",\n                children: _jsx(InlineCode, {\n                  children: \"glorot_uniform_init\"\n                })\n              }), \". \", _jsx(_components.del, {\n                children: \"Callable[[Ops, Tuple[int, …]]], FloatsXd]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"key_attr\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Defaults to \", _jsx(InlineCode, {\n                children: \"\\\"ORTH\\\"\"\n              }), \". \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Ragged]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"FeatureExtractor\",\n        children: \"spacy.FeatureExtractor.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.FeatureExtractor.v1\\\"\\ncolumns = [\\\"NORM\\\", \\\"PREFIX\\\", \\\"SUFFIX\\\", \\\"SHAPE\\\", \\\"ORTH\\\"]\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Extract arrays of input features from \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" objects. Expects a list\\nof feature names to extract, which should refer to token attributes.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"columns\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The token attributes to extract. \", _jsx(_components.del, {\n                children: \"List[Union[int, str]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The created feature extraction layer. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Ints2d]]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-transformers\",\n      children: [_jsx(_components.h2, {\n        id: \"transformers\",\n        source: \"github.com/explosion/spacy-transformers/blob/master/spacy_transformers/architectures.py\",\n        children: \"Transformer architectures \"\n      }), _jsxs(_components.p, {\n        children: [\"The following architectures are provided by the package\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy-transformers\",\n          children: _jsx(InlineCode, {\n            children: \"spacy-transformers\"\n          })\n        }), \". See the\\n\", _jsx(_components.a, {\n          href: \"/usage/embeddings-transformers#transformers\",\n          children: \"usage documentation\"\n        }), \" for how to\\nintegrate the architectures into your training config.\"]\n      }), _jsx(Infobox, {\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"Note that in order to use these architectures in your config, you need to\\ninstall the\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spacy-transformers\",\n            children: _jsx(InlineCode, {\n              children: \"spacy-transformers\"\n            })\n          }), \". See the\\n\", _jsx(_components.a, {\n            href: \"/usage/embeddings-transformers#transformers-installation\",\n            children: \"installation docs\"\n          }), \"\\nfor details and system requirements.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"TransformerModel\",\n        children: \"spacy-transformers.TransformerModel.v3 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy-transformers.TransformerModel.v3\\\"\\nname = \\\"roberta-base\\\"\\ntokenizer_config = {\\\"use_fast\\\": true}\\ntransformer_config = {}\\nmixed_precision = true\\ngrad_scaler_config = {\\\"init_scale\\\": 32768}\\n\\n[model.get_spans]\\n@span_getters = \\\"spacy-transformers.strided_spans.v1\\\"\\nwindow = 128\\nstride = 96\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Load and wrap a transformer model from the\\n\", _jsxs(_components.a, {\n          href: \"https://huggingface.co/transformers\",\n          children: [\"HuggingFace \", _jsx(InlineCode, {\n            children: \"transformers\"\n          })]\n        }), \" library. You\\ncan use any transformer that has pretrained weights and a PyTorch\\nimplementation. The \", _jsx(InlineCode, {\n          children: \"name\"\n        }), \" variable is passed through to the underlying library,\\nso it can be either a string or a path. If it’s a string, the pretrained weights\\nwill be downloaded via the transformers library if they are not already\\navailable locally.\"]\n      }), _jsxs(_components.p, {\n        children: [\"In order to support longer documents, the\\n\", _jsx(_components.a, {\n          href: \"/api/architectures#TransformerModel\",\n          children: \"TransformerModel\"\n        }), \" layer allows you to pass\\nin a \", _jsx(InlineCode, {\n          children: \"get_spans\"\n        }), \" function that will divide up the \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" objects\\nbefore passing them through the transformer. Your spans are allowed to overlap\\nor exclude tokens. This layer is usually used directly by the\\n\", _jsx(_components.a, {\n          href: \"/api/transformer\",\n          children: _jsx(InlineCode, {\n            children: \"Transformer\"\n          })\n        }), \" component, which allows you to share the\\ntransformer weights across your pipeline. For a layer that’s configured for use\\nin other components, see\\n\", _jsx(_components.a, {\n          href: \"/api/architectures#Tok2VecTransformer\",\n          children: \"Tok2VecTransformer\"\n        }), \".\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"name\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Any model name that can be loaded by \", _jsx(_components.a, {\n                href: \"https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoModel\",\n                children: _jsx(InlineCode, {\n                  children: \"transformers.AutoModel\"\n                })\n              }), \". \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"get_spans\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Function that takes a batch of \", _jsx(_components.a, {\n                href: \"/api/doc\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc\"\n                })\n              }), \" object and returns lists of \", _jsx(_components.a, {\n                href: \"/api\",\n                children: _jsx(InlineCode, {\n                  children: \"Span\"\n                })\n              }), \" objects to process by the transformer. \", _jsx(_components.a, {\n                href: \"/api/transformer#span_getters\",\n                children: \"See here\"\n              }), \" for built-in options and examples. \", _jsx(_components.del, {\n                children: \"Callable[[List[Doc]], List[Span]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tokenizer_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Tokenizer settings passed to \", _jsx(_components.a, {\n                href: \"https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoTokenizer\",\n                children: _jsx(InlineCode, {\n                  children: \"transformers.AutoTokenizer\"\n                })\n              }), \". \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"transformer_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Transformer settings passed to \", _jsx(_components.a, {\n                href: \"https://huggingface.co/transformers/model_doc/auto.html?highlight=autoconfig#transformers.AutoConfig\",\n                children: _jsx(InlineCode, {\n                  children: \"transformers.AutoConfig\"\n                })\n              }), \" \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"mixed_precision\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Replace whitelisted ops by half-precision counterparts. Speeds up training and prediction on GPUs with \", _jsx(_components.a, {\n                href: \"https://developer.nvidia.com/tensor-cores\",\n                children: \"Tensor Cores\"\n              }), \" and reduces GPU memory use. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"grad_scaler_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Configuration to pass to \", _jsx(InlineCode, {\n                children: \"thinc.api.PyTorchGradScaler\"\n              }), \" during training when \", _jsx(InlineCode, {\n                children: \"mixed_precision\"\n              }), \" is enabled. \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], FullTransformerBatch]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {}), _jsx(_components.td, {})]\n          })]\n        })]\n      }), _jsx(Infobox, {\n        title: \"Mixed precision support\",\n        variant: \"warning\",\n        children: _jsx(_components.p, {\n          children: \"Mixed-precision support is currently an experimental feature.\"\n        })\n      }), _jsxs(Accordion, {\n        title: \"Previous versions of spacy-transformers.TransformerModel\",\n        spaced: true,\n        children: [_jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"transformer_config\"\n            }), \" argument was added in\\n\", _jsx(InlineCode, {\n              children: \"spacy-transformers.TransformerModel.v2\"\n            }), \".\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"mixed_precision\"\n            }), \" and \", _jsx(InlineCode, {\n              children: \"grad_scaler_config\"\n            }), \" arguments were added in\\n\", _jsx(InlineCode, {\n              children: \"spacy-transformers.TransformerModel.v3\"\n            }), \".\"]\n          }), \"\\n\"]\n        }), _jsx(_components.p, {\n          children: \"The other arguments are shared between all versions.\"\n        })]\n      }), _jsx(_components.h3, {\n        id: \"TransformerListener\",\n        children: \"spacy-transformers.TransformerListener.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy-transformers.TransformerListener.v1\\\"\\ngrad_factor = 1.0\\n\\n[model.pooling]\\n@layers = \\\"reduce_mean.v1\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Create a \", _jsx(InlineCode, {\n          children: \"TransformerListener\"\n        }), \" layer, which will connect to a\\n\", _jsx(_components.a, {\n          href: \"/api/transformer\",\n          children: _jsx(InlineCode, {\n            children: \"Transformer\"\n          })\n        }), \" component earlier in the pipeline. The layer\\ntakes a list of \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" objects as input, and produces a list of\\n2-dimensional arrays as output, with each array having one row per token. Most\\nspaCy models expect a sublayer with this signature, making it easy to connect\\nthem to a transformer model via this sublayer. Transformer models usually\\noperate over wordpieces, which usually don’t align one-to-one against spaCy\\ntokens. The layer therefore requires a reduction operation in order to calculate\\na single token vector given zero or more wordpiece vectors.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"pooling\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A reduction layer used to calculate the token vectors based on zero or more wordpiece vectors. If in doubt, mean pooling (see \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-layers#reduce_mean\",\n                children: _jsx(InlineCode, {\n                  children: \"reduce_mean\"\n                })\n              }), \") is usually a good choice. \", _jsx(_components.del, {\n                children: \"Model[Ragged, Floats2d]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"grad_factor\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Reweight gradients from the component before passing them upstream. You can set this to \", _jsx(InlineCode, {\n                children: \"0\"\n              }), \" to “freeze” the transformer weights with respect to the component, or use it to make some components more significant than others. Leaving it at \", _jsx(InlineCode, {\n                children: \"1.0\"\n              }), \" is usually fine. \", _jsx(_components.del, {\n                children: \"float\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"upstream\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A string to identify the “upstream” \", _jsx(InlineCode, {\n                children: \"Transformer\"\n              }), \" component to communicate with. By default, the upstream name is the wildcard string \", _jsx(InlineCode, {\n                children: \"\\\"*\\\"\"\n              }), \", but you could also specify the name of the \", _jsx(InlineCode, {\n                children: \"Transformer\"\n              }), \" component. You’ll almost never have multiple upstream \", _jsx(InlineCode, {\n                children: \"Transformer\"\n              }), \" components, so the wildcard string will almost always be fine. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"Tok2VecTransformer\",\n        children: \"spacy-transformers.Tok2VecTransformer.v3 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy-transformers.Tok2VecTransformer.v3\\\"\\nname = \\\"albert-base-v2\\\"\\ntokenizer_config = {\\\"use_fast\\\": false}\\ntransformer_config = {}\\ngrad_factor = 1.0\\nmixed_precision = true\\ngrad_scaler_config = {\\\"init_scale\\\": 32768}\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Use a transformer as a \", _jsx(_components.a, {\n          href: \"/api/tok2vec\",\n          children: _jsx(InlineCode, {\n            children: \"Tok2Vec\"\n          })\n        }), \" layer directly. This does\\n\", _jsx(_components.strong, {\n          children: \"not\"\n        }), \" allow multiple components to share the transformer weights and does\\n\", _jsx(_components.strong, {\n          children: \"not\"\n        }), \" allow the transformer to set annotations into the \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \"\\nobject, but it’s a \", _jsx(_components.strong, {\n          children: \"simpler solution\"\n        }), \" if you only need the transformer within\\none component.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"get_spans\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Function that takes a batch of \", _jsx(_components.a, {\n                href: \"/api/doc\",\n                children: _jsx(InlineCode, {\n                  children: \"Doc\"\n                })\n              }), \" object and returns lists of \", _jsx(_components.a, {\n                href: \"/api\",\n                children: _jsx(InlineCode, {\n                  children: \"Span\"\n                })\n              }), \" objects to process by the transformer. \", _jsx(_components.a, {\n                href: \"/api/transformer#span_getters\",\n                children: \"See here\"\n              }), \" for built-in options and examples. \", _jsx(_components.del, {\n                children: \"Callable[[List[Doc]], List[Span]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tokenizer_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Tokenizer settings passed to \", _jsx(_components.a, {\n                href: \"https://huggingface.co/transformers/model_doc/auto.html#transformers.AutoTokenizer\",\n                children: _jsx(InlineCode, {\n                  children: \"transformers.AutoTokenizer\"\n                })\n              }), \". \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"transformer_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Settings to pass to the transformers forward pass. \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"pooling\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A reduction layer used to calculate the token vectors based on zero or more wordpiece vectors. If in doubt, mean pooling (see \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-layers#reduce_mean\",\n                children: _jsx(InlineCode, {\n                  children: \"reduce_mean\"\n                })\n              }), \") is usually a good choice. \", _jsx(_components.del, {\n                children: \"Model[Ragged, Floats2d]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"grad_factor\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Reweight gradients from the component before passing them upstream. You can set this to \", _jsx(InlineCode, {\n                children: \"0\"\n              }), \" to “freeze” the transformer weights with respect to the component, or use it to make some components more significant than others. Leaving it at \", _jsx(InlineCode, {\n                children: \"1.0\"\n              }), \" is usually fine. \", _jsx(_components.del, {\n                children: \"float\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"mixed_precision\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Replace whitelisted ops by half-precision counterparts. Speeds up training and prediction on GPUs with \", _jsx(_components.a, {\n                href: \"https://developer.nvidia.com/tensor-cores\",\n                children: \"Tensor Cores\"\n              }), \" and reduces GPU memory use. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"grad_scaler_config\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Configuration to pass to \", _jsx(InlineCode, {\n                children: \"thinc.api.PyTorchGradScaler\"\n              }), \" during training when \", _jsx(InlineCode, {\n                children: \"mixed_precision\"\n              }), \" is enabled. \", _jsx(_components.del, {\n                children: \"Dict[str, Any]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(Infobox, {\n        title: \"Mixed precision support\",\n        variant: \"warning\",\n        children: _jsx(_components.p, {\n          children: \"Mixed-precision support is currently an experimental feature.\"\n        })\n      }), _jsxs(Accordion, {\n        title: \"Previous versions of spacy-transformers.Tok2VecTransformer\",\n        spaced: true,\n        children: [_jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"transformer_config\"\n            }), \" argument was added in\\n\", _jsx(InlineCode, {\n              children: \"spacy-transformers.Tok2VecTransformer.v2\"\n            }), \".\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"mixed_precision\"\n            }), \" and \", _jsx(InlineCode, {\n              children: \"grad_scaler_config\"\n            }), \" arguments were added in\\n\", _jsx(InlineCode, {\n              children: \"spacy-transformers.Tok2VecTransformer.v3\"\n            }), \".\"]\n          }), \"\\n\"]\n        }), _jsx(_components.p, {\n          children: \"The other arguments are shared between all versions.\"\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-pretrain\",\n      children: [_jsx(_components.h2, {\n        id: \"pretrain\",\n        source: \"spacy/ml/models/multi_task.py\",\n        children: \"Pretraining architectures \"\n      }), _jsxs(_components.p, {\n        children: [\"The spacy \", _jsx(InlineCode, {\n          children: \"pretrain\"\n        }), \" command lets you initialize a \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" layer in your\\npipeline with information from raw text. To this end, additional layers are\\nadded to build a network for a temporary task that forces the \", _jsx(InlineCode, {\n          children: \"Tok2Vec\"\n        }), \" layer to\\nlearn something about sentence structure and word cooccurrence statistics. Two\\npretraining objectives are available, both of which are variants of the cloze\\ntask \", _jsx(_components.a, {\n          href: \"https://arxiv.org/abs/1810.04805\",\n          children: \"Devlin et al. (2018)\"\n        }), \" introduced for\\nBERT.\"]\n      }), _jsxs(_components.p, {\n        children: [\"For more information, see the section on\\n\", _jsx(_components.a, {\n          href: \"/usage/embeddings-transformers#pretraining\",\n          children: \"pretraining\"\n        }), \".\"]\n      }), _jsx(_components.h3, {\n        id: \"pretrain_vectors\",\n        children: \"spacy.PretrainVectors.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[pretraining]\\ncomponent = \\\"tok2vec\\\"\\n\\n[initialize]\\nvectors = \\\"en_core_web_lg\\\"\\n...\\n\\n[pretraining.objective]\\n@architectures = \\\"spacy.PretrainVectors.v1\\\"\\nmaxout_pieces = 3\\nhidden_size = 300\\nloss = \\\"cosine\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Predict the word’s vector from a static embeddings table as pretraining\\nobjective for a Tok2Vec layer. To use this objective, make sure that the\\n\", _jsx(InlineCode, {\n          children: \"initialize.vectors\"\n        }), \" section in the config refers to a model with static\\nvectors.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"maxout_pieces\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of maxout pieces to use. Recommended values are \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"3\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Size of the hidden layer of the model. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"loss\"\n              })\n            }), _jsx(_components.td, {\n              children: \"The loss function can be either “cosine” or “L2”. We typically recommend to use “cosine”. ~~~str~~\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A callable function that can create the Model, given the \", _jsx(InlineCode, {\n                children: \"vocab\"\n              }), \" of the pipeline and the \", _jsx(InlineCode, {\n                children: \"tok2vec\"\n              }), \" layer to pretrain. \", _jsx(_components.del, {\n                children: \"Callable[[Vocab, Model], Model]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"pretrain_chars\",\n        children: \"spacy.PretrainCharacters.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[pretraining]\\ncomponent = \\\"tok2vec\\\"\\n...\\n\\n[pretraining.objective]\\n@architectures = \\\"spacy.PretrainCharacters.v1\\\"\\nmaxout_pieces = 3\\nhidden_size = 300\\nn_characters = 4\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"Predict some number of leading and trailing UTF-8 bytes as pretraining objective\\nfor a Tok2Vec layer.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"maxout_pieces\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of maxout pieces to use. Recommended values are \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"3\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Size of the hidden layer of the model. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"n_characters\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The window of characters - e.g. if \", _jsx(InlineCode, {\n                children: \"n_characters = 2\"\n              }), \", the model will try to predict the first two and last two characters of the word. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A callable function that can create the Model, given the \", _jsx(InlineCode, {\n                children: \"vocab\"\n              }), \" of the pipeline and the \", _jsx(InlineCode, {\n                children: \"tok2vec\"\n              }), \" layer to pretrain. \", _jsx(_components.del, {\n                children: \"Callable[[Vocab, Model], Model]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-parser\",\n      children: [_jsx(_components.h2, {\n        id: \"parser\",\n        children: \"Parser \u0026 NER architectures \"\n      }), _jsx(_components.h3, {\n        id: \"TransitionBasedParser\",\n        source: \"spacy/ml/models/parser.py\",\n        children: \"spacy.TransitionBasedParser.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.TransitionBasedParser.v2\\\"\\nstate_type = \\\"ner\\\"\\nextra_state_tokens = false\\nhidden_width = 64\\nmaxout_pieces = 2\\nuse_upper = true\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy.HashEmbedCNN.v2\\\"\\npretrained_vectors = null\\nwidth = 96\\ndepth = 4\\nembed_size = 2000\\nwindow_size = 1\\nmaxout_pieces = 3\\nsubword_features = true\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Build a transition-based parser model. Can apply to NER or dependency parsing.\\nTransition-based parsing is an approach to structured prediction where the task\\nof predicting the structure is mapped to a series of state transitions. You\\nmight find \", _jsx(_components.a, {\n          href: \"https://explosion.ai/blog/parsing-english-in-python\",\n          children: \"this tutorial\"\n        }), \"\\nhelpful for background information. The neural network state prediction model\\nconsists of either two or three subnetworks:\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"tok2vec\"\n          }), \": Map each token into a vector representation. This subnetwork is\\nrun once for each batch.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"lower\"\n          }), \": Construct a feature-specific vector for each \", _jsx(InlineCode, {\n            children: \"(token, feature)\"\n          }), \"\\npair. This is also run once for each batch. Constructing the state\\nrepresentation is then a matter of summing the component features and applying\\nthe non-linearity.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"upper\"\n          }), \" (optional): A feed-forward network that predicts scores from the\\nstate representation. If not present, the output from the lower model is used\\nas action scores directly.\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Subnetwork to map tokens into vector representations. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"state_type\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Which task to extract features for. Possible values are “ner” and “parser”. \", _jsx(_components.del, {\n                children: \"str\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"extra_state_tokens\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether to use an expanded feature set when extracting the state tokens. Slightly slower, but sometimes improves accuracy slightly. Defaults to \", _jsx(InlineCode, {\n                children: \"False\"\n              }), \". \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_width\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The width of the hidden layer. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"maxout_pieces\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"How many pieces to use in the state prediction layer. Recommended values are \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \", \", _jsx(InlineCode, {\n                children: \"2\"\n              }), \" or \", _jsx(InlineCode, {\n                children: \"3\"\n              }), \". If \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \", the maxout non-linearity is replaced with a \", _jsx(_components.a, {\n                href: \"https://thinc.ai/docs/api-layers#relu\",\n                children: _jsx(InlineCode, {\n                  children: \"Relu\"\n                })\n              }), \" non-linearity if \", _jsx(InlineCode, {\n                children: \"use_upper\"\n              }), \" is \", _jsx(InlineCode, {\n                children: \"True\"\n              }), \", and no non-linearity if \", _jsx(InlineCode, {\n                children: \"False\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"use_upper\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether to use an additional hidden layer after the state vector in order to predict the action scores. It is recommended to set this to \", _jsx(InlineCode, {\n                children: \"False\"\n              }), \" for large pretrained models such as transformers, and \", _jsx(InlineCode, {\n                children: \"True\"\n              }), \" for smaller networks. The upper layer is computed on CPU, which becomes a bottleneck on larger GPU-based models, where it’s also less necessary. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of actions the model will predict between. Usually inferred from data at the beginning of training, or loaded from disk. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Docs], List[List[Floats2d]]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(Accordion, {\n        title: \"spacy.TransitionBasedParser.v1 definition\",\n        spaced: true,\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.a, {\n            href: \"/api/legacy#TransitionBasedParser_v1\",\n            children: \"TransitionBasedParser.v1\"\n          }), \" had the exact\\nsame signature, but the \", _jsx(InlineCode, {\n            children: \"use_upper\"\n          }), \" argument was \", _jsx(InlineCode, {\n            children: \"True\"\n          }), \" by default.\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-tagger\",\n      children: [_jsx(_components.h2, {\n        id: \"tagger\",\n        source: \"spacy/ml/models/tagger.py\",\n        children: \"Tagging architectures \"\n      }), _jsx(_components.h3, {\n        id: \"Tagger\",\n        children: \"spacy.Tagger.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.Tagger.v2\\\"\\nnO = null\\nnormalize = false\\n\\n[model.tok2vec]\\n# ...\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"Build a tagger model, using a provided token-to-vector component. The tagger\\nmodel adds a linear layer with softmax activation to predict scores given the\\ntoken vectors.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Subnetwork to map tokens into vector representations. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of tags to output. Inferred from the data if \", _jsx(InlineCode, {\n                children: \"None\"\n              }), \". \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"normalize\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Normalize probabilities during inference. Defaults to \", _jsx(InlineCode, {\n                children: \"False\"\n              }), \". \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsxs(Accordion, {\n        title: \"Previous versions of spacy.Tagger\",\n        spaced: true,\n        children: [_jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [\"The \", _jsx(InlineCode, {\n              children: \"normalize\"\n            }), \" argument was added in \", _jsx(InlineCode, {\n              children: \"spacy.Tagger.v2\"\n            }), \". \", _jsx(InlineCode, {\n              children: \"spacy.Tagger.v1\"\n            }), \"\\nalways normalizes probabilities during inference.\"]\n          }), \"\\n\"]\n        }), _jsx(_components.p, {\n          children: \"The other arguments are shared between all versions.\"\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-textcat\",\n      children: [_jsx(_components.h2, {\n        id: \"textcat\",\n        source: \"spacy/ml/models/textcat.py\",\n        children: \"Text classification architectures \"\n      }), _jsxs(_components.p, {\n        children: [\"A text classification architecture needs to take a \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" as input,\\nand produce a score for each potential label class. Textcat challenges can be\\nbinary (e.g. sentiment analysis) or involve multiple possible labels.\\nMulti-label challenges can either have mutually exclusive labels (each example\\nhas exactly one label), or multiple labels may be applicable at the same time.\"]\n      }), _jsx(_components.p, {\n        children: \"As the properties of text classification problems can vary widely, we provide\\nseveral different built-in architectures. It is recommended to experiment with\\ndifferent architectures and settings to determine what works best on your\\nspecific data and challenge.\"\n      }), _jsx(Infobox, {\n        title: \"Single-label vs. multi-label classification\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"When the architecture for a text classification challenge contains a setting for\\n\", _jsx(InlineCode, {\n            children: \"exclusive_classes\"\n          }), \", it is important to use the correct value for the correct\\npipeline component. The \", _jsx(InlineCode, {\n            children: \"textcat\"\n          }), \" component should always be used for\\nsingle-label use-cases where \", _jsx(InlineCode, {\n            children: \"exclusive_classes = true\"\n          }), \", while the\\n\", _jsx(InlineCode, {\n            children: \"textcat_multilabel\"\n          }), \" should be used for multi-label settings with\\n\", _jsx(InlineCode, {\n            children: \"exclusive_classes = false\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"TextCatEnsemble\",\n        children: \"spacy.TextCatEnsemble.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.TextCatEnsemble.v2\\\"\\nnO = null\\n\\n[model.linear_model]\\n@architectures = \\\"spacy.TextCatBOW.v2\\\"\\nexclusive_classes = true\\nngram_size = 1\\nno_output_layer = false\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy.Tok2Vec.v2\\\"\\n\\n[model.tok2vec.embed]\\n@architectures = \\\"spacy.MultiHashEmbed.v2\\\"\\nwidth = 64\\nrows = [2000, 2000, 1000, 1000, 1000, 1000]\\nattrs = [\\\"ORTH\\\", \\\"LOWER\\\", \\\"PREFIX\\\", \\\"SUFFIX\\\", \\\"SHAPE\\\", \\\"ID\\\"]\\ninclude_static_vectors = false\\n\\n[model.tok2vec.encode]\\n@architectures = \\\"spacy.MaxoutWindowEncoder.v2\\\"\\nwidth = ${model.tok2vec.embed.width}\\nwindow_size = 1\\nmaxout_pieces = 3\\ndepth = 2\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Stacked ensemble of a linear bag-of-words model and a neural network model. The\\nneural network is built upon a Tok2Vec layer and uses attention. The setting for\\nwhether or not this model should cater for multi-label classification, is taken\\nfrom the linear model, where it is stored in \", _jsx(InlineCode, {\n          children: \"model.attrs[\\\"multi_label\\\"]\"\n        }), \".\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"linear_model\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The linear bag-of-words model. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(InlineCode, {\n                children: \"tok2vec\"\n              }), \" layer to build the neural network upon. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Output dimension, determined by the number of different labels. If not set, the \", _jsx(_components.a, {\n                href: \"/api/textcategorizer\",\n                children: _jsx(InlineCode, {\n                  children: \"TextCategorizer\"\n                })\n              }), \" component will set it when \", _jsx(InlineCode, {\n                children: \"initialize\"\n              }), \" is called. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsxs(Accordion, {\n        title: \"spacy.TextCatEnsemble.v1 definition\",\n        spaced: true,\n        children: [_jsxs(_components.p, {\n          children: [_jsx(_components.a, {\n            href: \"/api/legacy#TextCatEnsemble_v1\",\n            children: \"TextCatEnsemble.v1\"\n          }), \" was functionally similar,\\nbut used an internal \", _jsx(InlineCode, {\n            children: \"tok2vec\"\n          }), \" instead of taking it as argument:\"]\n        }), _jsxs(_components.table, {\n          children: [_jsx(_components.thead, {\n            children: _jsxs(_components.tr, {\n              children: [_jsx(_components.th, {\n                children: \"Name\"\n              }), _jsx(_components.th, {\n                children: \"Description\"\n              })]\n            })\n          }), _jsxs(_components.tbody, {\n            children: [_jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"exclusive_classes\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Whether or not categories are mutually exclusive. \", _jsx(_components.del, {\n                  children: \"bool\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"pretrained_vectors\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Whether or not pretrained vectors will be used in addition to the feature vectors. \", _jsx(_components.del, {\n                  children: \"bool\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"width\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Output dimension of the feature encoding step. \", _jsx(_components.del, {\n                  children: \"int\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"embed_size\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Input dimension of the feature encoding step. \", _jsx(_components.del, {\n                  children: \"int\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"conv_depth\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Depth of the tok2vec layer. \", _jsx(_components.del, {\n                  children: \"int\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"window_size\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"The number of contextual vectors to \", _jsx(_components.a, {\n                  href: \"https://thinc.ai/docs/api-layers#expand_window\",\n                  children: \"concatenate\"\n                }), \" from the left and from the right. \", _jsx(_components.del, {\n                  children: \"int\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"ngram_size\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Determines the maximum length of the n-grams in the BOW model. For instance, \", _jsx(InlineCode, {\n                  children: \"ngram_size=3\"\n                }), \"would give unigram, trigram and bigram features. \", _jsx(_components.del, {\n                  children: \"int\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"dropout\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"The dropout rate. \", _jsx(_components.del, {\n                  children: \"float\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(InlineCode, {\n                  children: \"nO\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"Output dimension, determined by the number of different labels. If not set, the \", _jsx(_components.a, {\n                  href: \"/api/textcategorizer\",\n                  children: _jsx(InlineCode, {\n                    children: \"TextCategorizer\"\n                  })\n                }), \" component will set it when \", _jsx(InlineCode, {\n                  children: \"initialize\"\n                }), \" is called. \", _jsx(_components.del, {\n                  children: \"Optional[int]\"\n                })]\n              })]\n            }), _jsxs(_components.tr, {\n              children: [_jsx(_components.td, {\n                children: _jsx(_components.strong, {\n                  children: \"CREATES\"\n                })\n              }), _jsxs(_components.td, {\n                children: [\"The model using the architecture. \", _jsx(_components.del, {\n                  children: \"Model[List[Doc], Floats2d]\"\n                })]\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"TextCatCNN\",\n        children: \"spacy.TextCatCNN.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.TextCatCNN.v2\\\"\\nexclusive_classes = false\\nnO = null\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy.HashEmbedCNN.v2\\\"\\npretrained_vectors = null\\nwidth = 96\\ndepth = 4\\nembed_size = 2000\\nwindow_size = 1\\nmaxout_pieces = 3\\nsubword_features = true\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"A neural network model where token vectors are calculated using a CNN. The\\nvectors are mean pooled and used as features in a feed-forward network. This\\narchitecture is usually less accurate than the ensemble, but runs faster.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclusive_classes\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether or not categories are mutually exclusive. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(_components.a, {\n                href: \"#tok2vec\",\n                children: _jsx(InlineCode, {\n                  children: \"tok2vec\"\n                })\n              }), \" layer of the model. \", _jsx(_components.del, {\n                children: \"Model\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Output dimension, determined by the number of different labels. If not set, the \", _jsx(_components.a, {\n                href: \"/api/textcategorizer\",\n                children: _jsx(InlineCode, {\n                  children: \"TextCategorizer\"\n                })\n              }), \" component will set it when \", _jsx(InlineCode, {\n                children: \"initialize\"\n              }), \" is called. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(Accordion, {\n        title: \"spacy.TextCatCNN.v1 definition\",\n        spaced: true,\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.a, {\n            href: \"/api/legacy#TextCatCNN_v1\",\n            children: \"TextCatCNN.v1\"\n          }), \" had the exact same signature, but was\\nnot yet resizable. Since v2, new labels can be added to this component, even\\nafter training.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"TextCatBOW\",\n        children: \"spacy.TextCatBOW.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.TextCatBOW.v2\\\"\\nexclusive_classes = false\\nngram_size = 1\\nno_output_layer = false\\nnO = null\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.p, {\n        children: \"An n-gram “bag-of-words” model. This architecture should run much faster than\\nthe others, but may not be as accurate, especially if texts are short.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"exclusive_classes\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether or not categories are mutually exclusive. \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"ngram_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Determines the maximum length of the n-grams in the BOW model. For instance, \", _jsx(InlineCode, {\n                children: \"ngram_size=3\"\n              }), \" would give unigram, trigram and bigram features. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"no_output_layer\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Whether or not to add an output layer to the model (\", _jsx(InlineCode, {\n                children: \"Softmax\"\n              }), \" activation if \", _jsx(InlineCode, {\n                children: \"exclusive_classes\"\n              }), \" is \", _jsx(InlineCode, {\n                children: \"True\"\n              }), \", else \", _jsx(InlineCode, {\n                children: \"Logistic\"\n              }), \"). \", _jsx(_components.del, {\n                children: \"bool\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Output dimension, determined by the number of different labels. If not set, the \", _jsx(_components.a, {\n                href: \"/api/textcategorizer\",\n                children: _jsx(InlineCode, {\n                  children: \"TextCategorizer\"\n                })\n              }), \" component will set it when \", _jsx(InlineCode, {\n                children: \"initialize\"\n              }), \" is called. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(Accordion, {\n        title: \"spacy.TextCatBOW.v1 definition\",\n        spaced: true,\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.a, {\n            href: \"/api/legacy#TextCatBOW_v1\",\n            children: \"TextCatBOW.v1\"\n          }), \" had the exact same signature, but was\\nnot yet resizable. Since v2, new labels can be added to this component, even\\nafter training.\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-spancat\",\n      children: [_jsx(_components.h2, {\n        id: \"spancat\",\n        source: \"spacy/ml/models/spancat.py\",\n        children: \"Span classification architectures \"\n      }), _jsx(_components.h3, {\n        id: \"SpanCategorizer\",\n        children: \"spacy.SpanCategorizer.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.SpanCategorizer.v1\\\"\\nscorer = {\\\"@layers\\\": \\\"spacy.LinearLogistic.v1\\\"}\\n\\n[model.reducer]\\n@layers = spacy.mean_max_reducer.v1\\\"\\nhidden_size = 128\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy.Tok2Vec.v1\\\"\\n\\n[model.tok2vec.embed]\\n@architectures = \\\"spacy.MultiHashEmbed.v1\\\"\\n# ...\\n\\n[model.tok2vec.encode]\\n@architectures = \\\"spacy.MaxoutWindowEncoder.v1\\\"\\n# ...\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Build a span categorizer model to power a\\n\", _jsx(_components.a, {\n          href: \"/api/spancategorizer\",\n          children: _jsx(InlineCode, {\n            children: \"SpanCategorizer\"\n          })\n        }), \" component, given a token-to-vector\\nmodel, a reducer model to map the sequence of vectors for each span down to a\\nsingle vector, and a scorer model to map the vectors to probabilities.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The token-to-vector model. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[Floats2d]]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"reducer\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The reducer model. \", _jsx(_components.del, {\n                children: \"Model[Ragged, Floats2d]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"scorer\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The scorer model. \", _jsx(_components.del, {\n                children: \"Model[Floats2d, Floats2d]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[Tuple[List[Doc], Ragged], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"mean_max_reducer\",\n        children: \"spacy.mean_max_reducer.v1 \"\n      }), _jsx(_components.p, {\n        children: \"Reduce sequences by concatenating their mean and max pooled vectors, and then\\ncombine the concatenated vectors with a hidden layer.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsx(_components.tbody, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The size of the hidden layer. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          })\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-entitylinker\",\n      children: [_jsx(_components.h2, {\n        id: \"entitylinker\",\n        source: \"spacy/ml/models/entity_linker.py\",\n        children: \"Entity linking architectures \"\n      }), _jsxs(_components.p, {\n        children: [\"An \", _jsx(_components.a, {\n          href: \"/api/entitylinker\",\n          children: _jsx(InlineCode, {\n            children: \"EntityLinker\"\n          })\n        }), \" component disambiguates textual mentions\\n(tagged as named entities) to unique identifiers, grounding the named entities\\ninto the “real world”. This requires 3 main components:\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [\"A \", _jsx(_components.a, {\n            href: \"/api/kb\",\n            children: _jsx(InlineCode, {\n              children: \"KnowledgeBase\"\n            })\n          }), \" (KB) holding the unique identifiers, potential\\nsynonyms and prior probabilities.\"]\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"A candidate generation step to produce a set of likely identifiers, given a\\ncertain textual mention.\"\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"A machine learning \", _jsx(_components.a, {\n            href: \"https://thinc.ai/docs/api-model\",\n            children: _jsx(InlineCode, {\n              children: \"Model\"\n            })\n          }), \" that picks the\\nmost plausible ID from the set of candidates.\"]\n        }), \"\\n\"]\n      }), _jsx(_components.h3, {\n        id: \"EntityLinker\",\n        children: \"spacy.EntityLinker.v2 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[model]\\n@architectures = \\\"spacy.EntityLinker.v2\\\"\\nnO = null\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy.HashEmbedCNN.v2\\\"\\npretrained_vectors = null\\nwidth = 96\\ndepth = 2\\nembed_size = 2000\\nwindow_size = 1\\nmaxout_pieces = 3\\nsubword_features = true\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(InlineCode, {\n          children: \"EntityLinker\"\n        }), \" model architecture is a Thinc \", _jsx(InlineCode, {\n          children: \"Model\"\n        }), \" with a\\n\", _jsx(_components.a, {\n          href: \"https://thinc.ai/api-layers#linear\",\n          children: _jsx(InlineCode, {\n            children: \"Linear\"\n          })\n        }), \" output layer.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(_components.a, {\n                href: \"#tok2vec\",\n                children: _jsx(InlineCode, {\n                  children: \"tok2vec\"\n                })\n              }), \" layer of the model. \", _jsx(_components.del, {\n                children: \"Model\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"nO\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Output dimension, determined by the length of the vectors encoding each entity in the KB. If the \", _jsx(InlineCode, {\n                children: \"nO\"\n              }), \" dimension is not set, the entity linking component will set it when \", _jsx(InlineCode, {\n                children: \"initialize\"\n              }), \" is called. \", _jsx(_components.del, {\n                children: \"Optional[int]\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"EmptyKB\",\n        children: \"spacy.EmptyKB.v1 \"\n      }), _jsxs(_components.p, {\n        children: [\"A function that creates an empty \", _jsx(InlineCode, {\n          children: \"KnowledgeBase\"\n        }), \" from a \", _jsx(_components.a, {\n          href: \"/api/vocab\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab\"\n          })\n        }), \"\\ninstance. This is the default when a new entity linker component is created.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsx(_components.tbody, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"entity_vector_length\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The length of the vectors encoding each entity in the KB. Defaults to \", _jsx(InlineCode, {\n                children: \"64\"\n              }), \". \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          })\n        })]\n      }), _jsx(_components.h3, {\n        id: \"KBFromFile\",\n        children: \"spacy.KBFromFile.v1 \"\n      }), _jsxs(_components.p, {\n        children: [\"A function that reads an existing \", _jsx(InlineCode, {\n          children: \"KnowledgeBase\"\n        }), \" from file.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsx(_components.tbody, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"kb_path\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The location of the KB that was stored to file. \", _jsx(_components.del, {\n                children: \"Path\"\n              })]\n            })]\n          })\n        })]\n      }), _jsx(_components.h3, {\n        id: \"CandidateGenerator\",\n        children: \"spacy.CandidateGenerator.v1 \"\n      }), _jsxs(_components.p, {\n        children: [\"A function that takes as input a \", _jsx(_components.a, {\n          href: \"/api/kb\",\n          children: _jsx(InlineCode, {\n            children: \"KnowledgeBase\"\n          })\n        }), \" and a\\n\", _jsx(_components.a, {\n          href: \"/api/span\",\n          children: _jsx(InlineCode, {\n            children: \"Span\"\n          })\n        }), \" object denoting a named entity, and returns a list of\\nplausible \", _jsx(_components.a, {\n          href: \"/api/kb/#candidate\",\n          children: _jsx(InlineCode, {\n            children: \"Candidate\"\n          })\n        }), \" objects. The default\\n\", _jsx(InlineCode, {\n          children: \"CandidateGenerator\"\n        }), \" uses the text of a mention to find its potential aliases in\\nthe \", _jsx(InlineCode, {\n          children: \"KnowledgeBase\"\n        }), \". Note that this function is case-dependent.\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-coref-architectures\",\n      children: [_jsx(_components.h2, {\n        id: \"coref-architectures\",\n        tag: \"experimental\",\n        children: \"Coreference \"\n      }), _jsxs(_components.p, {\n        children: [\"A \", _jsx(_components.a, {\n          href: \"/api/coref\",\n          children: _jsx(InlineCode, {\n            children: \"CoreferenceResolver\"\n          })\n        }), \" component identifies tokens that refer to\\nthe same entity. A \", _jsx(_components.a, {\n          href: \"/api/span-resolver\",\n          children: _jsx(InlineCode, {\n            children: \"SpanResolver\"\n          })\n        }), \" component infers spans\\nfrom single tokens. Together these components can be used to reproduce\\ntraditional coreference models. You can also omit the \", _jsx(InlineCode, {\n          children: \"SpanResolver\"\n        }), \" if working\\nwith only token-level clusters is acceptable.\"]\n      }), _jsx(_components.h3, {\n        id: \"Coref\",\n        tag: \"experimental\",\n        children: \"spacy-experimental.Coref.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"\\n[model]\\n@architectures = \\\"spacy-experimental.Coref.v1\\\"\\ndistance_embedding_size = 20\\ndropout = 0.3\\nhidden_size = 1024\\ndepth = 2\\nantecedent_limit = 50\\nantecedent_batch_size = 512\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy-transformers.TransformerListener.v1\\\"\\ngrad_factor = 1.0\\nupstream = \\\"transformer\\\"\\npooling = {\\\"@layers\\\":\\\"reduce_mean.v1\\\"}\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(InlineCode, {\n          children: \"Coref\"\n        }), \" model architecture is a Thinc \", _jsx(InlineCode, {\n          children: \"Model\"\n        }), \".\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(_components.a, {\n                href: \"#tok2vec\",\n                children: _jsx(InlineCode, {\n                  children: \"tok2vec\"\n                })\n              }), \" layer of the model. \", _jsx(_components.del, {\n                children: \"Model\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"distance_embedding_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A representation of the distance between candidates. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"dropout\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The dropout to use internally. Unlike some Thinc models, this has separate dropout for the internal PyTorch layers. \", _jsx(_components.del, {\n                children: \"float\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Size of the main internal layers. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"depth\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Depth of the internal network. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"antecedent_limit\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"How many candidate antecedents to keep after rough scoring. This has a significant effect on memory usage. Typical values would be 50 to 200, or higher for very long documents. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"antecedent_batch_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Internal batch size. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], Floats2d]\"\n              })]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"SpanResolver\",\n        tag: \"experimental\",\n        children: \"spacy-experimental.SpanResolver.v1 \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example Config\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"\\n[model]\\n@architectures = \\\"spacy-experimental.SpanResolver.v1\\\"\\nhidden_size = 1024\\ndistance_embedding_size = 64\\nconv_channels = 4\\nwindow_size = 1\\nmax_distance = 128\\nprefix = \\\"coref_head_clusters\\\"\\n\\n[model.tok2vec]\\n@architectures = \\\"spacy-transformers.TransformerListener.v1\\\"\\ngrad_factor = 1.0\\nupstream = \\\"transformer\\\"\\npooling = {\\\"@layers\\\":\\\"reduce_mean.v1\\\"}\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(InlineCode, {\n          children: \"SpanResolver\"\n        }), \" model architecture is a Thinc \", _jsx(InlineCode, {\n          children: \"Model\"\n        }), \". Note that\\n\", _jsx(InlineCode, {\n          children: \"MentionClusters\"\n        }), \" is \", _jsx(InlineCode, {\n          children: \"List[List[Tuple[int, int]]]\"\n        }), \".\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"tok2vec\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The \", _jsx(_components.a, {\n                href: \"#tok2vec\",\n                children: _jsx(InlineCode, {\n                  children: \"tok2vec\"\n                })\n              }), \" layer of the model. \", _jsx(_components.del, {\n                children: \"Model\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"hidden_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Size of the main internal layers. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"distance_embedding_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"A representation of the distance between two candidates. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"conv_channels\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of channels in the internal CNN. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"window_size\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The number of neighboring tokens to consider in the internal CNN. \", _jsx(InlineCode, {\n                children: \"1\"\n              }), \" means consider one token on each side. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"max_distance\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The longest possible length of a predicted span. \", _jsx(_components.del, {\n                children: \"int\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"prefix\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The prefix that indicates spans to use for input data. \", _jsx(_components.del, {\n                children: \"string\"\n              })]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"CREATES\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"The model using the architecture. \", _jsx(_components.del, {\n                children: \"Model[List[Doc], List[MentionClusters]]\"\n              })]\n            })]\n          })]\n        })]\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"Model Architectures","teaser":"Pre-defined model architectures included with the core library","source":"spacy/ml/models","menu":[["Tok2Vec","tok2vec-arch"],["Transformers","transformers"],["Pretraining","pretrain"],["Parser \u0026 NER","parser"],["Tagging","tagger"],["Text Classification","textcat"],["Span Classification","spancat"],["Entity Linking","entitylinker"],["Coreference","coref-architectures"]]},"scope":{}},"sectionTitle":"API Documentation","theme":"green","section":"api","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":null},"__N_SSG":true},"page":"/[...listPathPage]","query":{"listPathPage":["api","architectures"]},"buildId":"Ugre-usgT1EZhnSeYcBR9","isFallback":false,"dynamicIds":[728],"gsp":true,"scriptLoader":[]}</script></body></html>