<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="shortcut icon" href="/icons/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=5.0, shrink-to-fit=no, viewport-fit=cover"/><meta name="theme-color" content="#09a3d5"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png"/><title>What&#x27;s New in v2.3 Â· spaCy Usage Documentation</title><meta name="description" content="New features, backwards incompatibilities and migration guide"/><meta property="og:title" content="What&#x27;s New in v2.3 Â· spaCy Usage Documentation"/><meta property="og:description" content="New features, backwards incompatibilities and migration guide"/><meta property="og:type" content="website"/><meta property="og:site_name" content="What&#x27;s New in v2.3"/><meta property="og:image" content="https://noewangjy.github.io/test-website//_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:image" content="https://noewangjy.github.io/test-website//_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:creator" content="@spacy_io"/><meta name="twitter:site" content="@spacy_io"/><meta name="twitter:title" content="What&#x27;s New in v2.3 Â· spaCy Usage Documentation"/><meta name="twitter:description" content="New features, backwards incompatibilities and migration guide"/><meta name="docsearch:language" content="en"/><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/8f0b94edbc18d62d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f0b94edbc18d62d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e6995e0e8addcf99.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e6995e0e8addcf99.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/262.c647d33d06232ef6.js"></script><script defer="" src="/_next/static/chunks/728.cf6ba0da2700fa1b.js"></script><script src="/_next/static/chunks/webpack-8161fc2bb14cec39.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-a0f603ce323043fd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-ee1fab0e25bb912e.js" defer=""></script><script src="/_next/static/chunks/94-57434c8b7a6c3878.js" defer=""></script><script src="/_next/static/chunks/128-76b45627a109219b.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...listPathPage%5D-45eea57fe8c2902c.js" defer=""></script><script src="/_next/static/2lY2cUyEfZosk4VLgkHb2/_buildManifest.js" defer=""></script><script src="/_next/static/2lY2cUyEfZosk4VLgkHb2/_ssgManifest.js" defer=""></script></head><body class="theme-blue"><div id="__next"><div class="theme-blue"><nav class="navigation_root__yPL8O"><span class="navigation_has-alert__s0Drf"><a class="link_root__1Me7D link_no-link-layout__RPvod" aria-label="spaCy" href="/"><h1 class="navigation_title__pm49s">spaCy</h1></a> <span class="navigation_alert__ZOXon"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage/v3-5"><strong>ðŸ’¥ Out now:</strong> spaCy v3.5</a></span></span><div class="navigation_menu__ZMJxN"><select class="dropdown_root__3uiQq navigation_dropdown__4j4pI"><option value="title" disabled="">Menu</option><option value="/usage" selected="">Usage</option><option value="/models">Models</option><option value="/api">API</option><option value="/universe">Universe</option></select><ul class="navigation_list__DCzqi"><li class="navigation_item__ln1O1 navigation_is-active__RjVJG"><a class="link_root__1Me7D link_no-link-layout__RPvod" tabindex="-1" href="/usage">Usage</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li class="navigation_item__ln1O1 navigation_github__MpFNv"><span><a href="https://github.com/explosion/spaCy" data-size="large" data-show-count="true" aria-label="Star spaCy on GitHub"></a></span></li></ul><div class="navigation_search__BKZCn"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div><progress class="progress_root__9huWN" value="0" max="100"></progress></nav><menu class="sidebar sidebar_root__s2No7"><h1 hidden="" aria-hidden="true" class="h0 sidebar_active-heading___dkf9">Documentation</h1><div class="sidebar_dropdown__vyqjz"><select class="dropdown_root__3uiQq sidebar_dropdown-select__Nwbq9"><option disabled="">Select page...</option><option value="/usage">Get started<!-- --> â€º <!-- -->Installation</option><option value="/usage/models">Get started<!-- --> â€º <!-- -->Models &amp; Languages</option><option value="/usage/facts-figures">Get started<!-- --> â€º <!-- -->Facts &amp; Figures</option><option value="/usage/spacy-101">Get started<!-- --> â€º <!-- -->spaCy 101</option><option value="/usage/v3">Get started<!-- --> â€º <!-- -->New in v3.0</option><option value="/usage/v3-1">Get started<!-- --> â€º <!-- -->New in v3.1</option><option value="/usage/v3-2">Get started<!-- --> â€º <!-- -->New in v3.2</option><option value="/usage/v3-3">Get started<!-- --> â€º <!-- -->New in v3.3</option><option value="/usage/v3-4">Get started<!-- --> â€º <!-- -->New in v3.4</option><option value="/usage/v3-5">Get started<!-- --> â€º <!-- -->New in v3.5</option><option value="/usage/linguistic-features">Guides<!-- --> â€º <!-- -->Linguistic Features</option><option value="/usage/rule-based-matching">Guides<!-- --> â€º <!-- -->Rule-based Matching</option><option value="/usage/processing-pipelines">Guides<!-- --> â€º <!-- -->Processing Pipelines</option><option value="/usage/embeddings-transformers">Guides<!-- --> â€º <!-- -->Embeddings &amp; Transformers</option><option value="/usage/training">Guides<!-- --> â€º <!-- -->Training Models</option><option value="/usage/layers-architectures">Guides<!-- --> â€º <!-- -->Layers &amp; Model Architectures</option><option value="/usage/projects">Guides<!-- --> â€º <!-- -->spaCy Projects</option><option value="/usage/saving-loading">Guides<!-- --> â€º <!-- -->Saving &amp; Loading</option><option value="/usage/visualizers">Guides<!-- --> â€º <!-- -->Visualizers</option><option value="https://github.com/explosion/projects">Resources<!-- --> â€º <!-- -->Project Templates</option><option value="https://v2.spacy.io">Resources<!-- --> â€º <!-- -->v2.x Documentation</option><option value="https://explosion.ai/custom-solutions">Resources<!-- --> â€º <!-- -->Custom Solutions</option></select></div><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Get started</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage">Installation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/models">Models &amp; Languages</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/facts-figures">Facts &amp; Figures</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/spacy-101">spaCy 101</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3">New in v3.0</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-1">New in v3.1</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-2">New in v3.2</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-3">New in v3.3</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-4">New in v3.4</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-5">New in v3.5</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Guides</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/linguistic-features">Linguistic Features</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/rule-based-matching">Rule-based Matching</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/processing-pipelines">Processing Pipelines</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/embeddings-transformers">Embeddings &amp; Transformers<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/training">Training Models<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/layers-architectures">Layers &amp; Model Architectures<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/projects">spaCy Projects<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/saving-loading">Saving &amp; Loading</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/visualizers">Visualizers</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Resources</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/projects">Project Templates</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://v2.spacy.io">v2.x Documentation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></menu><main class="main_root__7f6Tj main_with-sidebar__uH1df main_with-asides__ikQT6"><article class="main_content__8zFCH"><header class="title_root__pS2WQ"><h1 id="_title" class="typography_heading__D82WZ typography_h1__b7dt9 title_h1__l3CW1"><span class="heading-text">What&#x27;s New in v2.3<!-- --> </span></h1><div class="heading-teaser title_teaser__QhwCH">New features, backwards incompatibilities and migration guide</div></header><section id="section-features" class="section_root__k1hUl"><p>spaCy v2.3 features new pretrained models for five languages, word vectors for
all language models, and decreased model size and loading times for models with
vectors. Weâ€™ve added pretrained models for <strong>Chinese, Danish, Japanese, Polish
and Romanian</strong> and updated the training data and vectors for most languages.
Model packages with vectors are about <strong>2&amp;times</strong> smaller on disk and load
<strong>2-4Ã—</strong> faster. For the full changelog, see the
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/releases/tag/v2.3.0"><span class="link_source-text__VDP74">release notes on GitHub</span></a>.
For more details and a behind-the-scenes look at the new release,
<a class="link_root__1Me7D" href="https://explosion.ai/blog/spacy-v2-3">see our blog post</a>.</p><h3 id="models" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#models" class="heading-text typography_permalink__UiIRy">Expanded model families with vectors <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre>
</div></div></aside><p>With new model families for Chinese, Danish, Polish, Romanian and Chinese plus
<code class="code_inline-code__Bq7ot">md</code> and <code class="code_inline-code__Bq7ot">lg</code> models with word vectors for all languages, this release provides
a total of 46 model packages. For models trained using
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://universaldependencies.org">Universal Dependencies</a> corpora, the
training data has been updated to UD v2.5 (v2.6 for Japanese, v2.3 for Polish)
and Dutch has been extended to include both UD Dutch Alpino and LassySmall.</p><aside class="infobox_root__yNIMg"><p><strong>Models:</strong> <a class="link_root__1Me7D" href="/models">Models directory</a> **Benchmarks: **
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/releases/tag/v2.3.0"><span class="link_source-text__VDP74">Release notes</span></a></p></aside><h3 id="chinese" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#chinese" class="heading-text typography_permalink__UiIRy">Chinese <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre>
</div></div></aside><p>This release adds support for
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/lancopku/pkuseg-python"><code class="code_inline-code__Bq7ot">pkuseg</code></a> for word segmentation and
the new Chinese models ship with a custom pkuseg model trained on OntoNotes. The
Chinese tokenizer can be initialized with both <code class="code_inline-code__Bq7ot">pkuseg</code> and custom models and
the <code class="code_inline-code__Bq7ot">pkuseg</code> user dictionary is easy to customize. Note that
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/lancopku/pkuseg-python"><code class="code_inline-code__Bq7ot">pkuseg</code></a> doesnâ€™t yet ship with
pre-compiled wheels for Python 3.8. See the
<a class="link_root__1Me7D" href="/usage/models#chinese">usage documentation</a> for details on how to install it on
Python 3.8.</p><aside class="infobox_root__yNIMg"><p><strong>Models:</strong> <a class="link_root__1Me7D link_with-icon__NAVDA" href="/models/zh"><span class="link_source-text__VDP74">Chinese models</span></a> **Usage: **
<a class="link_root__1Me7D" href="/usage/models#chinese">Chinese tokenizer usage</a></p></aside><h3 id="japanese" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#japanese" class="heading-text typography_permalink__UiIRy">Japanese <!-- --> </a></h3><p>The updated Japanese language class switches to
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/WorksApplications/SudachiPy"><code class="code_inline-code__Bq7ot">SudachiPy</code></a> for word
segmentation and part-of-speech tagging. Using <code class="code_inline-code__Bq7ot">SudachiPy</code> greatly simplifies
installing spaCy for Japanese, which is now possible with a single command:
<code class="code_inline-code__Bq7ot">pip install spacy[ja]</code>.</p><aside class="infobox_root__yNIMg"><p><strong>Models:</strong> <a class="link_root__1Me7D link_with-icon__NAVDA" href="/models/ja"><span class="link_source-text__VDP74">Japanese models</span></a> <strong>Usage:</strong>
<a class="link_root__1Me7D" href="/usage/models#japanese">Japanese tokenizer usage</a></p></aside><h3 class="typography_heading__D82WZ typography_h3__mPKmB"><span class="heading-text">Small CLI updates<!-- --> </span></h3><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#debug-data"><code class="code_inline-code__Bq7ot">spacy debug-data</code></a> provides the coverage of the vectors
in a base model with <code class="code_inline-code__Bq7ot code_wrap__b41os">spacy debug-data lang train dev -b base_model</code></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#evaluate"><code class="code_inline-code__Bq7ot">spacy evaluate</code></a> supports <code class="code_inline-code__Bq7ot">blank:lg</code> (e.g.
<code class="code_inline-code__Bq7ot code_wrap__b41os">spacy evaluate blank:en dev.json</code>) to evaluate the tokenization accuracy
without loading a model</li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#train"><code class="code_inline-code__Bq7ot">spacy train</code></a> on GPU restricts the CPU timing evaluation to
the first iteration</li>
</ul></section>
<section id="section-incompat" class="section_root__k1hUl"><h2 id="incompat" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#incompat" class="heading-text typography_permalink__UiIRy">Backwards incompatibilities <!-- --> </a></h2><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note on models</span></h4><p>If youâ€™ve been training <strong>your own models</strong>, youâ€™ll need to <strong>retrain</strong> them
with the new version. Also donâ€™t forget to upgrade all models to the latest
versions. Models for earlier v2 releases (v2.0, v2.1, v2.2) arenâ€™t compatible
with models for v2.3. To check if all of your models are up to date, you can run
the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#validate"><code class="code_inline-code__Bq7ot">spacy validate</code></a> command.</p></aside><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Install with lookups data<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre>
<p>You can also install
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a>
directly.</p>
</div></div></aside><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">If youâ€™re training new models, youâ€™ll want to install the package
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a>, which
now includes both the lemmatization tables (as in v2.2) and the normalization
tables (new in v2.3). If youâ€™re using pretrained models, <strong>nothing changes</strong>,
because the relevant tables are included in the model packages.</li>
<li class="list_li__sfx_z">Due to the updated Universal Dependencies training data, the fine-grained
part-of-speech tags will change for many provided language models. The
coarse-grained part-of-speech tagset remains the same, but the mapping from
particular fine-grained to coarse-grained tags may show minor differences.</li>
<li class="list_li__sfx_z">For French, Italian, Portuguese and Spanish, the fine-grained part-of-speech
tagsets contain new merged tags related to contracted forms, such as <code class="code_inline-code__Bq7ot">ADP_DET</code>
for French <code class="code_inline-code__Bq7ot">&quot;au&quot;</code>, which maps to UPOS <code class="code_inline-code__Bq7ot">ADP</code> based on the head <code class="code_inline-code__Bq7ot">&quot;Ã &quot;</code>. This
increases the accuracy of the models by improving the alignment between
spaCyâ€™s tokenization and Universal Dependencies multi-word tokens used for
contractions.</li>
</ul><h3 id="migrating" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#migrating" class="heading-text typography_permalink__UiIRy">Migrating from spaCy 2.2 <!-- --> </a></h3><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Tokenizer settings<!-- --> </span></h4><p>In spaCy v2.2.2-v2.2.4, there was a change to the precedence of <code class="code_inline-code__Bq7ot">token_match</code>
that gave prefixes and suffixes priority over <code class="code_inline-code__Bq7ot">token_match</code>, which caused
problems for many custom tokenizer configurations. This has been reverted in
v2.3 so that <code class="code_inline-code__Bq7ot">token_match</code> has priority over prefixes and suffixes as in v2.2.1
and earlier versions.</p><p>A new tokenizer setting <code class="code_inline-code__Bq7ot">url_match</code> has been introduced in v2.3.0 to handle
cases like URLs where the tokenizer should remove prefixes and suffixes (e.g., a
comma at the end of a URL) before applying the match. See the full
<a class="link_root__1Me7D" href="/usage/linguistic-features#tokenization">tokenizer documentation</a> and try out
<a class="link_root__1Me7D" href="/usage/linguistic-features#tokenizer-debug"><code class="code_inline-code__Bq7ot">nlp.tokenizer.explain()</code></a> when
debugging your tokenizer configuration.</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Warnings configuration<!-- --> </span></h4><p>spaCyâ€™s custom warnings have been replaced with native Python
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://docs.python.org/3/library/warnings.html"><code class="code_inline-code__Bq7ot">warnings</code></a>. Instead of
setting <code class="code_inline-code__Bq7ot">SPACY_WARNING_IGNORE</code>, use the
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://docs.python.org/3/library/warnings.html#the-warnings-filter"><code class="code_inline-code__Bq7ot">warnings</code> filters</a>
to manage warnings.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Normalization tables<!-- --> </span></h4><p>The normalization tables have moved from the language data in
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy/tree/v2.x/spacy/lang"><code class="code_inline-code__Bq7ot">spacy/lang</code></a> to the
package <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a>.
If youâ€™re adding data for a new language, the normalization table should be
added to <code class="code_inline-code__Bq7ot">spacy-lookups-data</code>. See
<a class="link_root__1Me7D" href="/usage/adding-languages#norm-exceptions">adding norm exceptions</a>.</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">No preloaded vocab for models with vectors<!-- --> </span></h4><p>To reduce the initial loading time, the lexemes in <code class="code_inline-code__Bq7ot">nlp.vocab</code> are no longer
loaded on initialization for models with vectors. As you process texts, the
lexemes will be added to the vocab automatically, just as in small models
without vectors.</p><p>To see the number of unique vectors and number of words with vectors, see
<code class="code_inline-code__Bq7ot">nlp.meta[&#x27;vectors&#x27;]</code>, for example for <code class="code_inline-code__Bq7ot">en_core_web_md</code> there are <code class="code_inline-code__Bq7ot">20000</code> unique
vectors and <code class="code_inline-code__Bq7ot">684830</code> words with vectors:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>If required, for instance if you are working directly with word vectors rather
than processing texts, you can load all lexemes for words with vectors at once:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>If your workflow previously iterated over <code class="code_inline-code__Bq7ot">nlp.vocab</code>, a similar alternative is
to iterate over words with vectors instead:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre><p>Be aware that the set of preloaded lexemes in a v2.2 model is not equivalent to
the set of words with vectors. For English, v2.2 <code class="code_inline-code__Bq7ot">md/lg</code> models have 1.3M
provided lexemes but only 685K words with vectors. The vectors have been updated
for most languages in v2.2, but the English models contain the same vectors for
both v2.2 and v2.3.</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Lexeme.is_oov and Token.is_oov<!-- --> </span></h4><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note</span></h4><p>Due to a bug, the values for <code class="code_inline-code__Bq7ot">is_oov</code> are reversed in v2.3.0, but this will be
fixed in the next patch release v2.3.1.</p></aside><p>In v2.3, <code class="code_inline-code__Bq7ot">Lexeme.is_oov</code> and <code class="code_inline-code__Bq7ot">Token.is_oov</code> are <code class="code_inline-code__Bq7ot">True</code> if the lexeme does not
have a word vector. This is equivalent to <code class="code_inline-code__Bq7ot code_wrap__b41os">token.orth not in nlp.vocab.vectors</code>.</p><p>Previously in v2.2, <code class="code_inline-code__Bq7ot">is_oov</code> corresponded to whether a lexeme had stored
probability and cluster features. The probability and cluster features are no
longer included in the provided medium and large models (see the next section).</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Probability and cluster features<!-- --> </span></h4><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Load and save extra prob lookups table<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre>
</div></div></aside><p>The <code class="code_inline-code__Bq7ot">Token.prob</code> and <code class="code_inline-code__Bq7ot">Token.cluster</code> features, which are no longer used by the
core pipeline components as of spaCy v2, are no longer provided in the
pretrained models to reduce the model size. To keep these features available for
users relying on them, the <code class="code_inline-code__Bq7ot">prob</code> and <code class="code_inline-code__Bq7ot">cluster</code> features for the most frequent
1M tokens have been moved to
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a> as
<code class="code_inline-code__Bq7ot">extra</code> features for the relevant languages (English, German, Greek and
Spanish).</p><p>The extra tables are loaded lazily, so if you have <code class="code_inline-code__Bq7ot">spacy-lookups-data</code>
installed and your code accesses <code class="code_inline-code__Bq7ot">Token.prob</code>, the full table is loaded into the
model vocab, which will take a few seconds on initial loading. When you save
this model after loading the <code class="code_inline-code__Bq7ot">prob</code> table, the full <code class="code_inline-code__Bq7ot">prob</code> table will be saved
as part of the model vocab.</p><p>To load the probability table into a provided model, first make sure you have
<code class="code_inline-code__Bq7ot">spacy-lookups-data</code> installed. To load the table, remove the empty provided
<code class="code_inline-code__Bq7ot">lexeme_prob</code> table and then access <code class="code_inline-code__Bq7ot">Lexeme.prob</code> for any word to load the table
from <code class="code_inline-code__Bq7ot">spacy-lookups-data</code>:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre><p>If youâ€™d like to include custom <code class="code_inline-code__Bq7ot">cluster</code>, <code class="code_inline-code__Bq7ot">prob</code>, or <code class="code_inline-code__Bq7ot">sentiment</code> tables as part
of a new model, add the data to
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a> under
the entry point <code class="code_inline-code__Bq7ot">lg_extra</code>, e.g. <code class="code_inline-code__Bq7ot">en_extra</code> for English. Alternatively, you can
initialize your <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a> with the <code class="code_inline-code__Bq7ot">lookups_extra</code> argument with a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lookups"><code class="code_inline-code__Bq7ot">Lookups</code></a> object that includes the tables <code class="code_inline-code__Bq7ot">lexeme_cluster</code>,
<code class="code_inline-code__Bq7ot">lexeme_prob</code>, <code class="code_inline-code__Bq7ot">lexeme_sentiment</code> or <code class="code_inline-code__Bq7ot">lexeme_settings</code>. <code class="code_inline-code__Bq7ot">lexeme_settings</code> is
currently only used to provide a custom <code class="code_inline-code__Bq7ot">oov_prob</code>. See examples in the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data/tree/master/spacy_lookups_data/data"><code class="code_inline-code__Bq7ot">data</code> directory</a>
in <code class="code_inline-code__Bq7ot">spacy-lookups-data</code>.</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Initializing new models without extra lookups tables<!-- --> </span></h4><p>When you initialize a new model with <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#init-model"><code class="code_inline-code__Bq7ot">spacy init-model</code></a>,
the <code class="code_inline-code__Bq7ot">prob</code> table from <code class="code_inline-code__Bq7ot">spacy-lookups-data</code> may be loaded as part of the
initialization. If youâ€™d like to omit this extra data as in spaCyâ€™s provided
v2.3 models, use the new flag <code class="code_inline-code__Bq7ot">--omit-extra-lookups</code>.</p><h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Tag maps in provided models vs. blank models<!-- --> </span></h4><p>The tag maps in the provided models may differ from the tag maps in the spaCy
library. You can access the tag map in a loaded model under
<code class="code_inline-code__Bq7ot">nlp.vocab.morphology.tag_map</code>.</p><p>The tag map from <code class="code_inline-code__Bq7ot">spacy.lang.lg.tag_map</code> is still used when a blank model is
initialized. If you want to provide an alternate tag map, update
<code class="code_inline-code__Bq7ot">nlp.vocab.morphology.tag_map</code> after initializing the model or if youâ€™re using
the <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/cli#train"><span class="link_source-text__VDP74">train CLI</span></a>, you can use the new <code class="code_inline-code__Bq7ot">--tag-map-path</code> option to
provide in the tag map as a JSON dict.</p><p>If you want to export a tag map from a provided model for use with the train
CLI, you can save it as a JSON dict. To only use string keys as required by JSON
and to make it easier to read and edit, any internal integer IDs need to be
converted back to strings:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre></section><div class="grid_root__EfDZl grid_spacing__fhBCv grid_half__xoJZs"><div style="margin-top:var(--spacing-lg)"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/website/docs/usage/v2-3.mdx">Suggest edits</a></div></div></article><div class="main_asides__RITE5" style="background-image:url(/_next/static/media/pattern_blue.d167bed5.png"></div><footer class="footer_root__zlkjP"><div class="grid_root__EfDZl footer_content__LaE1F grid_narrow__x_6xS grid_spacing__fhBCv grid_third__edHuB"><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">spaCy</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage">Usage</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API Reference</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://course.spacy.io">Online Course</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Community</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/discussions">GitHub Discussions</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues">Issue Tracker</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="http://stackoverflow.com/questions/tagged/spacy">Stack Overflow</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Connect</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/spacy_io">Twitter</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy">GitHub</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://youtube.com/c/ExplosionAI">YouTube</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/blog">Blog</a></li></ul></section><section class="footer_full___icln"><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Stay in the loop!</li><li>Receive updates about new releases, tutorials and more.</li><li><form id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" action="//spacy.us12.list-manage.com/subscribe/post?u=83b0498b1e7fa3c91ce68c3f1&amp;amp;id=ecc82e0493" method="post" target="_blank" novalidate=""><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_83b0498b1e7fa3c91ce68c3f1_ecc82e0493" tabindex="-1" value=""/></div><div class="newsletter_root__uh6MU"><input class="newsletter_input___SMSB" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email" aria-label="Your email"/><button class="newsletter_button__gKW8E" id="mc-embedded-subscribe" type="submit" name="subscribe">Sign up</button></div></form></li></ul></section></div><div class="footer_content__LaE1F footer_copy__rbjvc"><span>Â© 2016-<!-- -->2023<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai">Explosion</a></span><a class="link_root__1Me7D footer_logo__BthsJ link_no-link-layout__RPvod" aria-label="Explosion" href="https://explosion.ai"></a><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/legal">Legal / Imprint</a></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"What's New in v2.3","teaser":"New features, backwards incompatibilities and migration guide","menu":[["New Features","features"],["Backwards Incompatibilities","incompat"],["Migrating from v2.2","migrating"]],"slug":"/usage/v2-3","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    h2: \"h2\",\n    p: \"p\",\n    strong: \"strong\",\n    a: \"a\",\n    h3: \"h3\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    pre: \"pre\",\n    code: \"code\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components), {InlineCode, Infobox} = _components;\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      id: \"section-features\",\n      children: [_jsx(_components.h2, {\n        id: \"features\",\n        hidden: \"true\",\n        children: \"New Features \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy v2.3 features new pretrained models for five languages, word vectors for\\nall language models, and decreased model size and loading times for models with\\nvectors. Weâ€™ve added pretrained models for \", _jsx(_components.strong, {\n          children: \"Chinese, Danish, Japanese, Polish\\nand Romanian\"\n        }), \" and updated the training data and vectors for most languages.\\nModel packages with vectors are about \", _jsx(_components.strong, {\n          children: \"2\u0026times\"\n        }), \" smaller on disk and load\\n\", _jsx(_components.strong, {\n          children: \"2-4Ã—\"\n        }), \" faster. For the full changelog, see the\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spaCy/releases/tag/v2.3.0\",\n          children: \"release notes on GitHub\"\n        }), \".\\nFor more details and a behind-the-scenes look at the new release,\\n\", _jsx(_components.a, {\n          href: \"https://explosion.ai/blog/spacy-v2-3\",\n          children: \"see our blog post\"\n        }), \".\"]\n      }), _jsx(_components.h3, {\n        id: \"models\",\n        children: \"Expanded model families with vectors \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"python -m spacy download da_core_news_sm\\npython -m spacy download ja_core_news_sm\\npython -m spacy download pl_core_news_sm\\npython -m spacy download ro_core_news_sm\\npython -m spacy download zh_core_web_sm\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"With new model families for Chinese, Danish, Polish, Romanian and Chinese plus\\n\", _jsx(InlineCode, {\n          children: \"md\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"lg\"\n        }), \" models with word vectors for all languages, this release provides\\na total of 46 model packages. For models trained using\\n\", _jsx(_components.a, {\n          href: \"https://universaldependencies.org\",\n          children: \"Universal Dependencies\"\n        }), \" corpora, the\\ntraining data has been updated to UD v2.5 (v2.6 for Japanese, v2.3 for Polish)\\nand Dutch has been extended to include both UD Dutch Alpino and LassySmall.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"Models:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/models\",\n            children: \"Models directory\"\n          }), \" **Benchmarks: **\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/releases/tag/v2.3.0\",\n            children: \"Release notes\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"chinese\",\n        children: \"Chinese \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy.lang.zh import Chinese\\n\\n# Load with \\\"default\\\" model provided by pkuseg\\ncfg = {\\\"pkuseg_model\\\": \\\"default\\\", \\\"require_pkuseg\\\": True}\\nnlp = Chinese(meta={\\\"tokenizer\\\": {\\\"config\\\": cfg}})\\n\\n# Append words to user dict\\nnlp.tokenizer.pkuseg_update_user_dict([\\\"ä¸­å›½\\\", \\\"ABC\\\"])\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"This release adds support for\\n\", _jsx(_components.a, {\n          href: \"https://github.com/lancopku/pkuseg-python\",\n          children: _jsx(InlineCode, {\n            children: \"pkuseg\"\n          })\n        }), \" for word segmentation and\\nthe new Chinese models ship with a custom pkuseg model trained on OntoNotes. The\\nChinese tokenizer can be initialized with both \", _jsx(InlineCode, {\n          children: \"pkuseg\"\n        }), \" and custom models and\\nthe \", _jsx(InlineCode, {\n          children: \"pkuseg\"\n        }), \" user dictionary is easy to customize. Note that\\n\", _jsx(_components.a, {\n          href: \"https://github.com/lancopku/pkuseg-python\",\n          children: _jsx(InlineCode, {\n            children: \"pkuseg\"\n          })\n        }), \" doesnâ€™t yet ship with\\npre-compiled wheels for Python 3.8. See the\\n\", _jsx(_components.a, {\n          href: \"/usage/models#chinese\",\n          children: \"usage documentation\"\n        }), \" for details on how to install it on\\nPython 3.8.\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"Models:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/models/zh\",\n            children: \"Chinese models\"\n          }), \" **Usage: **\\n\", _jsx(_components.a, {\n            href: \"/usage/models#chinese\",\n            children: \"Chinese tokenizer usage\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        id: \"japanese\",\n        children: \"Japanese \"\n      }), _jsxs(_components.p, {\n        children: [\"The updated Japanese language class switches to\\n\", _jsx(_components.a, {\n          href: \"https://github.com/WorksApplications/SudachiPy\",\n          children: _jsx(InlineCode, {\n            children: \"SudachiPy\"\n          })\n        }), \" for word\\nsegmentation and part-of-speech tagging. Using \", _jsx(InlineCode, {\n          children: \"SudachiPy\"\n        }), \" greatly simplifies\\ninstalling spaCy for Japanese, which is now possible with a single command:\\n\", _jsx(InlineCode, {\n          children: \"pip install spacy[ja]\"\n        }), \".\"]\n      }), _jsx(Infobox, {\n        children: _jsxs(_components.p, {\n          children: [_jsx(_components.strong, {\n            children: \"Models:\"\n          }), \" \", _jsx(_components.a, {\n            href: \"/models/ja\",\n            children: \"Japanese models\"\n          }), \" \", _jsx(_components.strong, {\n            children: \"Usage:\"\n          }), \"\\n\", _jsx(_components.a, {\n            href: \"/usage/models#japanese\",\n            children: \"Japanese tokenizer usage\"\n          })]\n        })\n      }), _jsx(_components.h3, {\n        children: \"Small CLI updates\"\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"/api/cli#debug-data\",\n            children: _jsx(InlineCode, {\n              children: \"spacy debug-data\"\n            })\n          }), \" provides the coverage of the vectors\\nin a base model with \", _jsx(InlineCode, {\n            children: \"spacy debug-data lang train dev -b base_model\"\n          })]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"/api/cli#evaluate\",\n            children: _jsx(InlineCode, {\n              children: \"spacy evaluate\"\n            })\n          }), \" supports \", _jsx(InlineCode, {\n            children: \"blank:lg\"\n          }), \" (e.g.\\n\", _jsx(InlineCode, {\n            children: \"spacy evaluate blank:en dev.json\"\n          }), \") to evaluate the tokenization accuracy\\nwithout loading a model\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"/api/cli#train\",\n            children: _jsx(InlineCode, {\n              children: \"spacy train\"\n            })\n          }), \" on GPU restricts the CPU timing evaluation to\\nthe first iteration\"]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-incompat\",\n      children: [_jsx(_components.h2, {\n        id: \"incompat\",\n        children: \"Backwards incompatibilities \"\n      }), _jsx(Infobox, {\n        title: \"Important note on models\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"If youâ€™ve been training \", _jsx(_components.strong, {\n            children: \"your own models\"\n          }), \", youâ€™ll need to \", _jsx(_components.strong, {\n            children: \"retrain\"\n          }), \" them\\nwith the new version. Also donâ€™t forget to upgrade all models to the latest\\nversions. Models for earlier v2 releases (v2.0, v2.1, v2.2) arenâ€™t compatible\\nwith models for v2.3. To check if all of your models are up to date, you can run\\nthe \", _jsx(_components.a, {\n            href: \"/api/cli#validate\",\n            children: _jsx(InlineCode, {\n              children: \"spacy validate\"\n            })\n          }), \" command.\"]\n        })\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Install with lookups data\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"$ pip install spacy[lookups]\\n\"\n          })\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"You can also install\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spacy-lookups-data\",\n            children: _jsx(InlineCode, {\n              children: \"spacy-lookups-data\"\n            })\n          }), \"\\ndirectly.\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [\"If youâ€™re training new models, youâ€™ll want to install the package\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spacy-lookups-data\",\n            children: _jsx(InlineCode, {\n              children: \"spacy-lookups-data\"\n            })\n          }), \", which\\nnow includes both the lemmatization tables (as in v2.2) and the normalization\\ntables (new in v2.3). If youâ€™re using pretrained models, \", _jsx(_components.strong, {\n            children: \"nothing changes\"\n          }), \",\\nbecause the relevant tables are included in the model packages.\"]\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"Due to the updated Universal Dependencies training data, the fine-grained\\npart-of-speech tags will change for many provided language models. The\\ncoarse-grained part-of-speech tagset remains the same, but the mapping from\\nparticular fine-grained to coarse-grained tags may show minor differences.\"\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"For French, Italian, Portuguese and Spanish, the fine-grained part-of-speech\\ntagsets contain new merged tags related to contracted forms, such as \", _jsx(InlineCode, {\n            children: \"ADP_DET\"\n          }), \"\\nfor French \", _jsx(InlineCode, {\n            children: \"\\\"au\\\"\"\n          }), \", which maps to UPOS \", _jsx(InlineCode, {\n            children: \"ADP\"\n          }), \" based on the head \", _jsx(InlineCode, {\n            children: \"\\\"Ã \\\"\"\n          }), \". This\\nincreases the accuracy of the models by improving the alignment between\\nspaCyâ€™s tokenization and Universal Dependencies multi-word tokens used for\\ncontractions.\"]\n        }), \"\\n\"]\n      }), _jsx(_components.h3, {\n        id: \"migrating\",\n        children: \"Migrating from spaCy 2.2 \"\n      }), _jsx(_components.h4, {\n        children: \"Tokenizer settings\"\n      }), _jsxs(_components.p, {\n        children: [\"In spaCy v2.2.2-v2.2.4, there was a change to the precedence of \", _jsx(InlineCode, {\n          children: \"token_match\"\n        }), \"\\nthat gave prefixes and suffixes priority over \", _jsx(InlineCode, {\n          children: \"token_match\"\n        }), \", which caused\\nproblems for many custom tokenizer configurations. This has been reverted in\\nv2.3 so that \", _jsx(InlineCode, {\n          children: \"token_match\"\n        }), \" has priority over prefixes and suffixes as in v2.2.1\\nand earlier versions.\"]\n      }), _jsxs(_components.p, {\n        children: [\"A new tokenizer setting \", _jsx(InlineCode, {\n          children: \"url_match\"\n        }), \" has been introduced in v2.3.0 to handle\\ncases like URLs where the tokenizer should remove prefixes and suffixes (e.g., a\\ncomma at the end of a URL) before applying the match. See the full\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#tokenization\",\n          children: \"tokenizer documentation\"\n        }), \" and try out\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#tokenizer-debug\",\n          children: _jsx(InlineCode, {\n            children: \"nlp.tokenizer.explain()\"\n          })\n        }), \" when\\ndebugging your tokenizer configuration.\"]\n      }), _jsx(_components.h4, {\n        children: \"Warnings configuration\"\n      }), _jsxs(_components.p, {\n        children: [\"spaCyâ€™s custom warnings have been replaced with native Python\\n\", _jsx(_components.a, {\n          href: \"https://docs.python.org/3/library/warnings.html\",\n          children: _jsx(InlineCode, {\n            children: \"warnings\"\n          })\n        }), \". Instead of\\nsetting \", _jsx(InlineCode, {\n          children: \"SPACY_WARNING_IGNORE\"\n        }), \", use the\\n\", _jsxs(_components.a, {\n          href: \"https://docs.python.org/3/library/warnings.html#the-warnings-filter\",\n          children: [_jsx(InlineCode, {\n            children: \"warnings\"\n          }), \" filters\"]\n        }), \"\\nto manage warnings.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"import spacy\\n+ import warnings\\n\\n- spacy.errors.SPACY_WARNING_IGNORE.append('W007')\\n+ warnings.filterwarnings(\\\"ignore\\\", message=r\\\"\\\\\\\\[W007\\\\\\\\]\\\", category=UserWarning)\\n\"\n        })\n      }), _jsx(_components.h4, {\n        children: \"Normalization tables\"\n      }), _jsxs(_components.p, {\n        children: [\"The normalization tables have moved from the language data in\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy/tree/v2.x/spacy/lang\",\n          children: _jsx(InlineCode, {\n            children: \"spacy/lang\"\n          })\n        }), \" to the\\npackage \", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy-lookups-data\",\n          children: _jsx(InlineCode, {\n            children: \"spacy-lookups-data\"\n          })\n        }), \".\\nIf youâ€™re adding data for a new language, the normalization table should be\\nadded to \", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \". See\\n\", _jsx(_components.a, {\n          href: \"/usage/adding-languages#norm-exceptions\",\n          children: \"adding norm exceptions\"\n        }), \".\"]\n      }), _jsx(_components.h4, {\n        children: \"No preloaded vocab for models with vectors\"\n      }), _jsxs(_components.p, {\n        children: [\"To reduce the initial loading time, the lexemes in \", _jsx(InlineCode, {\n          children: \"nlp.vocab\"\n        }), \" are no longer\\nloaded on initialization for models with vectors. As you process texts, the\\nlexemes will be added to the vocab automatically, just as in small models\\nwithout vectors.\"]\n      }), _jsxs(_components.p, {\n        children: [\"To see the number of unique vectors and number of words with vectors, see\\n\", _jsx(InlineCode, {\n          children: \"nlp.meta['vectors']\"\n        }), \", for example for \", _jsx(InlineCode, {\n          children: \"en_core_web_md\"\n        }), \" there are \", _jsx(InlineCode, {\n          children: \"20000\"\n        }), \" unique\\nvectors and \", _jsx(InlineCode, {\n          children: \"684830\"\n        }), \" words with vectors:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"{\\n    'width': 300,\\n    'vectors': 20000,\\n    'keys': 684830,\\n    'name': 'en_core_web_md.vectors'\\n}\\n\"\n        })\n      }), _jsx(_components.p, {\n        children: \"If required, for instance if you are working directly with word vectors rather\\nthan processing texts, you can load all lexemes for words with vectors at once:\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"for orth in nlp.vocab.vectors:\\n    _ = nlp.vocab[orth]\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If your workflow previously iterated over \", _jsx(InlineCode, {\n          children: \"nlp.vocab\"\n        }), \", a similar alternative is\\nto iterate over words with vectors instead:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"- lexemes = [w for w in nlp.vocab]\\n+ lexemes = [nlp.vocab[orth] for orth in nlp.vocab.vectors]\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Be aware that the set of preloaded lexemes in a v2.2 model is not equivalent to\\nthe set of words with vectors. For English, v2.2 \", _jsx(InlineCode, {\n          children: \"md/lg\"\n        }), \" models have 1.3M\\nprovided lexemes but only 685K words with vectors. The vectors have been updated\\nfor most languages in v2.2, but the English models contain the same vectors for\\nboth v2.2 and v2.3.\"]\n      }), _jsx(_components.h4, {\n        children: \"Lexeme.is_oov and Token.is_oov\"\n      }), _jsx(Infobox, {\n        title: \"Important note\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"Due to a bug, the values for \", _jsx(InlineCode, {\n            children: \"is_oov\"\n          }), \" are reversed in v2.3.0, but this will be\\nfixed in the next patch release v2.3.1.\"]\n        })\n      }), _jsxs(_components.p, {\n        children: [\"In v2.3, \", _jsx(InlineCode, {\n          children: \"Lexeme.is_oov\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"Token.is_oov\"\n        }), \" are \", _jsx(InlineCode, {\n          children: \"True\"\n        }), \" if the lexeme does not\\nhave a word vector. This is equivalent to \", _jsx(InlineCode, {\n          children: \"token.orth not in nlp.vocab.vectors\"\n        }), \".\"]\n      }), _jsxs(_components.p, {\n        children: [\"Previously in v2.2, \", _jsx(InlineCode, {\n          children: \"is_oov\"\n        }), \" corresponded to whether a lexeme had stored\\nprobability and cluster features. The probability and cluster features are no\\nlonger included in the provided medium and large models (see the next section).\"]\n      }), _jsx(_components.h4, {\n        children: \"Probability and cluster features\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Load and save extra prob lookups table\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from spacy.lang.en import English\\nnlp = English()\\ndoc = nlp(\\\"the\\\")\\nprint(doc[0].prob) # lazily loads extra prob table\\nnlp.to_disk(\\\"/path/to/model\\\") # includes prob table\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(InlineCode, {\n          children: \"Token.prob\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"Token.cluster\"\n        }), \" features, which are no longer used by the\\ncore pipeline components as of spaCy v2, are no longer provided in the\\npretrained models to reduce the model size. To keep these features available for\\nusers relying on them, the \", _jsx(InlineCode, {\n          children: \"prob\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"cluster\"\n        }), \" features for the most frequent\\n1M tokens have been moved to\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy-lookups-data\",\n          children: _jsx(InlineCode, {\n            children: \"spacy-lookups-data\"\n          })\n        }), \" as\\n\", _jsx(InlineCode, {\n          children: \"extra\"\n        }), \" features for the relevant languages (English, German, Greek and\\nSpanish).\"]\n      }), _jsxs(_components.p, {\n        children: [\"The extra tables are loaded lazily, so if you have \", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \"\\ninstalled and your code accesses \", _jsx(InlineCode, {\n          children: \"Token.prob\"\n        }), \", the full table is loaded into the\\nmodel vocab, which will take a few seconds on initial loading. When you save\\nthis model after loading the \", _jsx(InlineCode, {\n          children: \"prob\"\n        }), \" table, the full \", _jsx(InlineCode, {\n          children: \"prob\"\n        }), \" table will be saved\\nas part of the model vocab.\"]\n      }), _jsxs(_components.p, {\n        children: [\"To load the probability table into a provided model, first make sure you have\\n\", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \" installed. To load the table, remove the empty provided\\n\", _jsx(InlineCode, {\n          children: \"lexeme_prob\"\n        }), \" table and then access \", _jsx(InlineCode, {\n          children: \"Lexeme.prob\"\n        }), \" for any word to load the table\\nfrom \", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \":\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          children: \"+ # prerequisite: pip install spacy-lookups-data\\nimport spacy\\n\\nnlp = spacy.load(\\\"en_core_web_md\\\")\\n\\n# remove the empty placeholder prob table\\n+ if nlp.vocab.lookups_extra.has_table(\\\"lexeme_prob\\\"):\\n+     nlp.vocab.lookups_extra.remove_table(\\\"lexeme_prob\\\")\\n\\n# access any `.prob` to load the full table into the model\\nassert nlp.vocab[\\\"a\\\"].prob == -3.9297883511\\n\\n# if desired, save this model with the probability table included\\nnlp.to_disk(\\\"/path/to/model\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If youâ€™d like to include custom \", _jsx(InlineCode, {\n          children: \"cluster\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"prob\"\n        }), \", or \", _jsx(InlineCode, {\n          children: \"sentiment\"\n        }), \" tables as part\\nof a new model, add the data to\\n\", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy-lookups-data\",\n          children: _jsx(InlineCode, {\n            children: \"spacy-lookups-data\"\n          })\n        }), \" under\\nthe entry point \", _jsx(InlineCode, {\n          children: \"lg_extra\"\n        }), \", e.g. \", _jsx(InlineCode, {\n          children: \"en_extra\"\n        }), \" for English. Alternatively, you can\\ninitialize your \", _jsx(_components.a, {\n          href: \"/api/vocab\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab\"\n          })\n        }), \" with the \", _jsx(InlineCode, {\n          children: \"lookups_extra\"\n        }), \" argument with a\\n\", _jsx(_components.a, {\n          href: \"/api/lookups\",\n          children: _jsx(InlineCode, {\n            children: \"Lookups\"\n          })\n        }), \" object that includes the tables \", _jsx(InlineCode, {\n          children: \"lexeme_cluster\"\n        }), \",\\n\", _jsx(InlineCode, {\n          children: \"lexeme_prob\"\n        }), \", \", _jsx(InlineCode, {\n          children: \"lexeme_sentiment\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"lexeme_settings\"\n        }), \". \", _jsx(InlineCode, {\n          children: \"lexeme_settings\"\n        }), \" is\\ncurrently only used to provide a custom \", _jsx(InlineCode, {\n          children: \"oov_prob\"\n        }), \". See examples in the\\n\", _jsxs(_components.a, {\n          href: \"https://github.com/explosion/spacy-lookups-data/tree/master/spacy_lookups_data/data\",\n          children: [_jsx(InlineCode, {\n            children: \"data\"\n          }), \" directory\"]\n        }), \"\\nin \", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \".\"]\n      }), _jsx(_components.h4, {\n        children: \"Initializing new models without extra lookups tables\"\n      }), _jsxs(_components.p, {\n        children: [\"When you initialize a new model with \", _jsx(_components.a, {\n          href: \"/api/cli#init-model\",\n          children: _jsx(InlineCode, {\n            children: \"spacy init-model\"\n          })\n        }), \",\\nthe \", _jsx(InlineCode, {\n          children: \"prob\"\n        }), \" table from \", _jsx(InlineCode, {\n          children: \"spacy-lookups-data\"\n        }), \" may be loaded as part of the\\ninitialization. If youâ€™d like to omit this extra data as in spaCyâ€™s provided\\nv2.3 models, use the new flag \", _jsx(InlineCode, {\n          children: \"--omit-extra-lookups\"\n        }), \".\"]\n      }), _jsx(_components.h4, {\n        children: \"Tag maps in provided models vs. blank models\"\n      }), _jsxs(_components.p, {\n        children: [\"The tag maps in the provided models may differ from the tag maps in the spaCy\\nlibrary. You can access the tag map in a loaded model under\\n\", _jsx(InlineCode, {\n          children: \"nlp.vocab.morphology.tag_map\"\n        }), \".\"]\n      }), _jsxs(_components.p, {\n        children: [\"The tag map from \", _jsx(InlineCode, {\n          children: \"spacy.lang.lg.tag_map\"\n        }), \" is still used when a blank model is\\ninitialized. If you want to provide an alternate tag map, update\\n\", _jsx(InlineCode, {\n          children: \"nlp.vocab.morphology.tag_map\"\n        }), \" after initializing the model or if youâ€™re using\\nthe \", _jsx(_components.a, {\n          href: \"/api/cli#train\",\n          children: \"train CLI\"\n        }), \", you can use the new \", _jsx(InlineCode, {\n          children: \"--tag-map-path\"\n        }), \" option to\\nprovide in the tag map as a JSON dict.\"]\n      }), _jsx(_components.p, {\n        children: \"If you want to export a tag map from a provided model for use with the train\\nCLI, you can save it as a JSON dict. To only use string keys as required by JSON\\nand to make it easier to read and edit, any internal integer IDs need to be\\nconverted back to strings:\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"import spacy\\nimport srsly\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ntag_map = {}\\n\\n# convert any integer IDs to strings for JSON\\nfor tag, morph in nlp.vocab.morphology.tag_map.items():\\n    tag_map[tag] = {}\\n    for feat, val in morph.items():\\n        feat = nlp.vocab.strings.as_string(feat)\\n        if not isinstance(val, bool):\\n            val = nlp.vocab.strings.as_string(val)\\n        tag_map[tag][feat] = val\\n\\nsrsly.write_json(\\\"tag_map.json\\\", tag_map)\\n\"\n        })\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"What's New in v2.3","teaser":"New features, backwards incompatibilities and migration guide","menu":[["New Features","features"],["Backwards Incompatibilities","incompat"],["Migrating from v2.2","migrating"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":null},"__N_SSG":true},"page":"/[...listPathPage]","query":{"listPathPage":["usage","v2-3"]},"buildId":"2lY2cUyEfZosk4VLgkHb2","isFallback":false,"dynamicIds":[728],"gsp":true,"scriptLoader":[]}</script></body></html>