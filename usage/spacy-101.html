<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="shortcut icon" href="/icons/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=5.0, shrink-to-fit=no, viewport-fit=cover"/><meta name="theme-color" content="#09a3d5"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png"/><title>spaCy 101: Everything you need to know · spaCy Usage Documentation</title><meta name="description" content="The most important concepts, explained in simple terms"/><meta property="og:title" content="spaCy 101: Everything you need to know · spaCy Usage Documentation"/><meta property="og:description" content="The most important concepts, explained in simple terms"/><meta property="og:type" content="website"/><meta property="og:site_name" content="spaCy 101: Everything you need to know"/><meta property="og:image" content="https://spacy.io/_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:image" content="https://spacy.io/_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:creator" content="@spacy_io"/><meta name="twitter:site" content="@spacy_io"/><meta name="twitter:title" content="spaCy 101: Everything you need to know · spaCy Usage Documentation"/><meta name="twitter:description" content="The most important concepts, explained in simple terms"/><meta name="docsearch:language" content="en"/><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/8f0b94edbc18d62d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f0b94edbc18d62d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e6995e0e8addcf99.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e6995e0e8addcf99.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/262.c647d33d06232ef6.js"></script><script defer="" src="/_next/static/chunks/728.cf6ba0da2700fa1b.js"></script><script defer="" src="/_next/static/chunks/4ad82c5e.9f71e347f3d5ee0a.js"></script><script defer="" src="/_next/static/chunks/fec483df.e5c4c2e1905c02db.js"></script><script defer="" src="/_next/static/chunks/d9c63220.b8e7d78d95edcd53.js"></script><script defer="" src="/_next/static/chunks/876.15142163f03ee62c.js"></script><script defer="" src="/_next/static/chunks/661.267b5ccf1a1d90d0.js"></script><script defer="" src="/_next/static/chunks/492.0a716e87ad804aae.js"></script><script src="/_next/static/chunks/webpack-8161fc2bb14cec39.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-a0f603ce323043fd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb3ea1261af64e73.js" defer=""></script><script src="/_next/static/chunks/94-57434c8b7a6c3878.js" defer=""></script><script src="/_next/static/chunks/128-76b45627a109219b.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...listPathPage%5D-45eea57fe8c2902c.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_buildManifest.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_ssgManifest.js" defer=""></script></head><body class="theme-blue"><div id="__next"><div class="theme-blue"><nav class="navigation_root__yPL8O"><span class="navigation_has-alert__s0Drf"><a class="link_root__1Me7D link_no-link-layout__RPvod" aria-label="spaCy" href="/"><h1 class="navigation_title__pm49s">spaCy</h1></a> <span class="navigation_alert__ZOXon"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage/v3-5"><strong>💥 Out now:</strong> spaCy v3.5</a></span></span><div class="navigation_menu__ZMJxN"><select class="dropdown_root__3uiQq navigation_dropdown__4j4pI"><option value="title" disabled="">Menu</option><option value="/usage" selected="">Usage</option><option value="/models">Models</option><option value="/api">API</option><option value="/universe">Universe</option></select><ul class="navigation_list__DCzqi"><li class="navigation_item__ln1O1 navigation_is-active__RjVJG"><a class="link_root__1Me7D link_no-link-layout__RPvod" tabindex="-1" href="/usage">Usage</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li class="navigation_item__ln1O1 navigation_github__MpFNv"><span><a href="https://github.com/explosion/spaCy" data-size="large" data-show-count="true" aria-label="Star spaCy on GitHub"></a></span></li></ul><div class="navigation_search__BKZCn"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div><progress class="progress_root__9huWN" value="0" max="100"></progress></nav><menu class="sidebar sidebar_root__s2No7"><h1 hidden="" aria-hidden="true" class="h0 sidebar_active-heading___dkf9">Get started</h1><div class="sidebar_dropdown__vyqjz"><select class="dropdown_root__3uiQq sidebar_dropdown-select__Nwbq9"><option disabled="">Select page...</option><option value="/usage">Get started<!-- --> › <!-- -->Installation</option><option value="/usage/models">Get started<!-- --> › <!-- -->Models &amp; Languages</option><option value="/usage/facts-figures">Get started<!-- --> › <!-- -->Facts &amp; Figures</option><option value="/usage/spacy-101" selected="">Get started<!-- --> › <!-- -->spaCy 101</option><option value="/usage/v3">Get started<!-- --> › <!-- -->New in v3.0</option><option value="/usage/v3-1">Get started<!-- --> › <!-- -->New in v3.1</option><option value="/usage/v3-2">Get started<!-- --> › <!-- -->New in v3.2</option><option value="/usage/v3-3">Get started<!-- --> › <!-- -->New in v3.3</option><option value="/usage/v3-4">Get started<!-- --> › <!-- -->New in v3.4</option><option value="/usage/v3-5">Get started<!-- --> › <!-- -->New in v3.5</option><option value="/usage/linguistic-features">Guides<!-- --> › <!-- -->Linguistic Features</option><option value="/usage/rule-based-matching">Guides<!-- --> › <!-- -->Rule-based Matching</option><option value="/usage/processing-pipelines">Guides<!-- --> › <!-- -->Processing Pipelines</option><option value="/usage/embeddings-transformers">Guides<!-- --> › <!-- -->Embeddings &amp; Transformers</option><option value="/usage/training">Guides<!-- --> › <!-- -->Training Models</option><option value="/usage/layers-architectures">Guides<!-- --> › <!-- -->Layers &amp; Model Architectures</option><option value="/usage/projects">Guides<!-- --> › <!-- -->spaCy Projects</option><option value="/usage/saving-loading">Guides<!-- --> › <!-- -->Saving &amp; Loading</option><option value="/usage/visualizers">Guides<!-- --> › <!-- -->Visualizers</option><option value="https://github.com/explosion/projects">Resources<!-- --> › <!-- -->Project Templates</option><option value="https://v2.spacy.io">Resources<!-- --> › <!-- -->v2.x Documentation</option><option value="https://explosion.ai/custom-solutions">Resources<!-- --> › <!-- -->Custom Solutions</option></select></div><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Get started</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage">Installation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/models">Models &amp; Languages</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/facts-figures">Facts &amp; Figures</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP sidebar_is-active__yVTtL is-active" href="/usage/spacy-101">spaCy 101</a><ul class="sidebar_crumbs__NhM2y"><li class="sidebar_crumb__tiiDl sidebar_crumb-active__zq8BI"><a href="#whats-spacy">What&#x27;s spaCy?</a></li><li class="sidebar_crumb__tiiDl"><a href="#features">Features</a></li><li class="sidebar_crumb__tiiDl"><a href="#annotations">Linguistic Annotations</a></li><li class="sidebar_crumb__tiiDl"><a href="#pipelines">Pipelines</a></li><li class="sidebar_crumb__tiiDl"><a href="#architecture">Architecture</a></li><li class="sidebar_crumb__tiiDl"><a href="#vocab">Vocab</a></li><li class="sidebar_crumb__tiiDl"><a href="#serialization">Serialization</a></li><li class="sidebar_crumb__tiiDl"><a href="#training">Training</a></li><li class="sidebar_crumb__tiiDl"><a href="#language-data">Language Data</a></li><li class="sidebar_crumb__tiiDl"><a href="#community-faq">Community &amp; FAQ</a></li></ul></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3">New in v3.0</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-1">New in v3.1</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-2">New in v3.2</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-3">New in v3.3</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-4">New in v3.4</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-5">New in v3.5</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Guides</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/linguistic-features">Linguistic Features</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/rule-based-matching">Rule-based Matching</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/processing-pipelines">Processing Pipelines</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/embeddings-transformers">Embeddings &amp; Transformers<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/training">Training Models<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/layers-architectures">Layers &amp; Model Architectures<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/projects">spaCy Projects<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/saving-loading">Saving &amp; Loading</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/visualizers">Visualizers</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Resources</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/projects">Project Templates</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://v2.spacy.io">v2.x Documentation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></menu><main class="main_root__7f6Tj main_with-sidebar__uH1df main_with-asides__ikQT6"><article class="main_content__8zFCH"><header class="title_root__pS2WQ"><h1 id="_title" class="typography_heading__D82WZ typography_h1__b7dt9 title_h1__l3CW1"><span class="heading-text">spaCy 101: Everything you need to know<!-- --> </span></h1><div class="heading-teaser title_teaser__QhwCH">The most important concepts, explained in simple terms</div></header><section class="section_root__k1hUl"><p>Whether you’re new to spaCy, or just want to brush up on some NLP basics and
implementation details – this page should have you covered. Each section will
explain one of spaCy’s features in simple terms and with examples or
illustrations. Some sections will also reappear across the usage guides as a
quick introduction.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Help us improve the docs<!-- --> </span></h4>
<p>Did you spot a mistake or come across explanations that are unclear? We always
appreciate improvement
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues"><span class="link_source-text__VDP74">suggestions</span></a> or
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/pulls"><span class="link_source-text__VDP74">pull requests</span></a>. You can find a
“Suggest edits” link at the bottom of each page that points you to the source.</p>
</div></div></aside><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span>Take the free interactive course</span></h4><figure class="gatsby-resp-image-figure"><a class="link_root__1Me7D gatsby-resp-image-link embed_image-link__loaAa link_no-link-layout__RPvod" href="https://course.spacy.io"><img class="embed_image__mSQUH" src="/images/course.jpg" alt="Advanced NLP with spaCy" width="650" height="auto"/></a></figure><p>In this course you’ll learn how to use spaCy to build advanced natural language
understanding systems, using both rule-based and machine learning approaches. It
includes 55 exercises featuring interactive coding practice, multiple-choice
questions and slide decks.</p><a class="link_root__1Me7D button_root__jwipc button_primary__JQj6N" href="https://course.spacy.io">Start the course</a></aside></section>
<section id="section-whats-spacy" class="section_root__k1hUl"><h2 id="whats-spacy" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#whats-spacy" class="heading-text typography_permalink__UiIRy">What’s spaCy? <!-- --> </a></h2><div class="grid_root__EfDZl grid_spacing__fhBCv grid_half__xoJZs"><div><p>spaCy is a <strong>free, open-source library</strong> for advanced <strong>Natural Language
Processing</strong> (NLP) in Python.</p><p>If you’re working with a lot of text, you’ll eventually want to know more about
it. For example, what’s it about? What do the words mean in context? Who is
doing what to whom? What companies and products are mentioned? Which texts are
similar to each other?</p><p>spaCy is designed specifically for <strong>production use</strong> and helps you build
applications that process and “understand” large volumes of text. It can be used
to build <strong>information extraction</strong> or <strong>natural language understanding</strong>
systems, or to pre-process text for <strong>deep learning</strong>.</p></div><div><a id="toc"></a><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span>Table of contents</span></h4><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#features">Features</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#annotations">Linguistic annotations</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#annotations-token">Tokenization</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#annotations-pos-deps">POS tags and dependencies</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#annotations-ner">Named entities</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#vectors-similarity">Word vectors and similarity</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#pipelines">Pipelines</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#architecture">Library architecture</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#vocab">Vocab, hashes and lexemes</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#serialization">Serialization</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#training">Training</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#language-data">Language data</a></li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D" href="/usage/spacy-101#community">Community &amp; FAQ</a></li>
</ul></aside></div></div><h3 id="what-spacy-isnt" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#what-spacy-isnt" class="heading-text typography_permalink__UiIRy">What spaCy isn’t <!-- --> </a></h3><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z list_li-icon__F2KvW"><strong>spaCy is not a platform or “an API”</strong>. Unlike a platform, spaCy does not
provide a software as a service, or a web application. It’s an open-source
library designed to help you build NLP applications, not a consumable service.</li>
<li class="list_li__sfx_z list_li-icon__F2KvW"><strong>spaCy is not an out-of-the-box chat bot engine</strong>. While spaCy can be used
to power conversational applications, it’s not designed specifically for chat
bots, and only provides the underlying text processing capabilities.</li>
<li class="list_li__sfx_z list_li-icon__F2KvW"><strong>spaCy is not research software</strong>. It’s built on the latest research, but
it’s designed to get things done. This leads to fairly different design
decisions than <a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/nltk/nltk"><span class="link_source-text__VDP74">NLTK</span></a> or
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://stanfordnlp.github.io/CoreNLP/">CoreNLP</a>, which were created as
platforms for teaching and research. The main difference is that spaCy is
integrated and opinionated. spaCy tries to avoid asking the user to choose
between multiple algorithms that deliver equivalent functionality. Keeping the
menu small lets spaCy deliver generally better performance and developer
experience.</li>
<li class="list_li__sfx_z list_li-icon__F2KvW"><strong>spaCy is not a company</strong>. It’s an open-source library. Our company
publishing spaCy and other software is called
<a class="link_root__1Me7D" href="https://explosion.ai">Explosion</a>.</li>
</ul></section>
<section id="section-features" class="section_root__k1hUl"><h2 id="features" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#features" class="heading-text typography_permalink__UiIRy">Features <!-- --> </a></h2><p>In the documentation, you’ll come across mentions of spaCy’s features and
capabilities. Some of them refer to linguistic concepts, while others are
related to more general machine learning functionality.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Tokenization</strong></td><td class="table_td__rmpJx">Segmenting text into words, punctuations marks etc.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Part-of-speech</strong> (POS) <strong>Tagging</strong></td><td class="table_td__rmpJx">Assigning word types to tokens, like verb or noun.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Dependency Parsing</strong></td><td class="table_td__rmpJx">Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Lemmatization</strong></td><td class="table_td__rmpJx">Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Sentence Boundary Detection</strong> (SBD)</td><td class="table_td__rmpJx">Finding and segmenting individual sentences.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Named Entity Recognition</strong> (NER)</td><td class="table_td__rmpJx">Labelling named “real-world” objects, like persons, companies or locations.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Entity Linking</strong> (EL)</td><td class="table_td__rmpJx">Disambiguating textual entities to unique identifiers in a knowledge base.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Similarity</strong></td><td class="table_td__rmpJx">Comparing words, text spans and documents and how similar they are to each other.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Text Classification</strong></td><td class="table_td__rmpJx">Assigning categories or labels to a whole document, or parts of a document.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Rule-based Matching</strong></td><td class="table_td__rmpJx">Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Training</strong></td><td class="table_td__rmpJx">Updating and improving a statistical model’s predictions.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Serialization</strong></td><td class="table_td__rmpJx">Saving objects to files or byte strings.</td></tr></tbody></table><h3 id="statistical-models" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#statistical-models" class="heading-text typography_permalink__UiIRy">Statistical models <!-- --> </a></h3><p>While some of spaCy’s features work independently, others require
<a class="link_root__1Me7D" href="/models">trained pipelines</a> to be loaded, which enable spaCy to <strong>predict</strong>
linguistic annotations – for example, whether a word is a verb or a noun. A
trained pipeline can consist of multiple components that use a statistical model
trained on labeled data. spaCy currently offers trained pipelines for a variety
of languages, which can be installed as individual Python modules. Pipeline
packages can differ in size, speed, memory usage, accuracy and the data they
include. The package you choose always depends on your use case and the texts
you’re working with. For a general-purpose use case, the small, default packages
are always a good start. They typically include the following components:</p><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Binary weights</strong> for the part-of-speech tagger, dependency parser and named
entity recognizer to predict those annotations in context.</li>
<li class="list_li__sfx_z"><strong>Lexical entries</strong> in the vocabulary, i.e. words and their
context-independent attributes like the shape or spelling.</li>
<li class="list_li__sfx_z"><strong>Data files</strong> like lemmatization rules and lookup tables.</li>
<li class="list_li__sfx_z"><strong>Word vectors</strong>, i.e. multi-dimensional meaning representations of words that
let you determine how similar they are to each other.</li>
<li class="list_li__sfx_z"><strong>Configuration</strong> options, like the language and processing pipeline settings
and model implementations to use, to put spaCy in the correct state when you
load the pipeline.</li>
</ul></section>
<section id="section-annotations" class="section_root__k1hUl"><h2 id="annotations" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#annotations" class="heading-text typography_permalink__UiIRy">Linguistic annotations <!-- --> </a></h2><p>spaCy provides a variety of linguistic annotations to give you <strong>insights into a
text’s grammatical structure</strong>. This includes the word types, like the parts of
speech, and how the words are related to each other. For example, if you’re
analyzing text, it makes a huge difference whether a noun is the subject of a
sentence, or the object – or whether “google” is used as a verb, or refers to
the website or company in a specific context.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Loading pipelines<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre>
</div></div></aside><p>Once you’ve <a class="link_root__1Me7D" href="/usage/models">downloaded and installed</a> a trained pipeline, you
can load it via <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/top-level#spacy.load"><code class="code_inline-code__Bq7ot">spacy.load</code></a>. This will return a
<code class="code_inline-code__Bq7ot">Language</code> object containing all components and data needed to process text. We
usually call it <code class="code_inline-code__Bq7ot">nlp</code>. Calling the <code class="code_inline-code__Bq7ot">nlp</code> object on a string of text will return
a processed <code class="code_inline-code__Bq7ot">Doc</code>:</p><pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre><p>Even though a <code class="code_inline-code__Bq7ot">Doc</code> is processed – e.g. split into individual words and
annotated – it still holds <strong>all information of the original text</strong>, like
whitespace characters. You can always get the offset of a token into the
original string, or reconstruct the original by joining the tokens and their
trailing whitespace. This way, you’ll never lose any information when processing
text with spaCy.</p><h3 id="annotations-token" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#annotations-token" class="heading-text typography_permalink__UiIRy">Tokenization <!-- --> </a></h3><p>During processing, spaCy first <strong>tokenizes</strong> the text, i.e. segments it into
words, punctuation and so on. This is done by applying rules specific to each
language. For example, punctuation at the end of a sentence should be split off
– whereas “U.K.” should remain one token. Each <code class="code_inline-code__Bq7ot">Doc</code> consists of individual
tokens, and we can iterate over them:</p>
<pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8" align="center">0</th><th class="table_th__QJ9F8" align="center">1</th><th class="table_th__QJ9F8" align="center">2</th><th class="table_th__QJ9F8" align="center">3</th><th class="table_th__QJ9F8" align="center">4</th><th class="table_th__QJ9F8" align="center">5</th><th class="table_th__QJ9F8" align="center">6</th><th class="table_th__QJ9F8" align="center">7</th><th class="table_th__QJ9F8" align="center">8</th><th class="table_th__QJ9F8" align="center">9</th><th class="table_th__QJ9F8" align="center">10</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx" align="center">Apple</td><td class="table_td__rmpJx" align="center">is</td><td class="table_td__rmpJx" align="center">looking</td><td class="table_td__rmpJx" align="center">at</td><td class="table_td__rmpJx" align="center">buying</td><td class="table_td__rmpJx" align="center">U.K.</td><td class="table_td__rmpJx" align="center">startup</td><td class="table_td__rmpJx" align="center">for</td><td class="table_td__rmpJx" align="center">$</td><td class="table_td__rmpJx" align="center">1</td><td class="table_td__rmpJx" align="center">billion</td></tr></tbody></table>
<p>First, the raw text is split on whitespace characters, similar to
<code class="code_inline-code__Bq7ot">text.split(&#x27; &#x27;)</code>. Then, the tokenizer processes the text from left to right. On
each substring, it performs two checks:</p>
<ol class="list_ol__aclSa">
<li class="list_li__sfx_z">
<p><strong>Does the substring match a tokenizer exception rule?</strong> For example, “don’t”
does not contain whitespace, but should be split into two tokens, “do” and
“n’t”, while “U.K.” should always remain one token.</p>
</li>
<li class="list_li__sfx_z">
<p><strong>Can a prefix, suffix or infix be split off?</strong> For example punctuation like
commas, periods, hyphens or quotes.</p>
</li>
</ol>
<p>If there’s a match, the rule is applied and the tokenizer continues its loop,
starting with the newly split substrings. This way, spaCy can split <strong>complex,
nested tokens</strong> like combinations of abbreviations and multiple punctuation
marks.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Tokenizer exception:</strong> Special-case rule to split a string into several
tokens or prevent a token from being split when punctuation rules are
applied.</li>
<li class="list_li__sfx_z"><strong>Prefix:</strong> Character(s) at the beginning, e.g. <code class="code_inline-code__Bq7ot">$</code>, <code class="code_inline-code__Bq7ot">(</code>, <code class="code_inline-code__Bq7ot">“</code>, <code class="code_inline-code__Bq7ot">¿</code>.</li>
<li class="list_li__sfx_z"><strong>Suffix:</strong> Character(s) at the end, e.g. <code class="code_inline-code__Bq7ot">km</code>, <code class="code_inline-code__Bq7ot">)</code>, <code class="code_inline-code__Bq7ot">”</code>, <code class="code_inline-code__Bq7ot">!</code>.</li>
<li class="list_li__sfx_z"><strong>Infix:</strong> Character(s) in between, e.g. <code class="code_inline-code__Bq7ot">-</code>, <code class="code_inline-code__Bq7ot">--</code>, <code class="code_inline-code__Bq7ot">/</code>, <code class="code_inline-code__Bq7ot">…</code>.</li>
</ul>
</div></div></aside>
<figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/tokenization.svg" alt="Example of the tokenization process" width="650" height="auto"/></figure>
<p>While punctuation rules are usually pretty general, tokenizer exceptions
strongly depend on the specifics of the individual language. This is why each
<a class="link_root__1Me7D" href="/usage/models#languages">available language</a> has its own subclass, like
<code class="code_inline-code__Bq7ot">English</code> or <code class="code_inline-code__Bq7ot">German</code>, that loads in lists of hard-coded data and exception
rules.</p><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Tokenization rules</span></h4><p>To learn more about how spaCy’s tokenization rules work in detail, how to
<strong>customize and replace</strong> the default tokenizer and how to <strong>add
language-specific data</strong>, see the usage guides on
<a class="link_root__1Me7D" href="/usage/linguistic-features#language-data">language data</a> and
<a class="link_root__1Me7D" href="/usage/linguistic-features#tokenization">customizing the tokenizer</a>.</p></aside><h3 id="annotations-pos-deps" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#annotations-pos-deps" class="heading-text typography_permalink__UiIRy">Part-of-speech tags and dependencies <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH" data-tooltip="To use this functionality, spaCy needs a trained pipeline that supports the following capabilities: parser">Needs model</span></h3><p>After tokenization, spaCy can <strong>parse</strong> and <strong>tag</strong> a given <code class="code_inline-code__Bq7ot">Doc</code>. This is where
the trained pipeline and its statistical models come in, which enable spaCy to
<strong>make predictions</strong> of which tag or label most likely applies in this context.
A trained component includes binary data that is produced by showing a system
enough examples for it to make predictions that generalize across the language –
for example, a word following “the” in English is most likely a noun.</p>
<p>Linguistic annotations are available as
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token#attributes"><code class="code_inline-code__Bq7ot">Token</code> attributes</a>. Like many NLP libraries, spaCy
<strong>encodes all strings to hash values</strong> to reduce memory usage and improve
efficiency. So to get the readable string representation of an attribute, we
need to add an underscore <code class="code_inline-code__Bq7ot">_</code> to its name:</p>
<pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Text:</strong> The original word text.</li>
<li class="list_li__sfx_z"><strong>Lemma:</strong> The base form of the word.</li>
<li class="list_li__sfx_z"><strong>POS:</strong> The simple <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://universaldependencies.org/u/pos/">UPOS</a>
part-of-speech tag.</li>
<li class="list_li__sfx_z"><strong>Tag:</strong> The detailed part-of-speech tag.</li>
<li class="list_li__sfx_z"><strong>Dep:</strong> Syntactic dependency, i.e. the relation between tokens.</li>
<li class="list_li__sfx_z"><strong>Shape:</strong> The word shape – capitalization, punctuation, digits.</li>
<li class="list_li__sfx_z"><strong>is alpha:</strong> Is the token an alpha character?</li>
<li class="list_li__sfx_z"><strong>is stop:</strong> Is the token part of a stop list, i.e. the most common words of
the language?</li>
</ul>
</div></div></aside>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Text</th><th class="table_th__QJ9F8">Lemma</th><th class="table_th__QJ9F8">POS</th><th class="table_th__QJ9F8">Tag</th><th class="table_th__QJ9F8">Dep</th><th class="table_th__QJ9F8">Shape</th><th class="table_th__QJ9F8">alpha</th><th class="table_th__QJ9F8">stop</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">Apple</td><td class="table_td__rmpJx">apple</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">PROPN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NNP</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nsubj</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Xxxxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">is</td><td class="table_td__rmpJx">be</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">AUX</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">VBZ</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">aux</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">looking</td><td class="table_td__rmpJx">look</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">VERB</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">VBG</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ROOT</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">at</td><td class="table_td__rmpJx">at</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ADP</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">IN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">prep</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">buying</td><td class="table_td__rmpJx">buy</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">VERB</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">VBG</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pcomp</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">U.K.</td><td class="table_td__rmpJx">u.k.</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">PROPN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NNP</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">compound</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">X.X.</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">startup</td><td class="table_td__rmpJx">startup</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NOUN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">dobj</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">for</td><td class="table_td__rmpJx">for</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ADP</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">IN</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">prep</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">$</td><td class="table_td__rmpJx">$</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">SYM</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">$</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">quantmod</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">$</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">1</td><td class="table_td__rmpJx">1</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NUM</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">CD</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">compound</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">d</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">billion</td><td class="table_td__rmpJx">billion</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">NUM</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">CD</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">pobj</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr></tbody></table>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Tip: Understanding tags and labels<!-- --> </span></h4>
<p>Most of the tags and labels look pretty abstract, and they vary between
languages. <code class="code_inline-code__Bq7ot">spacy.explain</code> will show you a short description – for example,
<code class="code_inline-code__Bq7ot">spacy.explain(&quot;VBZ&quot;)</code> returns “verb, 3rd person singular present”.</p>
</div></div></aside>
<p>Using spaCy’s built-in <a class="link_root__1Me7D" href="/usage/visualizers">displaCy visualizer</a>, here’s what
our example sentence and its dependencies look like:</p>
<iframe class="embed_standalone__RHbIL" title="displaCy visualization of dependencies and entities" src="/images/displacy-long.html" width="800" height="450" allowfullscreen="" frameBorder="0"></iframe><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Part-of-speech tagging and morphology</span></h4><p>To learn more about <strong>part-of-speech tagging</strong> and rule-based morphology, and
how to <strong>navigate and use the parse tree</strong> effectively, see the usage guides on
<a class="link_root__1Me7D" href="/usage/linguistic-features#pos-tagging">part-of-speech tagging</a> and
<a class="link_root__1Me7D" href="/usage/linguistic-features#dependency-parse">using the dependency parse</a>.</p></aside><h3 id="annotations-ner" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#annotations-ner" class="heading-text typography_permalink__UiIRy">Named Entities <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH" data-tooltip="To use this functionality, spaCy needs a trained pipeline that supports the following capabilities: ner">Needs model</span></h3><p>A named entity is a “real-world object” that’s assigned a name – for example, a
person, a country, a product or a book title. spaCy can <strong>recognize various
types of named entities in a document, by asking the model for a prediction</strong>.
Because models are statistical and strongly depend on the examples they were
trained on, this doesn’t always work <em>perfectly</em> and might need some tuning
later, depending on your use case.</p>
<p>Named entities are available as the <code class="code_inline-code__Bq7ot">ents</code> property of a <code class="code_inline-code__Bq7ot">Doc</code>:</p>
<pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Text:</strong> The original entity text.</li>
<li class="list_li__sfx_z"><strong>Start:</strong> Index of start of entity in the <code class="code_inline-code__Bq7ot">Doc</code>.</li>
<li class="list_li__sfx_z"><strong>End:</strong> Index of end of entity in the <code class="code_inline-code__Bq7ot">Doc</code>.</li>
<li class="list_li__sfx_z"><strong>Label:</strong> Entity label, i.e. type.</li>
</ul>
</div></div></aside>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Text</th><th class="table_th__QJ9F8" align="center">Start</th><th class="table_th__QJ9F8" align="center">End</th><th class="table_th__QJ9F8">Label</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">Apple</td><td class="table_td__rmpJx" align="center">0</td><td class="table_td__rmpJx" align="center">5</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">ORG</code></td><td class="table_td__rmpJx">Companies, agencies, institutions.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">U.K.</td><td class="table_td__rmpJx table_num__mTxMB" align="center">27</td><td class="table_td__rmpJx table_num__mTxMB" align="center">31</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">GPE</code></td><td class="table_td__rmpJx">Geopolitical entity, i.e. countries, cities, states.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">$1 billion</td><td class="table_td__rmpJx table_num__mTxMB" align="center">44</td><td class="table_td__rmpJx table_num__mTxMB" align="center">54</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">MONEY</code></td><td class="table_td__rmpJx">Monetary values, including unit.</td></tr></tbody></table>
<p>Using spaCy’s built-in <a class="link_root__1Me7D" href="/usage/visualizers">displaCy visualizer</a>, here’s what
our example sentence and its named entities look like:</p>
<iframe class="embed_standalone__RHbIL" title="displaCy visualization of entities" src="/images/displacy-ent1.html" width="800" height="100" allowfullscreen="" frameBorder="0"></iframe><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Named Entity Recognition</span></h4><p>To learn more about entity recognition in spaCy, how to <strong>add your own
entities</strong> to a document and how to <strong>train and update</strong> the entity predictions
of a model, see the usage guides on
<a class="link_root__1Me7D" href="/usage/linguistic-features#named-entities">named entity recognition</a> and
<a class="link_root__1Me7D" href="/usage/training">training pipelines</a>.</p></aside><h3 id="vectors-similarity" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#vectors-similarity" class="heading-text typography_permalink__UiIRy">Word vectors and similarity <!-- --> </a><span class="tag_root__NTSnK tag_spaced__Q9amH" data-tooltip="To use this functionality, spaCy needs a trained pipeline that supports the following capabilities: vectors">Needs model</span></h3><p>Similarity is determined by comparing <strong>word vectors</strong> or “word embeddings”,
multi-dimensional meaning representations of a word. Word vectors can be
generated using an algorithm like
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> and usually look like this:</p>
<pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">banana.vector</h4><code class="code_code__CILJL language-python language-python"></code></pre>
<aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note</span></h4><p>To make them compact and fast, spaCy’s small <a class="link_root__1Me7D" href="/models">pipeline packages</a> (all
packages that end in <code class="code_inline-code__Bq7ot">sm</code>) <strong>don’t ship with word vectors</strong>, and only include
context-sensitive <strong>tensors</strong>. This means you can still use the <code class="code_inline-code__Bq7ot">similarity()</code>
methods to compare documents, spans and tokens – but the result won’t be as
good, and individual tokens won’t have any vectors assigned. So in order to use
<em>real</em> word vectors, you need to download a larger pipeline package:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre></aside>
<p>Pipeline packages that come with built-in word vectors make them available as
the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token#vector"><code class="code_inline-code__Bq7ot">Token.vector</code></a> attribute.
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc#vector"><code class="code_inline-code__Bq7ot">Doc.vector</code></a> and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span#vector"><code class="code_inline-code__Bq7ot">Span.vector</code></a> will
default to an average of their token vectors. You can also check if a token has
a vector assigned, and get the L2 norm, which can be used to normalize vectors.</p>
<pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Text</strong>: The original token text.</li>
<li class="list_li__sfx_z"><strong>has vector</strong>: Does the token have a vector representation?</li>
<li class="list_li__sfx_z"><strong>Vector norm</strong>: The L2 norm of the token’s vector (the square root of the
sum of the values squared)</li>
<li class="list_li__sfx_z"><strong>OOV</strong>: Out-of-vocabulary</li>
</ul>
</div></div></aside>
<p>The words “dog”, “cat” and “banana” are all pretty common in English, so they’re
part of the pipeline’s vocabulary, and come with a vector. The word “afskfsd” on
the other hand is a lot less common and out-of-vocabulary – so its vector
representation consists of 300 dimensions of <code class="code_inline-code__Bq7ot">0</code>, which means it’s practically
nonexistent. If your application will benefit from a <strong>large vocabulary</strong> with
more vectors, you should consider using one of the larger pipeline packages or
loading in a full vector package, for example,
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/models/en#en_core_web_lg"><code class="code_inline-code__Bq7ot">en_core_web_lg</code></a>, which includes <strong>685k unique
vectors</strong>.</p>
<p>spaCy is able to compare two objects, and make a prediction of <strong>how similar
they are</strong>. Predicting similarity is useful for building recommendation systems
or flagging duplicates. For example, you can suggest a user content that’s
similar to what they’re currently looking at, or label a support ticket as a
duplicate if it’s very similar to an already existing one.</p>
<p>Each <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a>, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span"><code class="code_inline-code__Bq7ot">Span</code></a>, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token"><code class="code_inline-code__Bq7ot">Token</code></a> and
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lexeme"><code class="code_inline-code__Bq7ot">Lexeme</code></a> comes with a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token#similarity"><code class="code_inline-code__Bq7ot">.similarity</code></a>
method that lets you compare it with another object, and determine the
similarity. Of course similarity is always subjective – whether two words, spans
or documents are similar really depends on how you’re looking at it. spaCy’s
similarity implementation usually assumes a pretty general-purpose definition of
similarity.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">📝 Things to try<!-- --> </span></h4>
<ol class="list_ol__aclSa">
<li class="list_li__sfx_z">Compare two different tokens and try to find the two most <em>dissimilar</em>
tokens in the texts with the lowest similarity score (according to the
vectors).</li>
<li class="list_li__sfx_z">Compare the similarity of two <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lexeme"><code class="code_inline-code__Bq7ot">Lexeme</code></a> objects, entries in
the vocabulary. You can get a lexeme via the <code class="code_inline-code__Bq7ot">.lex</code> attribute of a token.
You should see that the similarity results are identical to the token
similarity.</li>
</ol>
</div></div></aside>
<pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre>
<h3 id="similarity-expectations" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#similarity-expectations" class="heading-text typography_permalink__UiIRy">What to expect from similarity results <!-- --> </a></h3>
<p>Computing similarity scores can be helpful in many situations, but it’s also
important to maintain <strong>realistic expectations</strong> about what information it can
provide. Words can be related to each other in many ways, so a single
“similarity” score will always be a <strong>mix of different signals</strong>, and vectors
trained on different data can produce very different results that may not be
useful for your purpose. Here are some important considerations to keep in mind:</p>
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z">There’s no objective definition of similarity. Whether “I like burgers” and “I
like pasta” is similar <strong>depends on your application</strong>. Both talk about food
preferences, which makes them very similar – but if you’re analyzing mentions
of food, those sentences are pretty dissimilar, because they talk about very
different foods.</li>
<li class="list_li__sfx_z">The similarity of <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span"><code class="code_inline-code__Bq7ot">Span</code></a> objects defaults
to the <strong>average</strong> of the token vectors. This means that the vector for “fast
food” is the average of the vectors for “fast” and “food”, which isn’t
necessarily representative of the phrase “fast food”.</li>
<li class="list_li__sfx_z">Vector averaging means that the vector of multiple tokens is <strong>insensitive to
the order</strong> of the words. Two documents expressing the same meaning with
dissimilar wording will return a lower similarity score than two documents
that happen to contain the same words while expressing different meanings.</li>
</ul>
<aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">💡</span>Tip: Check out sense2vec</span></h4><figure class="gatsby-resp-image-figure"><a class="link_root__1Me7D gatsby-resp-image-link embed_image-link__loaAa link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/sense2vec"><img class="embed_image__mSQUH" src="/images/sense2vec.jpg" alt="sense2vec Screenshot" width="650" height="auto"/></a></figure><p><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/sense2vec"><code class="code_inline-code__Bq7ot">sense2vec</code></a> is a library developed by
us that builds on top of spaCy and lets you train and query more interesting and
detailed word vectors. It combines noun phrases like “fast food” or “fair game”
and includes the part-of-speech tags and entity labels. The library also
includes annotation recipes for our annotation tool <a class="link_root__1Me7D" href="https://prodi.gy">Prodigy</a>
that let you evaluate vectors and create terminology lists. For more details,
check out <a class="link_root__1Me7D" href="https://explosion.ai/blog/sense2vec-reloaded">our blog post</a>. To
explore the semantic similarities across all Reddit comments of 2015 and 2019,
see the <a class="link_root__1Me7D" href="https://explosion.ai/demos/sense2vec">interactive demo</a>.</p></aside><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Word vectors</span></h4><p>To learn more about word vectors, how to <strong>customize them</strong> and how to load
<strong>your own vectors</strong> into spaCy, see the usage guide on
<a class="link_root__1Me7D" href="/usage/linguistic-features#vectors-similarity">using word vectors and semantic similarities</a>.</p></aside></section>
<section id="section-pipelines" class="section_root__k1hUl"><h2 id="pipelines" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#pipelines" class="heading-text typography_permalink__UiIRy">Pipelines <!-- --> </a></h2><p>When you call <code class="code_inline-code__Bq7ot">nlp</code> on a text, spaCy first tokenizes the text to produce a <code class="code_inline-code__Bq7ot">Doc</code>
object. The <code class="code_inline-code__Bq7ot">Doc</code> is then processed in several different steps – this is also
referred to as the <strong>processing pipeline</strong>. The pipeline used by the
<a class="link_root__1Me7D" href="/models">trained pipelines</a> typically include a tagger, a lemmatizer, a parser
and an entity recognizer. Each pipeline component returns the processed <code class="code_inline-code__Bq7ot">Doc</code>,
which is then passed on to the next component.</p>
<figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/pipeline.svg" alt="The processing pipeline" width="650" height="auto"/></figure>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Name</strong>: ID of the pipeline component.</li>
<li class="list_li__sfx_z"><strong>Component:</strong> spaCy’s implementation of the component.</li>
<li class="list_li__sfx_z"><strong>Creates:</strong> Objects, attributes and properties modified and set by the
component.</li>
</ul>
</div></div></aside>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Component</th><th class="table_th__QJ9F8">Creates</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>tokenizer</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tokenizer"><code class="code_inline-code__Bq7ot">Tokenizer</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Doc</code></td><td class="table_td__rmpJx">Segment text into tokens.</td></tr><tr class="table_tr__K_tkF table_divider__DRQHe"><td class="table_td__rmpJx"><em>processing pipeline</em></td><td class="table_td__rmpJx"></td><td class="table_td__rmpJx"></td><td class="table_td__rmpJx"></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>tagger</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tagger"><code class="code_inline-code__Bq7ot">Tagger</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Token.tag</code></td><td class="table_td__rmpJx">Assign part-of-speech tags.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>parser</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/dependencyparser"><code class="code_inline-code__Bq7ot">DependencyParser</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Token.head</code>, <code class="code_inline-code__Bq7ot">Token.dep</code>, <code class="code_inline-code__Bq7ot">Doc.sents</code>, <code class="code_inline-code__Bq7ot">Doc.noun_chunks</code></td><td class="table_td__rmpJx">Assign dependency labels.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>ner</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityrecognizer"><code class="code_inline-code__Bq7ot">EntityRecognizer</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Doc.ents</code>, <code class="code_inline-code__Bq7ot">Token.ent_iob</code>, <code class="code_inline-code__Bq7ot">Token.ent_type</code></td><td class="table_td__rmpJx">Detect and label named entities.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>lemmatizer</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lemmatizer"><code class="code_inline-code__Bq7ot">Lemmatizer</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Token.lemma</code></td><td class="table_td__rmpJx">Assign base forms.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>textcat</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Doc.cats</code></td><td class="table_td__rmpJx">Assign document labels.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>custom</strong></td><td class="table_td__rmpJx"><a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components">custom components</a></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">Doc._.xxx</code>, <code class="code_inline-code__Bq7ot">Token._.xxx</code>, <code class="code_inline-code__Bq7ot">Span._.xxx</code></td><td class="table_td__rmpJx">Assign custom attributes, methods or properties.</td></tr></tbody></table>
<p>The capabilities of a processing pipeline always depend on the components, their
models and how they were trained. For example, a pipeline for named entity
recognition needs to include a trained named entity recognizer component with a
statistical model and weights that enable it to <strong>make predictions</strong> of entity
labels. This is why each pipeline specifies its components and their settings in
the <a class="link_root__1Me7D" href="/usage/training#config">config</a>:</p>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
<section class="accordion" id="pipeline-components-order"><div class="accordion_root__pPltq"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Does the order of pipeline components matter?</span><a class="link_root__1Me7D accordion_anchor__kidBh link_no-link-layout__RPvod" href="/usage/spacy-101#pipeline-components-order">¶</a></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p>The statistical components like the tagger or parser are typically independent
and don’t share any data between each other. For example, the named entity
recognizer doesn’t use any features set by the tagger and parser, and so on.
This means that you can swap them, or remove single components from the pipeline
without affecting the others. However, components may share a “token-to-vector”
component like <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tok2vec"><code class="code_inline-code__Bq7ot">Tok2Vec</code></a> or <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/transformer"><code class="code_inline-code__Bq7ot">Transformer</code></a>.
You can read more about this in the docs on
<a class="link_root__1Me7D" href="/usage/embeddings-transformers#embedding-layers">embedding layers</a>.</p><p>Custom components may also depend on annotations set by other components. For
example, a custom lemmatizer may need the part-of-speech tags assigned, so it’ll
only work if it’s added after the tagger. The parser will respect pre-defined
sentence boundaries, so if a previous component in the pipeline sets them, its
dependency predictions may be different. Similarly, it matters if you add the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityruler"><code class="code_inline-code__Bq7ot">EntityRuler</code></a> before or after the statistical entity
recognizer: if it’s added before, the entity recognizer will take the existing
entities into account when making predictions. The
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entitylinker"><code class="code_inline-code__Bq7ot">EntityLinker</code></a>, which resolves named entities to knowledge
base IDs, should be preceded by a pipeline component that recognizes entities
such as the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityrecognizer"><code class="code_inline-code__Bq7ot">EntityRecognizer</code></a>.</p></div></div></section>
<section class="accordion" id="pipeline-components-tokenizer"><div class="accordion_root__pPltq"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Why is the tokenizer special?</span><a class="link_root__1Me7D accordion_anchor__kidBh link_no-link-layout__RPvod" href="/usage/spacy-101#pipeline-components-tokenizer">¶</a></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p>The tokenizer is a “special” component and isn’t part of the regular pipeline.
It also doesn’t show up in <code class="code_inline-code__Bq7ot">nlp.pipe_names</code>. The reason is that there can only
really be one tokenizer, and while all other pipeline components take a <code class="code_inline-code__Bq7ot">Doc</code>
and return it, the tokenizer takes a <strong>string of text</strong> and turns it into a
<code class="code_inline-code__Bq7ot">Doc</code>. You can still customize the tokenizer, though. <code class="code_inline-code__Bq7ot">nlp.tokenizer</code> is
writable, so you can either create your own
<a class="link_root__1Me7D" href="/usage/linguistic-features#native-tokenizers"><code class="code_inline-code__Bq7ot">Tokenizer</code> class from scratch</a>,
or even replace it with an
<a class="link_root__1Me7D" href="/usage/linguistic-features#custom-tokenizer">entirely custom function</a>.</p></div></div></section>
<hr class="section_hr__07Hes"/><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Processing pipelines</span></h4><p>To learn more about <strong>how processing pipelines work</strong> in detail, how to enable
and disable their components, and how to <strong>create your own</strong>, see the usage
guide on <a class="link_root__1Me7D" href="/usage/processing-pipelines">language processing pipelines</a>.</p></aside></section>
<section id="section-architecture" class="section_root__k1hUl"><h2 id="architecture" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#architecture" class="heading-text typography_permalink__UiIRy">Architecture <!-- --> </a></h2><p>The central data structures in spaCy are the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language"><code class="code_inline-code__Bq7ot">Language</code></a> class,
the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a> and the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> object. The <code class="code_inline-code__Bq7ot">Language</code> class
is used to process a text and turn it into a <code class="code_inline-code__Bq7ot">Doc</code> object. It’s typically stored
as a variable called <code class="code_inline-code__Bq7ot">nlp</code>. The <code class="code_inline-code__Bq7ot">Doc</code> object owns the <strong>sequence of tokens</strong> and
all their annotations. By centralizing strings, word vectors and lexical
attributes in the <code class="code_inline-code__Bq7ot">Vocab</code>, we avoid storing multiple copies of this data. This
saves memory, and ensures there’s a <strong>single source of truth</strong>.</p>
<p>Text annotations are also designed to allow a single source of truth: the <code class="code_inline-code__Bq7ot">Doc</code>
object owns the data, and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span"><code class="code_inline-code__Bq7ot">Span</code></a> and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token"><code class="code_inline-code__Bq7ot">Token</code></a> are
<strong>views that point into it</strong>. The <code class="code_inline-code__Bq7ot">Doc</code> object is constructed by the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tokenizer"><code class="code_inline-code__Bq7ot">Tokenizer</code></a>, and then <strong>modified in place</strong> by the components
of the pipeline. The <code class="code_inline-code__Bq7ot">Language</code> object coordinates these components. It takes
raw text and sends it through the pipeline, returning an <strong>annotated document</strong>.
It also orchestrates training and serialization.</p>
<figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/architecture.svg" alt="Library architecture {w:1080, h:1254}" width="650" height="auto"/></figure>
<h3 id="architecture-containers" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#architecture-containers" class="heading-text typography_permalink__UiIRy">Container objects <!-- --> </a></h3>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a></td><td class="table_td__rmpJx">A container for accessing linguistic annotations.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/docbin"><code class="code_inline-code__Bq7ot">DocBin</code></a></td><td class="table_td__rmpJx">A collection of <code class="code_inline-code__Bq7ot">Doc</code> objects for efficient binary serialization. Also used for <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/data-formats#binary-training"><span class="link_source-text__VDP74">training data</span></a>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/example"><code class="code_inline-code__Bq7ot">Example</code></a></td><td class="table_td__rmpJx">A collection of training annotations, containing two <code class="code_inline-code__Bq7ot">Doc</code> objects: the reference data and the predictions.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language"><code class="code_inline-code__Bq7ot">Language</code></a></td><td class="table_td__rmpJx">Processing class that turns text into <code class="code_inline-code__Bq7ot">Doc</code> objects. Different languages implement their own subclasses of it. The variable is typically called <code class="code_inline-code__Bq7ot">nlp</code>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lexeme"><code class="code_inline-code__Bq7ot">Lexeme</code></a></td><td class="table_td__rmpJx">An entry in the vocabulary. It’s a word type with no context, as opposed to a word token. It therefore has no part-of-speech tag, dependency parse etc.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span"><code class="code_inline-code__Bq7ot">Span</code></a></td><td class="table_td__rmpJx">A slice from a <code class="code_inline-code__Bq7ot">Doc</code> object.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/spangroup"><code class="code_inline-code__Bq7ot">SpanGroup</code></a></td><td class="table_td__rmpJx">A named collection of spans belonging to a <code class="code_inline-code__Bq7ot">Doc</code>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/token"><code class="code_inline-code__Bq7ot">Token</code></a></td><td class="table_td__rmpJx">An individual token — i.e. a word, punctuation symbol, whitespace, etc.</td></tr></tbody></table>
<h3 id="architecture-pipeline" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#architecture-pipeline" class="heading-text typography_permalink__UiIRy">Processing pipeline <!-- --> </a></h3>
<p>The processing pipeline consists of one or more <strong>pipeline components</strong> that are
called on the <code class="code_inline-code__Bq7ot">Doc</code> in order. The tokenizer runs before the components. Pipeline
components can be added using <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#add_pipe"><code class="code_inline-code__Bq7ot">Language.add_pipe</code></a>.
They can contain a statistical model and trained weights, or only make
rule-based modifications to the <code class="code_inline-code__Bq7ot">Doc</code>. spaCy provides a range of built-in
components for different language processing tasks and also allows adding
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components">custom components</a>.</p>
<figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/pipeline.svg" alt="The processing pipeline" width="650" height="auto"/></figure>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/attributeruler"><code class="code_inline-code__Bq7ot">AttributeRuler</code></a></td><td class="table_td__rmpJx">Set token attributes using matcher rules.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/dependencyparser"><code class="code_inline-code__Bq7ot">DependencyParser</code></a></td><td class="table_td__rmpJx">Predict syntactic dependencies.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/edittreelemmatizer"><code class="code_inline-code__Bq7ot">EditTreeLemmatizer</code></a></td><td class="table_td__rmpJx">Predict base forms of words.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entitylinker"><code class="code_inline-code__Bq7ot">EntityLinker</code></a></td><td class="table_td__rmpJx">Disambiguate named entities to nodes in a knowledge base.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityrecognizer"><code class="code_inline-code__Bq7ot">EntityRecognizer</code></a></td><td class="table_td__rmpJx">Predict named entities, e.g. persons or products.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityruler"><code class="code_inline-code__Bq7ot">EntityRuler</code></a></td><td class="table_td__rmpJx">Add entity spans to the <code class="code_inline-code__Bq7ot">Doc</code> using token-based rules or exact phrase matches.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lemmatizer"><code class="code_inline-code__Bq7ot">Lemmatizer</code></a></td><td class="table_td__rmpJx">Determine the base forms of words using rules and lookups.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/morphologizer"><code class="code_inline-code__Bq7ot">Morphologizer</code></a></td><td class="table_td__rmpJx">Predict morphological features and coarse-grained part-of-speech tags.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/sentencerecognizer"><code class="code_inline-code__Bq7ot">SentenceRecognizer</code></a></td><td class="table_td__rmpJx">Predict sentence boundaries.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/sentencizer"><code class="code_inline-code__Bq7ot">Sentencizer</code></a></td><td class="table_td__rmpJx">Implement rule-based sentence boundary detection that doesn’t require the dependency parse.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tagger"><code class="code_inline-code__Bq7ot">Tagger</code></a></td><td class="table_td__rmpJx">Predict part-of-speech tags.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/textcategorizer"><code class="code_inline-code__Bq7ot">TextCategorizer</code></a></td><td class="table_td__rmpJx">Predict categories or labels over the whole document.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tok2vec"><code class="code_inline-code__Bq7ot">Tok2Vec</code></a></td><td class="table_td__rmpJx">Apply a “token-to-vector” model and set its outputs.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/tokenizer"><code class="code_inline-code__Bq7ot">Tokenizer</code></a></td><td class="table_td__rmpJx">Segment raw text and create <code class="code_inline-code__Bq7ot">Doc</code> objects from the words.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/pipe"><code class="code_inline-code__Bq7ot">TrainablePipe</code></a></td><td class="table_td__rmpJx">Class that all trainable pipeline components inherit from.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/transformer"><code class="code_inline-code__Bq7ot">Transformer</code></a></td><td class="table_td__rmpJx">Use a transformer model and set its outputs.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/pipeline-functions"><span class="link_source-text__VDP74">Other functions</span></a></td><td class="table_td__rmpJx">Automatically apply something to the <code class="code_inline-code__Bq7ot">Doc</code>, e.g. to merge spans of tokens.</td></tr></tbody></table>
<h3 id="architecture-matchers" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#architecture-matchers" class="heading-text typography_permalink__UiIRy">Matchers <!-- --> </a></h3>
<p>Matchers help you find and extract information from <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> objects
based on match patterns describing the sequences you’re looking for. A matcher
operates on a <code class="code_inline-code__Bq7ot">Doc</code> and gives you access to the matched tokens <strong>in context</strong>.</p>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/dependencymatcher"><code class="code_inline-code__Bq7ot">DependencyMatcher</code></a></td><td class="table_td__rmpJx">Match sequences of tokens based on dependency trees using <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html">Semgrex operators</a>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/matcher"><code class="code_inline-code__Bq7ot">Matcher</code></a></td><td class="table_td__rmpJx">Match sequences of tokens, based on pattern rules, similar to regular expressions.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/phrasematcher"><code class="code_inline-code__Bq7ot">PhraseMatcher</code></a></td><td class="table_td__rmpJx">Match sequences of tokens based on phrases.</td></tr></tbody></table>
<h3 id="architecture-other" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#architecture-other" class="heading-text typography_permalink__UiIRy">Other classes <!-- --> </a></h3>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/corpus"><code class="code_inline-code__Bq7ot">Corpus</code></a></td><td class="table_td__rmpJx">Class for managing annotated corpora for training and evaluation data.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/kb"><code class="code_inline-code__Bq7ot">KnowledgeBase</code></a></td><td class="table_td__rmpJx">Abstract base class for storage and retrieval of data for entity linking.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/inmemorylookupkb"><code class="code_inline-code__Bq7ot">InMemoryLookupKB</code></a></td><td class="table_td__rmpJx">Implementation of <code class="code_inline-code__Bq7ot">KnowledgeBase</code> storing all data in memory.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/kb#candidate"><code class="code_inline-code__Bq7ot">Candidate</code></a></td><td class="table_td__rmpJx">Object associating a textual mention with a specific entity contained in a <code class="code_inline-code__Bq7ot">KnowledgeBase</code>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lookups"><code class="code_inline-code__Bq7ot">Lookups</code></a></td><td class="table_td__rmpJx">Container for convenient access to large lookup tables and dictionaries.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/morphology#morphanalysis"><code class="code_inline-code__Bq7ot">MorphAnalysis</code></a></td><td class="table_td__rmpJx">A morphological analysis.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/morphology"><code class="code_inline-code__Bq7ot">Morphology</code></a></td><td class="table_td__rmpJx">Store morphological analyses and map them to and from hash values.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/scorer"><code class="code_inline-code__Bq7ot">Scorer</code></a></td><td class="table_td__rmpJx">Compute evaluation scores.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/stringstore"><code class="code_inline-code__Bq7ot">StringStore</code></a></td><td class="table_td__rmpJx">Map strings to and from hash values.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vectors"><code class="code_inline-code__Bq7ot">Vectors</code></a></td><td class="table_td__rmpJx">Container class for vector data keyed by string.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a></td><td class="table_td__rmpJx">The shared vocabulary that stores strings and gives you access to <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lexeme"><code class="code_inline-code__Bq7ot">Lexeme</code></a> objects.</td></tr></tbody></table></section>
<section id="section-vocab" class="section_root__k1hUl"><h2 id="vocab" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#vocab" class="heading-text typography_permalink__UiIRy">Vocab, hashes and lexemes <!-- --> </a></h2><p>Whenever possible, spaCy tries to store data in a vocabulary, the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a>, that will be <strong>shared by multiple documents</strong>. To save
memory, spaCy also encodes all strings to <strong>hash values</strong> – in this case for
example, “coffee” has the hash <code class="code_inline-code__Bq7ot">3197928453018144401</code>. Entity labels like “ORG”
and part-of-speech tags like “VERB” are also encoded. Internally, spaCy only
“speaks” in hash values.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Token</strong>: A word, punctuation mark etc. <em>in context</em>, including its
attributes, tags and dependencies.</li>
<li class="list_li__sfx_z"><strong>Lexeme</strong>: A “word type” with no context. Includes the word shape and
flags, e.g. if it’s lowercase, a digit or punctuation.</li>
<li class="list_li__sfx_z"><strong>Doc</strong>: A processed container of tokens in context.</li>
<li class="list_li__sfx_z"><strong>Vocab</strong>: The collection of lexemes.</li>
<li class="list_li__sfx_z"><strong>StringStore</strong>: The dictionary mapping hash values to strings, for example
<code class="code_inline-code__Bq7ot">3197928453018144401</code> → “coffee”.</li>
</ul>
</div></div></aside><figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/vocab_stringstore.svg" alt="Doc, Vocab, Lexeme and StringStore" width="650" height="auto"/></figure><p>If you process lots of documents containing the word “coffee” in all kinds of
different contexts, storing the exact string “coffee” every time would take up
way too much space. So instead, spaCy hashes the string and stores it in the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/stringstore"><code class="code_inline-code__Bq7ot">StringStore</code></a>. You can think of the <code class="code_inline-code__Bq7ot">StringStore</code> as a
<strong>lookup table that works in both directions</strong> – you can look up a string to get
its hash, or a hash to get its string:</p><pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre><p>Now that all strings are encoded, the entries in the vocabulary <strong>don’t need to
include the word text</strong> themselves. Instead, they can look it up in the
<code class="code_inline-code__Bq7ot">StringStore</code> via its hash value. Each entry in the vocabulary, also called
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lexeme"><code class="code_inline-code__Bq7ot">Lexeme</code></a>, contains the <strong>context-independent</strong> information about
a word. For example, no matter if “love” is used as a verb or a noun in some
context, its spelling and whether it consists of alphabetic characters won’t
ever change. Its hash value will also always be the same.</p><pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Text</strong>: The original text of the lexeme.</li>
<li class="list_li__sfx_z"><strong>Orth</strong>: The hash value of the lexeme.</li>
<li class="list_li__sfx_z"><strong>Shape</strong>: The abstract word shape of the lexeme.</li>
<li class="list_li__sfx_z"><strong>Prefix</strong>: By default, the first letter of the word string.</li>
<li class="list_li__sfx_z"><strong>Suffix</strong>: By default, the last three letters of the word string.</li>
<li class="list_li__sfx_z"><strong>is alpha</strong>: Does the lexeme consist of alphabetic characters?</li>
<li class="list_li__sfx_z"><strong>is digit</strong>: Does the lexeme consist of digits?</li>
</ul>
</div></div></aside><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Text</th><th class="table_th__QJ9F8">Orth</th><th class="table_th__QJ9F8">Shape</th><th class="table_th__QJ9F8">Prefix</th><th class="table_th__QJ9F8">Suffix</th><th class="table_th__QJ9F8">is_alpha</th><th class="table_th__QJ9F8">is_digit</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">I</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">4690420944186131903</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">X</code></td><td class="table_td__rmpJx">I</td><td class="table_td__rmpJx">I</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">love</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">3702023516439754181</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx">l</td><td class="table_td__rmpJx">ove</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx">coffee</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">3197928453018144401</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">xxxx</code></td><td class="table_td__rmpJx">c</td><td class="table_td__rmpJx">fee</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">True</code></td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">False</code></td></tr></tbody></table><p>The mapping of words to hashes doesn’t depend on any state. To make sure each
value is unique, spaCy uses a
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> to calculate the
hash <strong>based on the word string</strong>. This also means that the hash for “coffee”
will always be the same, no matter which pipeline you’re using or how you’ve
configured spaCy.</p><p>However, hashes <strong>cannot be reversed</strong> and there’s no way to resolve
<code class="code_inline-code__Bq7ot">3197928453018144401</code> back to “coffee”. All spaCy can do is look it up in the
vocabulary. That’s why you always need to make sure all objects you create have
access to the same vocabulary. If they don’t, spaCy might not be able to find
the strings it needs.</p><pre class="code_pre__kzg60"><div class="code_juniper-wrapper__Vfpma"><h4 class="code_juniper-title__ePkNN">Editable Code<span class="code_juniper-meta__aRELD">spaCy v<!-- -->3.5<!-- --> · Python 3 · via<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://mybinder.org/">Binder</a></span></h4><div class="code_juniper-cell__XJBck"><div class="cm-theme code_juniper-input__HKv_l"></div><button class="code_juniper-button__k_2FS">run</button></div></div></pre><p>If the vocabulary doesn’t contain a string for <code class="code_inline-code__Bq7ot">3197928453018144401</code>, spaCy will
raise an error. You can re-add “coffee” manually, but this only works if you
actually <em>know</em> that the document contains that word. To prevent this problem,
spaCy will also export the <code class="code_inline-code__Bq7ot">Vocab</code> when you save a <code class="code_inline-code__Bq7ot">Doc</code> or <code class="code_inline-code__Bq7ot">nlp</code> object. This
will give you the object and its encoded annotations, plus the “key” to decode
it.</p></section>
<section id="section-serialization" class="section_root__k1hUl"><h2 id="serialization" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#serialization" class="heading-text typography_permalink__UiIRy">Serialization <!-- --> </a></h2><p>If you’ve been modifying the pipeline, vocabulary, vectors and entities, or made
updates to the component models, you’ll eventually want to <strong>save your
progress</strong> – for example, everything that’s in your <code class="code_inline-code__Bq7ot">nlp</code> object. This means
you’ll have to translate its contents and structure into a format that can be
saved, like a file or a byte string. This process is called serialization. spaCy
comes with <strong>built-in serialization methods</strong> and supports the
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://www.diveinto.org/python3/serializing.html#dump">Pickle protocol</a>.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">What’s pickle?<!-- --> </span></h4>
<p>Pickle is Python’s built-in object persistence system. It lets you transfer
arbitrary Python objects between processes. This is usually used to load an
object to and from disk, but it’s also used for distributed computing, e.g.
with
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://spark.apache.org/docs/0.9.0/python-programming-guide.html">PySpark</a>
or <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://dask.org">Dask</a>. When you unpickle an object, you’re agreeing to
execute whatever code it contains. It’s like calling <code class="code_inline-code__Bq7ot">eval()</code> on a string – so
don’t unpickle objects from untrusted sources.</p>
</div></div></aside>
<p>All container classes, i.e. <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language"><code class="code_inline-code__Bq7ot">Language</code></a> (<code class="code_inline-code__Bq7ot">nlp</code>),
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a>, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a> and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/stringstore"><code class="code_inline-code__Bq7ot">StringStore</code></a>
have the following methods available:</p>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Method</th><th class="table_th__QJ9F8">Returns</th><th class="table_th__QJ9F8">Example</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">to_bytes</code></td><td class="table_td__rmpJx">bytes</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">data = nlp.to_bytes()</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">from_bytes</code></td><td class="table_td__rmpJx">object</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.from_bytes(data)</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">to_disk</code></td><td class="table_td__rmpJx">-</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.to_disk(&quot;/path&quot;)</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">from_disk</code></td><td class="table_td__rmpJx">object</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.from_disk(&quot;/path&quot;)</code></td></tr></tbody></table><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Saving and loading</span></h4><p>To learn more about how to <strong>save and load your own pipelines</strong>, see the usage
guide on <a class="link_root__1Me7D" href="/usage/saving-loading#models">saving and loading</a>.</p></aside></section>
<section id="section-training" class="section_root__k1hUl"><h2 id="training" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#training" class="heading-text typography_permalink__UiIRy">Training <!-- --> </a></h2><p>spaCy’s tagger, parser, text categorizer and many other components are powered
by <strong>statistical models</strong>. Every “decision” these components make – for example,
which part-of-speech tag to assign, or whether a word is a named entity – is a
<strong>prediction</strong> based on the model’s current <strong>weight values</strong>. The weight values
are estimated based on examples the model has seen during <strong>training</strong>. To train
a model, you first need training data – examples of text, and the labels you
want the model to predict. This could be a part-of-speech tag, a named entity or
any other information.</p>
<p>Training is an iterative process in which the model’s predictions are compared
against the reference annotations in order to estimate the <strong>gradient of the
loss</strong>. The gradient of the loss is then used to calculate the gradient of the
weights through <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://thinc.ai/docs/backprop101">backpropagation</a>. The
gradients indicate how the weight values should be changed so that the model’s
predictions become more similar to the reference labels over time.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>Training data:</strong> Examples and their annotations.</li>
<li class="list_li__sfx_z"><strong>Text:</strong> The input text the model should predict a label for.</li>
<li class="list_li__sfx_z"><strong>Label:</strong> The label the model should predict.</li>
<li class="list_li__sfx_z"><strong>Gradient:</strong> The direction and rate of change for a numeric value.
Minimising the gradient of the weights should result in predictions that are
closer to the reference labels on the training data.</li>
</ul>
</div></div></aside>
<figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/training.svg" alt="The training process" width="650" height="auto"/></figure>
<p>When training a model, we don’t just want it to memorize our examples – we want
it to come up with a theory that can be <strong>generalized across unseen data</strong>.
After all, we don’t just want the model to learn that this one instance of
“Amazon” right here is a company – we want it to learn that “Amazon”, in
contexts <em>like this</em>, is most likely a company. That’s why the training data
should always be representative of the data we want to process. A model trained
on Wikipedia, where sentences in the first person are extremely rare, will
likely perform badly on Twitter. Similarly, a model trained on romantic novels
will likely perform badly on legal text.</p>
<p>This also means that in order to know how the model is performing, and whether
it’s learning the right things, you don’t only need <strong>training data</strong> – you’ll
also need <strong>evaluation data</strong>. If you only test the model with the data it was
trained on, you’ll have no idea how well it’s generalizing. If you want to train
a model from scratch, you usually need at least a few hundred examples for both
training and evaluation.</p><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Training pipelines and models</span></h4><p>To learn more about <strong>training and updating</strong> pipelines, how to create training
data and how to improve spaCy’s named models, see the usage guides on
<a class="link_root__1Me7D" href="/usage/training">training</a>.</p></aside><h3 id="training-config" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#training-config" class="heading-text typography_permalink__UiIRy">Training config and lifecycle <!-- --> </a></h3><p>Training config files include all <strong>settings and hyperparameters</strong> for training
your pipeline. Instead of providing lots of arguments on the command line, you
only need to pass your <code class="code_inline-code__Bq7ot">config.cfg</code> file to <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#train"><code class="code_inline-code__Bq7ot">spacy train</code></a>.
This also makes it easy to integrate custom models and architectures, written in
your framework of choice. A pipeline’s <code class="code_inline-code__Bq7ot">config.cfg</code> is considered the “single
source of truth”, both at <strong>training</strong> and <strong>runtime</strong>.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">config.cfg (excerpt)</h4><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/lifecycle.svg" alt="Illustration of pipeline lifecycle" width="650" height="auto"/></figure><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Training configuration system</span></h4><p>For more details on spaCy’s <strong>configuration system</strong> and how to use it to
customize your pipeline components, component models, training settings and
hyperparameters, see the <a class="link_root__1Me7D" href="/usage/training#config">training config</a> usage guide.</p></aside><h3 id="training-components" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#training-components" class="heading-text typography_permalink__UiIRy">Trainable components <!-- --> </a></h3><p>spaCy’s <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/pipe"><code class="code_inline-code__Bq7ot">Pipe</code></a> class helps you implement your own trainable
components that have their own model instance, make predictions over <code class="code_inline-code__Bq7ot">Doc</code>
objects and can be updated using <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#train"><code class="code_inline-code__Bq7ot">spacy train</code></a>. This lets you
plug fully custom machine learning components into your pipeline that can be
configured via a single training config.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">config.cfg (excerpt)<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-ini language-ini"></code></pre>
</div></div></aside><figure class="gatsby-resp-image-figure"><img class="embed_image__mSQUH" src="/images/trainable_component.svg" alt="Illustration of Pipe methods" width="650" height="auto"/></figure><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">📖</span>Custom trainable components</span></h4><p>To learn more about how to implement your own <strong>model architectures</strong> and use
them to power custom <strong>trainable components</strong>, see the usage guides on the
<a class="link_root__1Me7D" href="/usage/processing-pipelines#trainable-components">trainable component API</a> and
implementing <a class="link_root__1Me7D" href="/usage/layers-architectures#components">layers and architectures</a>
for trainable components.</p></aside></section>
<section id="section-language-data" class="section_root__k1hUl"><h2 id="language-data" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#language-data" class="heading-text typography_permalink__UiIRy">Language data <!-- --> </a></h2><p>Every language is different – and usually full of <strong>exceptions and special
cases</strong>, especially amongst the most common words. Some of these exceptions are
shared across languages, while others are <strong>entirely specific</strong> – usually so
specific that they need to be hard-coded. The
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang"><code class="code_inline-code__Bq7ot">lang</code></a> module contains all language-specific data,
organized in simple Python files. This makes the data easy to update and extend.</p>
<p>The <strong>shared language data</strong> in the directory root includes rules that can be
generalized across languages – for example, rules for basic punctuation, emoji,
emoticons and single-letter abbreviations. The <strong>individual language data</strong> in a
submodule contains rules that are only relevant to a particular language. It
also takes care of putting together all components and creating the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language"><code class="code_inline-code__Bq7ot">Language</code></a> subclass – for example, <code class="code_inline-code__Bq7ot">English</code> or <code class="code_inline-code__Bq7ot">German</code>. The
values are defined in the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#defaults"><code class="code_inline-code__Bq7ot">Language.Defaults</code></a>.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre>
</div></div></aside>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Name</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Stop words</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/en/stop_words.py"><code class="code_inline-code__Bq7ot">stop_words.py</code></a></td><td class="table_td__rmpJx">List of most common words of a language that are often useful to filter out, for example “and” or “I”. Matching tokens will return <code class="code_inline-code__Bq7ot">True</code> for <code class="code_inline-code__Bq7ot">is_stop</code>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Tokenizer exceptions</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/de/tokenizer_exceptions.py"><code class="code_inline-code__Bq7ot">tokenizer_exceptions.py</code></a></td><td class="table_td__rmpJx">Special-case rules for the tokenizer, for example, contractions like “can’t” and abbreviations with punctuation, like “U.K.”.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Punctuation rules</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/punctuation.py"><code class="code_inline-code__Bq7ot">punctuation.py</code></a></td><td class="table_td__rmpJx">Regular expressions for splitting tokens, e.g. on punctuation or special characters like emoji. Includes rules for prefixes, suffixes and infixes.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Character classes</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/char_classes.py"><code class="code_inline-code__Bq7ot">char_classes.py</code></a></td><td class="table_td__rmpJx">Character classes to be used in regular expressions, for example, Latin characters, quotes, hyphens or icons.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Lexical attributes</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/en/lex_attrs.py"><code class="code_inline-code__Bq7ot">lex_attrs.py</code></a></td><td class="table_td__rmpJx">Custom functions for setting lexical attributes on tokens, e.g. <code class="code_inline-code__Bq7ot">like_num</code>, which includes language-specific words like “ten” or “hundred”.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Syntax iterators</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/en/syntax_iterators.py"><code class="code_inline-code__Bq7ot">syntax_iterators.py</code></a></td><td class="table_td__rmpJx">Functions that compute views of a <code class="code_inline-code__Bq7ot">Doc</code> object based on its syntax. At the moment, only used for <a class="link_root__1Me7D" href="/usage/linguistic-features#noun-chunks">noun chunks</a>.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><strong>Lemmatizer</strong><br/><a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/lang/fr/lemmatizer.py"><code class="code_inline-code__Bq7ot">lemmatizer.py</code></a> <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a></td><td class="table_td__rmpJx">Custom lemmatizer implementation and lemmatization tables.</td></tr></tbody></table></section>
<section id="section-community-faq" class="section_root__k1hUl"><h2 id="community-faq" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#community-faq" class="heading-text typography_permalink__UiIRy">Community &amp; FAQ <!-- --> </a></h2><p>We’re very happy to see the spaCy community grow and include a mix of people
from all kinds of different backgrounds – computational linguistics, data
science, deep learning, research and more. If you’d like to get involved, below
are some answers to the most important questions and resources for further
reading.</p><h3 id="faq-help-code" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#faq-help-code" class="heading-text typography_permalink__UiIRy">Help, my code isn’t working! <!-- --> </a></h3><p>Bugs suck, and we’re doing our best to continuously improve the tests and fix
bugs as soon as possible. Before you submit an issue, do a quick search and
check if the problem has already been reported. If you’re having installation or
loading problems, make sure to also check out the
<a class="link_root__1Me7D" href="/usage#troubleshooting">troubleshooting guide</a>. Help with spaCy is available
via the following platforms:</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">How do I know if something is a bug?<!-- --> </span></h4>
<p>Of course, it’s always hard to know for sure, so don’t worry – we’re not going
to be mad if a bug report turns out to be a typo in your code. As a simple
rule, any C-level error without a Python traceback, like a <strong>segmentation
fault</strong> or <strong>memory error</strong>, is <strong>always</strong> a spaCy bug.</p>
<p>Because models are statistical, their performance will never be <em>perfect</em>.
However, if you come across <strong>patterns that might indicate an underlying
issue</strong>, please do file a report. Similarly, we also care about behaviors that
<strong>contradict our docs</strong>.</p>
</div></div></aside><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://stackoverflow.com/questions/tagged/spacy">Stack Overflow</a>: <strong>Usage
questions</strong> and everything related to problems with your specific code. The
Stack Overflow community is much larger than ours, so if your problem can be
solved by others, you’ll receive help much quicker.</li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/discussions"><span class="link_source-text__VDP74">GitHub discussions</span></a>:
<strong>General discussion</strong>, <strong>project ideas</strong> and <strong>usage questions</strong>. Meet other
community members to get help with a specific code implementation, discuss
ideas for new projects/plugins, support more languages, and share best
practices.</li>
<li class="list_li__sfx_z"><a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues"><span class="link_source-text__VDP74">GitHub issue tracker</span></a>: <strong>Bug
reports</strong> and <strong>improvement suggestions</strong>, i.e. everything that’s likely
spaCy’s fault. This also includes problems with the trained pipelines beyond
statistical imprecisions, like patterns that point to a bug.</li>
</ul><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note</span></h4><p>Please understand that we won’t be able to provide individual support via email.
We also believe that help is much more valuable if it’s shared publicly, so that
<strong>more people can benefit from it</strong>. If you come across an issue and you think
you might be able to help, consider posting a quick update with your solution.
No matter how simple, it can easily save someone a lot of time and headache –
and the next time you need help, they might repay the favor.</p></aside><h3 id="faq-contributing" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#faq-contributing" class="heading-text typography_permalink__UiIRy">How can I contribute to spaCy? <!-- --> </a></h3><p>You don’t have to be an NLP expert or Python pro to contribute, and we’re happy
to help you get started. If you’re new to spaCy, a good place to start is the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted+%28easy%29%22"><code class="code_inline-code__Bq7ot">help wanted (easy)</code> label</a>
on GitHub, which we use to tag bugs and feature requests that are easy and
self-contained. We also appreciate contributions to the docs – whether it’s
fixing a typo, improving an example or adding additional explanations. You’ll
find a “Suggest edits” link at the bottom of each page that points you to the
source.</p><p>Another way of getting involved is to help us improve the
<a class="link_root__1Me7D" href="/usage/linguistic-features#language-data">language data</a> – especially if you
happen to speak one of the languages currently in
<a class="link_root__1Me7D" href="/usage/models#languages">alpha support</a>. Even adding simple tokenizer
exceptions, stop words or lemmatizer data can make a big difference. It will
also make it easier for us to provide a trained pipeline for the language in the
future. Submitting a test that documents a bug or performance issue, or covers
functionality that’s especially important for your application is also very
helpful. This way, you’ll also make sure we never accidentally introduce
regressions to the parts of the library that you care about the most.</p><p><strong>For more details on the types of contributions we’re looking for, the code
conventions and other useful tips, make sure to check out the
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/CONTRIBUTING.md"><span class="link_source-text__VDP74">contributing guidelines</span></a>.</strong></p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Code of Conduct</span></h4><p>spaCy adheres to the
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="http://contributor-covenant.org/version/1/4/">Contributor Covenant Code of Conduct</a>.
By participating, you are expected to uphold this code.</p></aside><h3 id="faq-project-with-spacy" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#faq-project-with-spacy" class="heading-text typography_permalink__UiIRy">I’ve built something cool with spaCy – how can I get the word out? <!-- --> </a></h3><p>First, congrats – we’d love to check it out! When you share your project on
Twitter, don’t forget to tag <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/spacy_io">@spacy_io</a> so we
don’t miss it. If you think your project would be a good fit for the
<a class="link_root__1Me7D" href="/universe">spaCy Universe</a>, <strong>feel free to submit it!</strong> Tutorials are also
incredibly valuable to other users and a great way to get exposure. So we
strongly encourage <strong>writing up your experiences</strong>, or sharing your code and
some tips and tricks on your blog. Since our website is open-source, you can add
your project or tutorial by making a pull request on GitHub.</p><p>If you would like to use the spaCy logo on your site, please get in touch and
ask us first. However, if you want to show support and tell others that your
project is using spaCy, you can grab one of our <strong>spaCy badges</strong> here:</p><img src="https://img.shields.io/badge/built%20with-spaCy-09a3d5.svg" alt="Built with spaCy"/><pre class="code_pre__kzg60"><code class="code_code__CILJL language-markdown language-markdown"></code></pre><img src="https://img.shields.io/badge/made%20with%20❤%20and-spaCy-09a3d5.svg" alt="Made with love and spaCy"/><pre class="code_pre__kzg60"><code class="code_code__CILJL language-markdown language-markdown"></code></pre></section><div class="grid_root__EfDZl grid_spacing__fhBCv grid_half__xoJZs"><div style="margin-top:var(--spacing-lg)"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/website/docs/usage/spacy-101.mdx">Suggest edits</a></div><a class="link_root__1Me7D readnext_root__JNzwZ link_no-link-layout__RPvod" href="/usage/v3"><span><span class="typography_label__l_oVJ">Read next</span>New in v3.0</span><span class="readnext_icon__jfRnJ"></span></a></div></article><div class="main_asides__RITE5" style="background-image:url(/_next/static/media/pattern_blue.d167bed5.png"></div><footer class="footer_root__zlkjP"><div class="grid_root__EfDZl footer_content__LaE1F grid_narrow__x_6xS grid_spacing__fhBCv grid_third__edHuB"><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">spaCy</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage">Usage</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API Reference</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://course.spacy.io">Online Course</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Community</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/discussions">GitHub Discussions</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues">Issue Tracker</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="http://stackoverflow.com/questions/tagged/spacy">Stack Overflow</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Connect</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/spacy_io">Twitter</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy">GitHub</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://youtube.com/c/ExplosionAI">YouTube</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/blog">Blog</a></li></ul></section><section class="footer_full___icln"><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Stay in the loop!</li><li>Receive updates about new releases, tutorials and more.</li><li><form id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" action="//spacy.us12.list-manage.com/subscribe/post?u=83b0498b1e7fa3c91ce68c3f1&amp;amp;id=ecc82e0493" method="post" target="_blank" novalidate=""><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_83b0498b1e7fa3c91ce68c3f1_ecc82e0493" tabindex="-1" value=""/></div><div class="newsletter_root__uh6MU"><input class="newsletter_input___SMSB" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email" aria-label="Your email"/><button class="newsletter_button__gKW8E" id="mc-embedded-subscribe" type="submit" name="subscribe">Sign up</button></div></form></li></ul></section></div><div class="footer_content__LaE1F footer_copy__rbjvc"><span>© 2016-<!-- -->2023<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai">Explosion</a></span><a class="link_root__1Me7D footer_logo__BthsJ link_no-link-layout__RPvod" aria-label="Explosion" href="https://explosion.ai"></a><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/legal">Legal / Imprint</a></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"spaCy 101: Everything you need to know","teaser":"The most important concepts, explained in simple terms","menu":[["What's spaCy?","whats-spacy"],["Features","features"],["Linguistic Annotations","annotations"],["Pipelines","pipelines"],["Architecture","architecture"],["Vocab","vocab"],["Serialization","serialization"],["Training","training"],["Language Data","language-data"],["Community \u0026 FAQ","community-faq"]],"slug":"/usage/spacy-101","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    p: \"p\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    a: \"a\",\n    h2: \"h2\",\n    strong: \"strong\",\n    ul: \"ul\",\n    li: \"li\",\n    h3: \"h3\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    pre: \"pre\",\n    code: \"code\",\n    em: \"em\",\n    img: \"img\"\n  }, _provideComponents(), props.components), {Infobox, Image, Button, Grid, InlineCode, Tokenization101, PosDeps101, NER101, Vectors101, Pipelines101, Architecture101, Serialization101, Training101, LanguageData101} = _components;\n  if (!Architecture101) _missingMdxReference(\"Architecture101\", true);\n  if (!Button) _missingMdxReference(\"Button\", true);\n  if (!Grid) _missingMdxReference(\"Grid\", true);\n  if (!Image) _missingMdxReference(\"Image\", true);\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  if (!LanguageData101) _missingMdxReference(\"LanguageData101\", true);\n  if (!NER101) _missingMdxReference(\"NER101\", true);\n  if (!Pipelines101) _missingMdxReference(\"Pipelines101\", true);\n  if (!PosDeps101) _missingMdxReference(\"PosDeps101\", true);\n  if (!Serialization101) _missingMdxReference(\"Serialization101\", true);\n  if (!Tokenization101) _missingMdxReference(\"Tokenization101\", true);\n  if (!Training101) _missingMdxReference(\"Training101\", true);\n  if (!Vectors101) _missingMdxReference(\"Vectors101\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      children: [_jsx(_components.p, {\n        children: \"Whether you’re new to spaCy, or just want to brush up on some NLP basics and\\nimplementation details – this page should have you covered. Each section will\\nexplain one of spaCy’s features in simple terms and with examples or\\nillustrations. Some sections will also reappear across the usage guides as a\\nquick introduction.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Help us improve the docs\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Did you spot a mistake or come across explanations that are unclear? We always\\nappreciate improvement\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/issues\",\n            children: \"suggestions\"\n          }), \" or\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/pulls\",\n            children: \"pull requests\"\n          }), \". You can find a\\n“Suggest edits” link at the bottom of each page that points you to the source.\"]\n        }), \"\\n\"]\n      }), _jsxs(Infobox, {\n        title: \"Take the free interactive course\",\n        children: [_jsx(Image, {\n          src: \"/images/course.jpg\",\n          href: \"https://course.spacy.io\",\n          alt: \"Advanced NLP with spaCy\"\n        }), _jsx(_components.p, {\n          children: \"In this course you’ll learn how to use spaCy to build advanced natural language\\nunderstanding systems, using both rule-based and machine learning approaches. It\\nincludes 55 exercises featuring interactive coding practice, multiple-choice\\nquestions and slide decks.\"\n        }), _jsx(Button, {\n          to: \"https://course.spacy.io\",\n          variant: \"primary\",\n          children: 'Start the course'\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-whats-spacy\",\n      children: [_jsx(_components.h2, {\n        id: \"whats-spacy\",\n        children: \"What’s spaCy? \"\n      }), _jsxs(Grid, {\n        cols: 2,\n        children: [_jsxs(\"div\", {\n          children: [_jsxs(_components.p, {\n            children: [\"spaCy is a \", _jsx(_components.strong, {\n              children: \"free, open-source library\"\n            }), \" for advanced \", _jsx(_components.strong, {\n              children: \"Natural Language\\nProcessing\"\n            }), \" (NLP) in Python.\"]\n          }), _jsx(_components.p, {\n            children: \"If you’re working with a lot of text, you’ll eventually want to know more about\\nit. For example, what’s it about? What do the words mean in context? Who is\\ndoing what to whom? What companies and products are mentioned? Which texts are\\nsimilar to each other?\"\n          }), _jsxs(_components.p, {\n            children: [\"spaCy is designed specifically for \", _jsx(_components.strong, {\n              children: \"production use\"\n            }), \" and helps you build\\napplications that process and “understand” large volumes of text. It can be used\\nto build \", _jsx(_components.strong, {\n              children: \"information extraction\"\n            }), \" or \", _jsx(_components.strong, {\n              children: \"natural language understanding\"\n            }), \"\\nsystems, or to pre-process text for \", _jsx(_components.strong, {\n              children: \"deep learning\"\n            }), \".\"]\n          })]\n        }), _jsx(Infobox, {\n          title: \"Table of contents\",\n          id: \"toc\",\n          children: _jsxs(_components.ul, {\n            children: [\"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#features\",\n                children: \"Features\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations\",\n                children: \"Linguistic annotations\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-token\",\n                children: \"Tokenization\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-pos-deps\",\n                children: \"POS tags and dependencies\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#annotations-ner\",\n                children: \"Named entities\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#vectors-similarity\",\n                children: \"Word vectors and similarity\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#pipelines\",\n                children: \"Pipelines\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#architecture\",\n                children: \"Library architecture\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#vocab\",\n                children: \"Vocab, hashes and lexemes\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#serialization\",\n                children: \"Serialization\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#training\",\n                children: \"Training\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#language-data\",\n                children: \"Language data\"\n              })\n            }), \"\\n\", _jsx(_components.li, {\n              children: _jsx(_components.a, {\n                href: \"#community\",\n                children: \"Community \u0026 FAQ\"\n              })\n            }), \"\\n\"]\n          })\n        })]\n      }), _jsx(_components.h3, {\n        id: \"what-spacy-isnt\",\n        children: \"What spaCy isn’t \"\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not a platform or “an API”\"\n          }), \". Unlike a platform, spaCy does not\\nprovide a software as a service, or a web application. It’s an open-source\\nlibrary designed to help you build NLP applications, not a consumable service.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not an out-of-the-box chat bot engine\"\n          }), \". While spaCy can be used\\nto power conversational applications, it’s not designed specifically for chat\\nbots, and only provides the underlying text processing capabilities.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌\", _jsx(_components.strong, {\n            children: \"spaCy is not research software\"\n          }), \". It’s built on the latest research, but\\nit’s designed to get things done. This leads to fairly different design\\ndecisions than \", _jsx(_components.a, {\n            href: \"https://github.com/nltk/nltk\",\n            children: \"NLTK\"\n          }), \" or\\n\", _jsx(_components.a, {\n            href: \"https://stanfordnlp.github.io/CoreNLP/\",\n            children: \"CoreNLP\"\n          }), \", which were created as\\nplatforms for teaching and research. The main difference is that spaCy is\\nintegrated and opinionated. spaCy tries to avoid asking the user to choose\\nbetween multiple algorithms that deliver equivalent functionality. Keeping the\\nmenu small lets spaCy deliver generally better performance and developer\\nexperience.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [\"❌ \", _jsx(_components.strong, {\n            children: \"spaCy is not a company\"\n          }), \". It’s an open-source library. Our company\\npublishing spaCy and other software is called\\n\", _jsx(_components.a, {\n            href: \"https://explosion.ai\",\n            children: \"Explosion\"\n          }), \".\"]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-features\",\n      children: [_jsx(_components.h2, {\n        id: \"features\",\n        children: \"Features \"\n      }), _jsx(_components.p, {\n        children: \"In the documentation, you’ll come across mentions of spaCy’s features and\\ncapabilities. Some of them refer to linguistic concepts, while others are\\nrelated to more general machine learning functionality.\"\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Name\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Tokenization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Segmenting text into words, punctuations marks etc.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Part-of-speech\"\n              }), \" (POS) \", _jsx(_components.strong, {\n                children: \"Tagging\"\n              })]\n            }), _jsx(_components.td, {\n              children: \"Assigning word types to tokens, like verb or noun.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Dependency Parsing\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Lemmatization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Sentence Boundary Detection\"\n              }), \" (SBD)\"]\n            }), _jsx(_components.td, {\n              children: \"Finding and segmenting individual sentences.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Named Entity Recognition\"\n              }), \" (NER)\"]\n            }), _jsx(_components.td, {\n              children: \"Labelling named “real-world” objects, like persons, companies or locations.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsxs(_components.td, {\n              children: [_jsx(_components.strong, {\n                children: \"Entity Linking\"\n              }), \" (EL)\"]\n            }), _jsx(_components.td, {\n              children: \"Disambiguating textual entities to unique identifiers in a knowledge base.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Similarity\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Comparing words, text spans and documents and how similar they are to each other.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Text Classification\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Assigning categories or labels to a whole document, or parts of a document.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Rule-based Matching\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Training\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Updating and improving a statistical model’s predictions.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.strong, {\n                children: \"Serialization\"\n              })\n            }), _jsx(_components.td, {\n              children: \"Saving objects to files or byte strings.\"\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        id: \"statistical-models\",\n        children: \"Statistical models \"\n      }), _jsxs(_components.p, {\n        children: [\"While some of spaCy’s features work independently, others require\\n\", _jsx(_components.a, {\n          href: \"/models\",\n          children: \"trained pipelines\"\n        }), \" to be loaded, which enable spaCy to \", _jsx(_components.strong, {\n          children: \"predict\"\n        }), \"\\nlinguistic annotations – for example, whether a word is a verb or a noun. A\\ntrained pipeline can consist of multiple components that use a statistical model\\ntrained on labeled data. spaCy currently offers trained pipelines for a variety\\nof languages, which can be installed as individual Python modules. Pipeline\\npackages can differ in size, speed, memory usage, accuracy and the data they\\ninclude. The package you choose always depends on your use case and the texts\\nyou’re working with. For a general-purpose use case, the small, default packages\\nare always a good start. They typically include the following components:\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Binary weights\"\n          }), \" for the part-of-speech tagger, dependency parser and named\\nentity recognizer to predict those annotations in context.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Lexical entries\"\n          }), \" in the vocabulary, i.e. words and their\\ncontext-independent attributes like the shape or spelling.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Data files\"\n          }), \" like lemmatization rules and lookup tables.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Word vectors\"\n          }), \", i.e. multi-dimensional meaning representations of words that\\nlet you determine how similar they are to each other.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.strong, {\n            children: \"Configuration\"\n          }), \" options, like the language and processing pipeline settings\\nand model implementations to use, to put spaCy in the correct state when you\\nload the pipeline.\"]\n        }), \"\\n\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-annotations\",\n      children: [_jsx(_components.h2, {\n        id: \"annotations\",\n        children: \"Linguistic annotations \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy provides a variety of linguistic annotations to give you \", _jsx(_components.strong, {\n          children: \"insights into a\\ntext’s grammatical structure\"\n        }), \". This includes the word types, like the parts of\\nspeech, and how the words are related to each other. For example, if you’re\\nanalyzing text, it makes a huge difference whether a noun is the subject of a\\nsentence, or the object – or whether “google” is used as a verb, or refers to\\nthe website or company in a specific context.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Loading pipelines\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-bash\",\n            lang: \"bash\",\n            children: \"$ python -m spacy download en_core_web_sm\\n\\n\u003e\u003e\u003e import spacy\\n\u003e\u003e\u003e nlp = spacy.load(\\\"en_core_web_sm\\\")\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"Once you’ve \", _jsx(_components.a, {\n          href: \"/usage/models\",\n          children: \"downloaded and installed\"\n        }), \" a trained pipeline, you\\ncan load it via \", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.load\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.load\"\n          })\n        }), \". This will return a\\n\", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" object containing all components and data needed to process text. We\\nusually call it \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \". Calling the \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object on a string of text will return\\na processed \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \":\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"Apple is looking at buying U.K. startup for $1 billion\\\")\\nfor token in doc:\\n    print(token.text, token.pos_, token.dep_)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Even though a \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" is processed – e.g. split into individual words and\\nannotated – it still holds \", _jsx(_components.strong, {\n          children: \"all information of the original text\"\n        }), \", like\\nwhitespace characters. You can always get the offset of a token into the\\noriginal string, or reconstruct the original by joining the tokens and their\\ntrailing whitespace. This way, you’ll never lose any information when processing\\ntext with spaCy.\"]\n      }), _jsx(_components.h3, {\n        id: \"annotations-token\",\n        children: \"Tokenization \"\n      }), _jsx(Tokenization101, {}), _jsx(Infobox, {\n        title: \"Tokenization rules\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how spaCy’s tokenization rules work in detail, how to\\n\", _jsx(_components.strong, {\n            children: \"customize and replace\"\n          }), \" the default tokenizer and how to \", _jsx(_components.strong, {\n            children: \"add\\nlanguage-specific data\"\n          }), \", see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#language-data\",\n            children: \"language data\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#tokenization\",\n            children: \"customizing the tokenizer\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"annotations-pos-deps\",\n        model: \"parser\",\n        children: \"Part-of-speech tags and dependencies \"\n      }), _jsx(PosDeps101, {}), _jsx(Infobox, {\n        title: \"Part-of-speech tagging and morphology\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"part-of-speech tagging\"\n          }), \" and rule-based morphology, and\\nhow to \", _jsx(_components.strong, {\n            children: \"navigate and use the parse tree\"\n          }), \" effectively, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#pos-tagging\",\n            children: \"part-of-speech tagging\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#dependency-parse\",\n            children: \"using the dependency parse\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"annotations-ner\",\n        model: \"ner\",\n        children: \"Named Entities \"\n      }), _jsx(NER101, {}), _jsx(Infobox, {\n        title: \"Named Entity Recognition\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about entity recognition in spaCy, how to \", _jsx(_components.strong, {\n            children: \"add your own\\nentities\"\n          }), \" to a document and how to \", _jsx(_components.strong, {\n            children: \"train and update\"\n          }), \" the entity predictions\\nof a model, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#named-entities\",\n            children: \"named entity recognition\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/usage/training\",\n            children: \"training pipelines\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"vectors-similarity\",\n        model: \"vectors\",\n        children: \"Word vectors and similarity \"\n      }), _jsx(Vectors101, {}), _jsx(Infobox, {\n        title: \"Word vectors\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about word vectors, how to \", _jsx(_components.strong, {\n            children: \"customize them\"\n          }), \" and how to load\\n\", _jsx(_components.strong, {\n            children: \"your own vectors\"\n          }), \" into spaCy, see the usage guide on\\n\", _jsx(_components.a, {\n            href: \"/usage/linguistic-features#vectors-similarity\",\n            children: \"using word vectors and semantic similarities\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-pipelines\",\n      children: [_jsx(_components.h2, {\n        id: \"pipelines\",\n        children: \"Pipelines \"\n      }), _jsx(Pipelines101, {}), _jsx(Infobox, {\n        title: \"Processing pipelines\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"how processing pipelines work\"\n          }), \" in detail, how to enable\\nand disable their components, and how to \", _jsx(_components.strong, {\n            children: \"create your own\"\n          }), \", see the usage\\nguide on \", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines\",\n            children: \"language processing pipelines\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-architecture\",\n      children: [_jsx(_components.h2, {\n        id: \"architecture\",\n        children: \"Architecture \"\n      }), _jsx(Architecture101, {})]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-vocab\",\n      children: [_jsx(_components.h2, {\n        id: \"vocab\",\n        children: \"Vocab, hashes and lexemes \"\n      }), _jsxs(_components.p, {\n        children: [\"Whenever possible, spaCy tries to store data in a vocabulary, the\\n\", _jsx(_components.a, {\n          href: \"/api/vocab\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab\"\n          })\n        }), \", that will be \", _jsx(_components.strong, {\n          children: \"shared by multiple documents\"\n        }), \". To save\\nmemory, spaCy also encodes all strings to \", _jsx(_components.strong, {\n          children: \"hash values\"\n        }), \" – in this case for\\nexample, “coffee” has the hash \", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \". Entity labels like “ORG”\\nand part-of-speech tags like “VERB” are also encoded. Internally, spaCy only\\n“speaks” in hash values.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Token\"\n            }), \": A word, punctuation mark etc. \", _jsx(_components.em, {\n              children: \"in context\"\n            }), \", including its\\nattributes, tags and dependencies.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Lexeme\"\n            }), \": A “word type” with no context. Includes the word shape and\\nflags, e.g. if it’s lowercase, a digit or punctuation.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Doc\"\n            }), \": A processed container of tokens in context.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Vocab\"\n            }), \": The collection of lexemes.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"StringStore\"\n            }), \": The dictionary mapping hash values to strings, for example\\n\", _jsx(InlineCode, {\n              children: \"3197928453018144401\"\n            }), \" → “coffee”.\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/vocab_stringstore.svg\",\n        alt: \"Doc, Vocab, Lexeme and StringStore\"\n      }), _jsxs(_components.p, {\n        children: [\"If you process lots of documents containing the word “coffee” in all kinds of\\ndifferent contexts, storing the exact string “coffee” every time would take up\\nway too much space. So instead, spaCy hashes the string and stores it in the\\n\", _jsx(_components.a, {\n          href: \"/api/stringstore\",\n          children: _jsx(InlineCode, {\n            children: \"StringStore\"\n          })\n        }), \". You can think of the \", _jsx(InlineCode, {\n          children: \"StringStore\"\n        }), \" as a\\n\", _jsx(_components.strong, {\n          children: \"lookup table that works in both directions\"\n        }), \" – you can look up a string to get\\nits hash, or a hash to get its string:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")\\nprint(doc.vocab.strings[\\\"coffee\\\"])  # 3197928453018144401\\nprint(doc.vocab.strings[3197928453018144401])  # 'coffee'\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Now that all strings are encoded, the entries in the vocabulary \", _jsx(_components.strong, {\n          children: \"don’t need to\\ninclude the word text\"\n        }), \" themselves. Instead, they can look it up in the\\n\", _jsx(InlineCode, {\n          children: \"StringStore\"\n        }), \" via its hash value. Each entry in the vocabulary, also called\\n\", _jsx(_components.a, {\n          href: \"/api/lexeme\",\n          children: _jsx(InlineCode, {\n            children: \"Lexeme\"\n          })\n        }), \", contains the \", _jsx(_components.strong, {\n          children: \"context-independent\"\n        }), \" information about\\na word. For example, no matter if “love” is used as a verb or a noun in some\\ncontext, its spelling and whether it consists of alphabetic characters won’t\\never change. Its hash value will also always be the same.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")\\nfor word in doc:\\n    lexeme = doc.vocab[word.text]\\n    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\\n            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)\\n\"\n        })\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Text\"\n            }), \": The original text of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Orth\"\n            }), \": The hash value of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Shape\"\n            }), \": The abstract word shape of the lexeme.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Prefix\"\n            }), \": By default, the first letter of the word string.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"Suffix\"\n            }), \": By default, the last three letters of the word string.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"is alpha\"\n            }), \": Does the lexeme consist of alphabetic characters?\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"is digit\"\n            }), \": Does the lexeme consist of digits?\"]\n          }), \"\\n\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Text\"\n            }), _jsx(_components.th, {\n              children: \"Orth\"\n            }), _jsx(_components.th, {\n              children: \"Shape\"\n            }), _jsx(_components.th, {\n              children: \"Prefix\"\n            }), _jsx(_components.th, {\n              children: \"Suffix\"\n            }), _jsx(_components.th, {\n              children: \"is_alpha\"\n            }), _jsx(_components.th, {\n              children: \"is_digit\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"4690420944186131903\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"X\"\n              })\n            }), _jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: \"I\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"love\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"3702023516439754181\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"xxxx\"\n              })\n            }), _jsx(_components.td, {\n              children: \"l\"\n            }), _jsx(_components.td, {\n              children: \"ove\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: \"coffee\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"3197928453018144401\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"xxxx\"\n              })\n            }), _jsx(_components.td, {\n              children: \"c\"\n            }), _jsx(_components.td, {\n              children: \"fee\"\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"True\"\n              })\n            }), _jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"False\"\n              })\n            })]\n          })]\n        })]\n      }), _jsxs(_components.p, {\n        children: [\"The mapping of words to hashes doesn’t depend on any state. To make sure each\\nvalue is unique, spaCy uses a\\n\", _jsx(_components.a, {\n          href: \"https://en.wikipedia.org/wiki/Hash_function\",\n          children: \"hash function\"\n        }), \" to calculate the\\nhash \", _jsx(_components.strong, {\n          children: \"based on the word string\"\n        }), \". This also means that the hash for “coffee”\\nwill always be the same, no matter which pipeline you’re using or how you’ve\\nconfigured spaCy.\"]\n      }), _jsxs(_components.p, {\n        children: [\"However, hashes \", _jsx(_components.strong, {\n          children: \"cannot be reversed\"\n        }), \" and there’s no way to resolve\\n\", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \" back to “coffee”. All spaCy can do is look it up in the\\nvocabulary. That’s why you always need to make sure all objects you create have\\naccess to the same vocabulary. If they don’t, spaCy might not be able to find\\nthe strings it needs.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          executable: \"true\",\n          children: \"import spacy\\nfrom spacy.tokens import Doc\\nfrom spacy.vocab import Vocab\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\ndoc = nlp(\\\"I love coffee\\\")  # Original Doc\\nprint(doc.vocab.strings[\\\"coffee\\\"])  # 3197928453018144401\\nprint(doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\\nempty_doc = Doc(Vocab())  # New Doc with empty Vocab\\n# empty_doc.vocab.strings[3197928453018144401] will raise an error :(\\n\\nempty_doc.vocab.strings.add(\\\"coffee\\\")  # Add \\\"coffee\\\" and generate hash\\nprint(empty_doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\\nnew_doc = Doc(doc.vocab)  # Create new doc with first doc's vocab\\nprint(new_doc.vocab.strings[3197928453018144401])  # 'coffee' 👍\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If the vocabulary doesn’t contain a string for \", _jsx(InlineCode, {\n          children: \"3197928453018144401\"\n        }), \", spaCy will\\nraise an error. You can re-add “coffee” manually, but this only works if you\\nactually \", _jsx(_components.em, {\n          children: \"know\"\n        }), \" that the document contains that word. To prevent this problem,\\nspaCy will also export the \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \" when you save a \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object. This\\nwill give you the object and its encoded annotations, plus the “key” to decode\\nit.\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-serialization\",\n      children: [_jsx(_components.h2, {\n        id: \"serialization\",\n        children: \"Serialization \"\n      }), _jsx(Serialization101, {}), _jsx(Infobox, {\n        title: \"Saving and loading\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how to \", _jsx(_components.strong, {\n            children: \"save and load your own pipelines\"\n          }), \", see the usage\\nguide on \", _jsx(_components.a, {\n            href: \"/usage/saving-loading#models\",\n            children: \"saving and loading\"\n          }), \".\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-training\",\n      children: [_jsx(_components.h2, {\n        id: \"training\",\n        children: \"Training \"\n      }), _jsx(Training101, {}), _jsx(Infobox, {\n        title: \"Training pipelines and models\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about \", _jsx(_components.strong, {\n            children: \"training and updating\"\n          }), \" pipelines, how to create training\\ndata and how to improve spaCy’s named models, see the usage guides on\\n\", _jsx(_components.a, {\n            href: \"/usage/training\",\n            children: \"training\"\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"training-config\",\n        children: \"Training config and lifecycle \"\n      }), _jsxs(_components.p, {\n        children: [\"Training config files include all \", _jsx(_components.strong, {\n          children: \"settings and hyperparameters\"\n        }), \" for training\\nyour pipeline. Instead of providing lots of arguments on the command line, you\\nonly need to pass your \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" file to \", _jsx(_components.a, {\n          href: \"/api/cli#train\",\n          children: _jsx(InlineCode, {\n            children: \"spacy train\"\n          })\n        }), \".\\nThis also makes it easy to integrate custom models and architectures, written in\\nyour framework of choice. A pipeline’s \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" is considered the “single\\nsource of truth”, both at \", _jsx(_components.strong, {\n          children: \"training\"\n        }), \" and \", _jsx(_components.strong, {\n          children: \"runtime\"\n        }), \".\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            title: \"config.cfg (excerpt)\",\n            children: \"[training]\\naccumulate_gradient = 3\\n\\n[training.optimizer]\\n@optimizers = \\\"Adam.v1\\\"\\n\\n[training.optimizer.learn_rate]\\n@schedules = \\\"warmup_linear.v1\\\"\\nwarmup_steps = 250\\ntotal_steps = 20000\\ninitial_rate = 0.01\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/lifecycle.svg\",\n        alt: \"Illustration of pipeline lifecycle\"\n      }), _jsx(Infobox, {\n        title: \"Training configuration system\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"For more details on spaCy’s \", _jsx(_components.strong, {\n            children: \"configuration system\"\n          }), \" and how to use it to\\ncustomize your pipeline components, component models, training settings and\\nhyperparameters, see the \", _jsx(_components.a, {\n            href: \"/usage/training#config\",\n            children: \"training config\"\n          }), \" usage guide.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"training-components\",\n        children: \"Trainable components \"\n      }), _jsxs(_components.p, {\n        children: [\"spaCy’s \", _jsx(_components.a, {\n          href: \"/api/pipe\",\n          children: _jsx(InlineCode, {\n            children: \"Pipe\"\n          })\n        }), \" class helps you implement your own trainable\\ncomponents that have their own model instance, make predictions over \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \"\\nobjects and can be updated using \", _jsx(_components.a, {\n          href: \"/api/cli#train\",\n          children: _jsx(InlineCode, {\n            children: \"spacy train\"\n          })\n        }), \". This lets you\\nplug fully custom machine learning components into your pipeline that can be\\nconfigured via a single training config.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"config.cfg (excerpt)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-ini\",\n            lang: \"ini\",\n            children: \"[components.my_component]\\nfactory = \\\"my_component\\\"\\n\\n[components.my_component.model]\\n@architectures = \\\"my_model.v1\\\"\\nwidth = 128\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.img, {\n        src: \"/images/trainable_component.svg\",\n        alt: \"Illustration of Pipe methods\"\n      }), _jsx(Infobox, {\n        title: \"Custom trainable components\",\n        emoji: \"📖\",\n        children: _jsxs(_components.p, {\n          children: [\"To learn more about how to implement your own \", _jsx(_components.strong, {\n            children: \"model architectures\"\n          }), \" and use\\nthem to power custom \", _jsx(_components.strong, {\n            children: \"trainable components\"\n          }), \", see the usage guides on the\\n\", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines#trainable-components\",\n            children: \"trainable component API\"\n          }), \" and\\nimplementing \", _jsx(_components.a, {\n            href: \"/usage/layers-architectures#components\",\n            children: \"layers and architectures\"\n          }), \"\\nfor trainable components.\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-language-data\",\n      children: [_jsx(_components.h2, {\n        id: \"language-data\",\n        children: \"Language data \"\n      }), _jsx(LanguageData101, {})]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-community-faq\",\n      children: [_jsx(_components.h2, {\n        id: \"community-faq\",\n        children: \"Community \u0026 FAQ \"\n      }), _jsx(_components.p, {\n        children: \"We’re very happy to see the spaCy community grow and include a mix of people\\nfrom all kinds of different backgrounds – computational linguistics, data\\nscience, deep learning, research and more. If you’d like to get involved, below\\nare some answers to the most important questions and resources for further\\nreading.\"\n      }), _jsx(_components.h3, {\n        id: \"faq-help-code\",\n        children: \"Help, my code isn’t working! \"\n      }), _jsxs(_components.p, {\n        children: [\"Bugs suck, and we’re doing our best to continuously improve the tests and fix\\nbugs as soon as possible. Before you submit an issue, do a quick search and\\ncheck if the problem has already been reported. If you’re having installation or\\nloading problems, make sure to also check out the\\n\", _jsx(_components.a, {\n          href: \"/usage/#troubleshooting\",\n          children: \"troubleshooting guide\"\n        }), \". Help with spaCy is available\\nvia the following platforms:\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"How do I know if something is a bug?\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Of course, it’s always hard to know for sure, so don’t worry – we’re not going\\nto be mad if a bug report turns out to be a typo in your code. As a simple\\nrule, any C-level error without a Python traceback, like a \", _jsx(_components.strong, {\n            children: \"segmentation\\nfault\"\n          }), \" or \", _jsx(_components.strong, {\n            children: \"memory error\"\n          }), \", is \", _jsx(_components.strong, {\n            children: \"always\"\n          }), \" a spaCy bug.\"]\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Because models are statistical, their performance will never be \", _jsx(_components.em, {\n            children: \"perfect\"\n          }), \".\\nHowever, if you come across \", _jsx(_components.strong, {\n            children: \"patterns that might indicate an underlying\\nissue\"\n          }), \", please do file a report. Similarly, we also care about behaviors that\\n\", _jsx(_components.strong, {\n            children: \"contradict our docs\"\n          }), \".\"]\n        }), \"\\n\"]\n      }), _jsxs(_components.ul, {\n        children: [\"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://stackoverflow.com/questions/tagged/spacy\",\n            children: \"Stack Overflow\"\n          }), \": \", _jsx(_components.strong, {\n            children: \"Usage\\nquestions\"\n          }), \" and everything related to problems with your specific code. The\\nStack Overflow community is much larger than ours, so if your problem can be\\nsolved by others, you’ll receive help much quicker.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/discussions\",\n            children: \"GitHub discussions\"\n          }), \":\\n\", _jsx(_components.strong, {\n            children: \"General discussion\"\n          }), \", \", _jsx(_components.strong, {\n            children: \"project ideas\"\n          }), \" and \", _jsx(_components.strong, {\n            children: \"usage questions\"\n          }), \". Meet other\\ncommunity members to get help with a specific code implementation, discuss\\nideas for new projects/plugins, support more languages, and share best\\npractices.\"]\n        }), \"\\n\", _jsxs(_components.li, {\n          children: [_jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/issues\",\n            children: \"GitHub issue tracker\"\n          }), \": \", _jsx(_components.strong, {\n            children: \"Bug\\nreports\"\n          }), \" and \", _jsx(_components.strong, {\n            children: \"improvement suggestions\"\n          }), \", i.e. everything that’s likely\\nspaCy’s fault. This also includes problems with the trained pipelines beyond\\nstatistical imprecisions, like patterns that point to a bug.\"]\n        }), \"\\n\"]\n      }), _jsx(Infobox, {\n        title: \"Important note\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"Please understand that we won’t be able to provide individual support via email.\\nWe also believe that help is much more valuable if it’s shared publicly, so that\\n\", _jsx(_components.strong, {\n            children: \"more people can benefit from it\"\n          }), \". If you come across an issue and you think\\nyou might be able to help, consider posting a quick update with your solution.\\nNo matter how simple, it can easily save someone a lot of time and headache –\\nand the next time you need help, they might repay the favor.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"faq-contributing\",\n        children: \"How can I contribute to spaCy? \"\n      }), _jsxs(_components.p, {\n        children: [\"You don’t have to be an NLP expert or Python pro to contribute, and we’re happy\\nto help you get started. If you’re new to spaCy, a good place to start is the\\n\", _jsxs(_components.a, {\n          href: \"https://github.com/explosion/spaCy/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted+%28easy%29%22\",\n          children: [_jsx(InlineCode, {\n            children: \"help wanted (easy)\"\n          }), \" label\"]\n        }), \"\\non GitHub, which we use to tag bugs and feature requests that are easy and\\nself-contained. We also appreciate contributions to the docs – whether it’s\\nfixing a typo, improving an example or adding additional explanations. You’ll\\nfind a “Suggest edits” link at the bottom of each page that points you to the\\nsource.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Another way of getting involved is to help us improve the\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#language-data\",\n          children: \"language data\"\n        }), \" – especially if you\\nhappen to speak one of the languages currently in\\n\", _jsx(_components.a, {\n          href: \"/usage/models#languages\",\n          children: \"alpha support\"\n        }), \". Even adding simple tokenizer\\nexceptions, stop words or lemmatizer data can make a big difference. It will\\nalso make it easier for us to provide a trained pipeline for the language in the\\nfuture. Submitting a test that documents a bug or performance issue, or covers\\nfunctionality that’s especially important for your application is also very\\nhelpful. This way, you’ll also make sure we never accidentally introduce\\nregressions to the parts of the library that you care about the most.\"]\n      }), _jsx(_components.p, {\n        children: _jsxs(_components.strong, {\n          children: [\"For more details on the types of contributions we’re looking for, the code\\nconventions and other useful tips, make sure to check out the\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/tree/master/CONTRIBUTING.md\",\n            children: \"contributing guidelines\"\n          }), \".\"]\n        })\n      }), _jsx(Infobox, {\n        title: \"Code of Conduct\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"spaCy adheres to the\\n\", _jsx(_components.a, {\n            href: \"http://contributor-covenant.org/version/1/4/\",\n            children: \"Contributor Covenant Code of Conduct\"\n          }), \".\\nBy participating, you are expected to uphold this code.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"faq-project-with-spacy\",\n        children: \"I’ve built something cool with spaCy – how can I get the word out? \"\n      }), _jsxs(_components.p, {\n        children: [\"First, congrats – we’d love to check it out! When you share your project on\\nTwitter, don’t forget to tag \", _jsx(_components.a, {\n          href: \"https://twitter.com/spacy_io\",\n          children: \"@spacy_io\"\n        }), \" so we\\ndon’t miss it. If you think your project would be a good fit for the\\n\", _jsx(_components.a, {\n          href: \"/universe\",\n          children: \"spaCy Universe\"\n        }), \", \", _jsx(_components.strong, {\n          children: \"feel free to submit it!\"\n        }), \" Tutorials are also\\nincredibly valuable to other users and a great way to get exposure. So we\\nstrongly encourage \", _jsx(_components.strong, {\n          children: \"writing up your experiences\"\n        }), \", or sharing your code and\\nsome tips and tricks on your blog. Since our website is open-source, you can add\\nyour project or tutorial by making a pull request on GitHub.\"]\n      }), _jsxs(_components.p, {\n        children: [\"If you would like to use the spaCy logo on your site, please get in touch and\\nask us first. However, if you want to show support and tell others that your\\nproject is using spaCy, you can grab one of our \", _jsx(_components.strong, {\n          children: \"spaCy badges\"\n        }), \" here:\"]\n      }), _jsx(\"img\", {\n        src: `https://img.shields.io/badge/built%20with-spaCy-09a3d5.svg`,\n        alt: \"Built with spaCy\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-markdown\",\n          lang: \"markdown\",\n          children: \"[![Built with spaCy](https://img.shields.io/badge/built%20with-spaCy-09a3d5.svg)](https://spacy.io)\\n\"\n        })\n      }), _jsx(\"img\", {\n        src: `https://img.shields.io/badge/made%20with%20❤%20and-spaCy-09a3d5.svg`,\n        alt: \"Made with love and spaCy\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-markdown\",\n          lang: \"markdown\",\n          children: \"[![Made with love and spaCy](https://img.shields.io/badge/made%20with%20❤%20and-spaCy-09a3d5.svg)](https://spacy.io)\\n\"\n        })\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"spaCy 101: Everything you need to know","teaser":"The most important concepts, explained in simple terms","menu":[["What's spaCy?","whats-spacy"],["Features","features"],["Linguistic Annotations","annotations"],["Pipelines","pipelines"],["Architecture","architecture"],["Vocab","vocab"],["Serialization","serialization"],["Training","training"],["Language Data","language-data"],["Community \u0026 FAQ","community-faq"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":{"slug":"/usage/v3","title":"New in v3.0"}},"__N_SSG":true},"page":"/[...listPathPage]","query":{"listPathPage":["usage","spacy-101"]},"buildId":"Ugre-usgT1EZhnSeYcBR9","isFallback":false,"dynamicIds":[728,5492],"gsp":true,"scriptLoader":[]}</script></body></html>