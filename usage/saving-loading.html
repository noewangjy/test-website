<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><link rel="shortcut icon" href="/icons/icon-192x192.png"/><link rel="manifest" href="/manifest.webmanifest"/><meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1, maximum-scale=5.0, shrink-to-fit=no, viewport-fit=cover"/><meta name="theme-color" content="#09a3d5"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png"/><title>Saving and Loading Â· spaCy Usage Documentation</title><meta name="description" content="spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more."/><meta property="og:title" content="Saving and Loading Â· spaCy Usage Documentation"/><meta property="og:description" content="spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more."/><meta property="og:type" content="website"/><meta property="og:site_name" content="Saving and Loading"/><meta property="og:image" content="https://spacy.io/_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:image" content="https://spacy.io/_next/static/media/social_default.96b04585.jpg"/><meta name="twitter:creator" content="@spacy_io"/><meta name="twitter:site" content="@spacy_io"/><meta name="twitter:title" content="Saving and Loading Â· spaCy Usage Documentation"/><meta name="twitter:description" content="spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more."/><meta name="docsearch:language" content="en"/><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/8f0b94edbc18d62d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8f0b94edbc18d62d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/e6995e0e8addcf99.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e6995e0e8addcf99.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/262.c647d33d06232ef6.js"></script><script defer="" src="/_next/static/chunks/728.cf6ba0da2700fa1b.js"></script><script src="/_next/static/chunks/webpack-8161fc2bb14cec39.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-a0f603ce323043fd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb3ea1261af64e73.js" defer=""></script><script src="/_next/static/chunks/94-57434c8b7a6c3878.js" defer=""></script><script src="/_next/static/chunks/128-76b45627a109219b.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...listPathPage%5D-45eea57fe8c2902c.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_buildManifest.js" defer=""></script><script src="/_next/static/Ugre-usgT1EZhnSeYcBR9/_ssgManifest.js" defer=""></script></head><body class="theme-blue"><div id="__next"><div class="theme-blue"><nav class="navigation_root__yPL8O"><span class="navigation_has-alert__s0Drf"><a class="link_root__1Me7D link_no-link-layout__RPvod" aria-label="spaCy" href="/"><h1 class="navigation_title__pm49s">spaCy</h1></a> <span class="navigation_alert__ZOXon"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage/v3-5"><strong>ðŸ’¥ Out now:</strong> spaCy v3.5</a></span></span><div class="navigation_menu__ZMJxN"><select class="dropdown_root__3uiQq navigation_dropdown__4j4pI"><option value="title" disabled="">Menu</option><option value="/usage" selected="">Usage</option><option value="/models">Models</option><option value="/api">API</option><option value="/universe">Universe</option></select><ul class="navigation_list__DCzqi"><li class="navigation_item__ln1O1 navigation_is-active__RjVJG"><a class="link_root__1Me7D link_no-link-layout__RPvod" tabindex="-1" href="/usage">Usage</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API</a></li><li class="navigation_item__ln1O1"><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li class="navigation_item__ln1O1 navigation_github__MpFNv"><span><a href="https://github.com/explosion/spaCy" data-size="large" data-show-count="true" aria-label="Star spaCy on GitHub"></a></span></li></ul><div class="navigation_search__BKZCn"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div><progress class="progress_root__9huWN" value="0" max="100"></progress></nav><menu class="sidebar sidebar_root__s2No7"><h1 hidden="" aria-hidden="true" class="h0 sidebar_active-heading___dkf9">Guides</h1><div class="sidebar_dropdown__vyqjz"><select class="dropdown_root__3uiQq sidebar_dropdown-select__Nwbq9"><option disabled="">Select page...</option><option value="/usage">Get started<!-- --> â€º <!-- -->Installation</option><option value="/usage/models">Get started<!-- --> â€º <!-- -->Models &amp; Languages</option><option value="/usage/facts-figures">Get started<!-- --> â€º <!-- -->Facts &amp; Figures</option><option value="/usage/spacy-101">Get started<!-- --> â€º <!-- -->spaCy 101</option><option value="/usage/v3">Get started<!-- --> â€º <!-- -->New in v3.0</option><option value="/usage/v3-1">Get started<!-- --> â€º <!-- -->New in v3.1</option><option value="/usage/v3-2">Get started<!-- --> â€º <!-- -->New in v3.2</option><option value="/usage/v3-3">Get started<!-- --> â€º <!-- -->New in v3.3</option><option value="/usage/v3-4">Get started<!-- --> â€º <!-- -->New in v3.4</option><option value="/usage/v3-5">Get started<!-- --> â€º <!-- -->New in v3.5</option><option value="/usage/linguistic-features">Guides<!-- --> â€º <!-- -->Linguistic Features</option><option value="/usage/rule-based-matching">Guides<!-- --> â€º <!-- -->Rule-based Matching</option><option value="/usage/processing-pipelines">Guides<!-- --> â€º <!-- -->Processing Pipelines</option><option value="/usage/embeddings-transformers">Guides<!-- --> â€º <!-- -->Embeddings &amp; Transformers</option><option value="/usage/training">Guides<!-- --> â€º <!-- -->Training Models</option><option value="/usage/layers-architectures">Guides<!-- --> â€º <!-- -->Layers &amp; Model Architectures</option><option value="/usage/projects">Guides<!-- --> â€º <!-- -->spaCy Projects</option><option value="/usage/saving-loading" selected="">Guides<!-- --> â€º <!-- -->Saving &amp; Loading</option><option value="/usage/visualizers">Guides<!-- --> â€º <!-- -->Visualizers</option><option value="https://github.com/explosion/projects">Resources<!-- --> â€º <!-- -->Project Templates</option><option value="https://v2.spacy.io">Resources<!-- --> â€º <!-- -->v2.x Documentation</option><option value="https://explosion.ai/custom-solutions">Resources<!-- --> â€º <!-- -->Custom Solutions</option></select></div><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Get started</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage">Installation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/models">Models &amp; Languages</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/facts-figures">Facts &amp; Figures</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/spacy-101">spaCy 101</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3">New in v3.0</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-1">New in v3.1</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-2">New in v3.2</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-3">New in v3.3</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-4">New in v3.4</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/v3-5">New in v3.5</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Guides</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/linguistic-features">Linguistic Features</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/rule-based-matching">Rule-based Matching</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/processing-pipelines">Processing Pipelines</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/embeddings-transformers">Embeddings &amp; Transformers<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/training">Training Models<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/layers-architectures">Layers &amp; Model Architectures<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/projects">spaCy Projects<span class="tag_root__NTSnK tag_spaced__Q9amH">new</span></a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP sidebar_is-active__yVTtL is-active" href="/usage/saving-loading">Saving &amp; Loading</a><ul class="sidebar_crumbs__NhM2y"><li class="sidebar_crumb__tiiDl sidebar_crumb-active__zq8BI"><a href="#basics">Basics</a></li><li class="sidebar_crumb__tiiDl"><a href="#docs">Serializing Docs</a></li><li class="sidebar_crumb__tiiDl"><a href="#serialization-methods">Serialization Methods</a></li><li class="sidebar_crumb__tiiDl"><a href="#entry-points">Entry Points</a></li><li class="sidebar_crumb__tiiDl"><a href="#models">Trained Pipelines</a></li></ul></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="/usage/visualizers">Visualizers</a></li></ul><ul class="sidebar_section__DArOO"><li class="sidebar_label__V3K28">Resources</li><li><a class="link_root__1Me7D sidebar_link__sKXFP" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/projects">Project Templates</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://v2.spacy.io">v2.x Documentation</a></li><li><a class="link_root__1Me7D sidebar_link__sKXFP" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></menu><main class="main_root__7f6Tj main_with-sidebar__uH1df main_with-asides__ikQT6"><article class="main_content__8zFCH"><header class="title_root__pS2WQ"><h1 id="_title" class="typography_heading__D82WZ typography_h1__b7dt9 title_h1__l3CW1"><span class="heading-text">Saving and Loading<!-- --> </span></h1></header><section id="section-basics" class="section_root__k1hUl"><p>If youâ€™ve been modifying the pipeline, vocabulary, vectors and entities, or made
updates to the component models, youâ€™ll eventually want to <strong>save your
progress</strong> â€“ for example, everything thatâ€™s in your <code class="code_inline-code__Bq7ot">nlp</code> object. This means
youâ€™ll have to translate its contents and structure into a format that can be
saved, like a file or a byte string. This process is called serialization. spaCy
comes with <strong>built-in serialization methods</strong> and supports the
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://www.diveinto.org/python3/serializing.html#dump">Pickle protocol</a>.</p>
<aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Whatâ€™s pickle?<!-- --> </span></h4>
<p>Pickle is Pythonâ€™s built-in object persistence system. It lets you transfer
arbitrary Python objects between processes. This is usually used to load an
object to and from disk, but itâ€™s also used for distributed computing, e.g.
with
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://spark.apache.org/docs/0.9.0/python-programming-guide.html">PySpark</a>
or <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://dask.org">Dask</a>. When you unpickle an object, youâ€™re agreeing to
execute whatever code it contains. Itâ€™s like calling <code class="code_inline-code__Bq7ot">eval()</code> on a string â€“ so
donâ€™t unpickle objects from untrusted sources.</p>
</div></div></aside>
<p>All container classes, i.e. <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language"><code class="code_inline-code__Bq7ot">Language</code></a> (<code class="code_inline-code__Bq7ot">nlp</code>),
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a>, <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a> and <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/stringstore"><code class="code_inline-code__Bq7ot">StringStore</code></a>
have the following methods available:</p>
<table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Method</th><th class="table_th__QJ9F8">Returns</th><th class="table_th__QJ9F8">Example</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">to_bytes</code></td><td class="table_td__rmpJx">bytes</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">data = nlp.to_bytes()</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">from_bytes</code></td><td class="table_td__rmpJx">object</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.from_bytes(data)</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">to_disk</code></td><td class="table_td__rmpJx">-</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.to_disk(&quot;/path&quot;)</code></td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">from_disk</code></td><td class="table_td__rmpJx">object</td><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">nlp.from_disk(&quot;/path&quot;)</code></td></tr></tbody></table><h3 id="pipeline" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#pipeline" class="heading-text typography_permalink__UiIRy">Serializing the pipeline <!-- --> </a></h3><p>When serializing the pipeline, keep in mind that this will only save out the
<strong>binary data for the individual components</strong> to allow spaCy to restore them â€“
not the entire objects. This is a good thing, because it makes serialization
safe. But it also means that you have to take care of storing the config, which
contains the pipeline configuration and all the relevant settings.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Saving the meta and config<!-- --> </span></h4>
<p>The <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#meta"><code class="code_inline-code__Bq7ot">nlp.meta</code></a> attribute is a JSON-serializable
dictionary and contains all pipeline meta information like the author and
license information. The <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#config"><code class="code_inline-code__Bq7ot">nlp.config</code></a> attribute is a
dictionary containing the training configuration, pipeline component factories
and other settings. It is saved out with a pipeline as the <code class="code_inline-code__Bq7ot">config.cfg</code>.</p>
</div></div></aside><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">Serialize</h4><code class="code_code__CILJL language-python language-python"></code></pre><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">Deserialize</h4><code class="code_code__CILJL language-python language-python"></code></pre><p>This is also how spaCy does it under the hood when loading a pipeline: it loads
the <code class="code_inline-code__Bq7ot">config.cfg</code> containing the language and pipeline information, initializes
the language class, creates and adds the pipeline components based on the config
and <em>then</em> loads in the binary data. You can read more about this process
<a class="link_root__1Me7D" href="/usage/processing-pipelines#pipelines">here</a>.</p></section>
<section id="section-docs" class="section_root__k1hUl"><h2 id="docs" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#docs" class="heading-text typography_permalink__UiIRy">Serializing Doc objects efficiently <!-- --> </a></h2><p>If youâ€™re working with lots of data, youâ€™ll probably need to pass analyses
between machines, either to use something like <a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://dask.org">Dask</a> or
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://spark.apache.org">Spark</a>, or even just to save out work to disk. Often
itâ€™s sufficient to use the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc#to_array"><code class="code_inline-code__Bq7ot">Doc.to_array</code></a> functionality for
this, and just serialize the numpy arrays â€“ but other times you want a more
general way to save and restore <code class="code_inline-code__Bq7ot">Doc</code> objects.</p><p>The <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/docbin"><code class="code_inline-code__Bq7ot">DocBin</code></a> class makes it easy to serialize and deserialize a
collection of <code class="code_inline-code__Bq7ot">Doc</code> objects together, and is much more efficient than calling
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc#to_bytes"><code class="code_inline-code__Bq7ot">Doc.to_bytes</code></a> on each individual <code class="code_inline-code__Bq7ot">Doc</code> object. You can
also control what data gets saved, and you can merge pallets together for easy
map/reduce-style processing.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python code_wrap__b41os"></code></pre><p>If <code class="code_inline-code__Bq7ot">store_user_data</code> is set to <code class="code_inline-code__Bq7ot">True</code>, the <code class="code_inline-code__Bq7ot">Doc.user_data</code> will be serialized as
well, which includes the values of
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components-attributes">extension attributes</a>
(if theyâ€™re serializable with msgpack).</p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note on serializing extension attributes</span></h4><p>Including the <code class="code_inline-code__Bq7ot">Doc.user_data</code> and extension attributes will only serialize the
<strong>values</strong> of the attributes. To restore the values and access them via the
<code class="code_inline-code__Bq7ot">doc._.</code> property, you need to register the global attribute on the <code class="code_inline-code__Bq7ot">Doc</code> again.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre></aside><h3 id="pickle" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#pickle" class="heading-text typography_permalink__UiIRy">Using Pickle <!-- --> </a></h3><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Example<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre>
</div></div></aside><p>When pickling spaCyâ€™s objects like the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/doc"><code class="code_inline-code__Bq7ot">Doc</code></a> or the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityrecognizer"><code class="code_inline-code__Bq7ot">EntityRecognizer</code></a>, keep in mind that they all require
the shared <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/vocab"><code class="code_inline-code__Bq7ot">Vocab</code></a> (which includes the string to hash mappings,
label schemes and optional vectors). This means that their pickled
representations can become very large, especially if you have word vectors
loaded, because it wonâ€™t only include the object itself, but also the entire
shared vocab it depends on.</p><p>If you need to pickle multiple objects, try to pickle them <strong>together</strong> instead
of separately. For instance, instead of pickling all pipeline components, pickle
the entire pipeline once. And instead of pickling several <code class="code_inline-code__Bq7ot">Doc</code> objects
separately, pickle a list of <code class="code_inline-code__Bq7ot">Doc</code> objects. Since they all share a reference to
the <em>same</em> <code class="code_inline-code__Bq7ot">Vocab</code> object, it will only be included once.</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">Pickling objects with shared data</h4><code class="code_code__CILJL language-python language-python code_wrap__b41os"></code></pre><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Pickling spans and tokens</span></h4><p>Pickling <code class="code_inline-code__Bq7ot">Token</code> and <code class="code_inline-code__Bq7ot">Span</code> objects isnâ€™t supported. Theyâ€™re only views of the
<code class="code_inline-code__Bq7ot">Doc</code> and canâ€™t exist on their own. Pickling them would always mean pulling in
the parent document and its vocabulary, which has practically no advantage over
pickling the parent <code class="code_inline-code__Bq7ot">Doc</code>.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre><p>If you really only need a span â€“ for example, a particular sentence â€“ you can
use <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/span#as_doc"><code class="code_inline-code__Bq7ot">Span.as_doc</code></a> to make a copy of it and convert it to a
<code class="code_inline-code__Bq7ot">Doc</code> object. However, note that this will not let you recover contextual
information from <em>outside</em> the span.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre></aside></section>
<section id="section-serialization-methods" class="section_root__k1hUl"><h2 id="serialization-methods" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#serialization-methods" class="heading-text typography_permalink__UiIRy">Implementing serialization methods <!-- --> </a></h2><p>When you call <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#to_disk"><code class="code_inline-code__Bq7ot">nlp.to_disk</code></a>,
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#from_disk"><code class="code_inline-code__Bq7ot">nlp.from_disk</code></a> or load a pipeline package, spaCy
will iterate over the components in the pipeline, check if they expose a
<code class="code_inline-code__Bq7ot">to_disk</code> or <code class="code_inline-code__Bq7ot">from_disk</code> method and if so, call it with the path to the pipeline
directory plus the string name of the component. For example, if youâ€™re calling
<code class="code_inline-code__Bq7ot">nlp.to_disk(&quot;/path&quot;)</code>, the data for the named entity recognizer will be saved
in <code class="code_inline-code__Bq7ot">/path/ner</code>.</p><p>If youâ€™re using custom pipeline components that depend on external data â€“ for
example, model weights or terminology lists â€“ you can take advantage of spaCyâ€™s
built-in component serialization by making your custom component expose its own
<code class="code_inline-code__Bq7ot">to_disk</code> and <code class="code_inline-code__Bq7ot">from_disk</code> or <code class="code_inline-code__Bq7ot">to_bytes</code> and <code class="code_inline-code__Bq7ot">from_bytes</code> methods. When an <code class="code_inline-code__Bq7ot">nlp</code>
object with the component in its pipeline is saved or loaded, the component will
then be able to serialize and deserialize itself.</p><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">ðŸ“–</span>Custom components and data</span></h4><p>For more details on how to work with pipeline components that depend on data
resources and manage data loading and initialization at training and runtime,
see the usage guide on initializing and serializing
<a class="link_root__1Me7D" href="/usage/processing-pipelines#component-data">component data</a>.</p></aside><p>The following example shows a custom component that keeps arbitrary
JSON-serializable data, allows the user to add to that data and saves and loads
the data to and from a JSON file.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Real-world example<!-- --> </span></h4>
<p>To see custom serialization methods in action, check out the new
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/entityruler"><code class="code_inline-code__Bq7ot">EntityRuler</code></a> component and its
<a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/spacy/pipeline/entityruler.py"><span class="link_source-text__VDP74">source</span></a>. Patterns added to the
component will be saved to a <code class="code_inline-code__Bq7ot">.jsonl</code> file if the pipeline is serialized to
disk, and to a bytestring if the pipeline is serialized to bytes. This allows
saving out a pipeline with a rule-based entity recognizer and including all
rules <em>with</em> the component data.</p>
</div></div></aside><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python code_wrap__b41os"></code></pre><p>After adding the component to the pipeline and adding some data to it, we can
serialize the <code class="code_inline-code__Bq7ot">nlp</code> object to a directory, which will call the custom
componentâ€™s <code class="code_inline-code__Bq7ot">to_disk</code> method.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python code_wrap__b41os"></code></pre><p>The contents of the directory would then look like this.
<code class="code_inline-code__Bq7ot">CustomComponent.to_disk</code> converted the data to a JSON string and saved it to a
file <code class="code_inline-code__Bq7ot">data.json</code> in its subdirectory:</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">Directory structure</h4><code class="code_code__CILJL language-yaml language-yaml code_wrap__b41os"></code></pre><p>When you load the data back in, spaCy will call the custom componentâ€™s
<code class="code_inline-code__Bq7ot">from_disk</code> method with the given file path, and the component can then load the
contents of <code class="code_inline-code__Bq7ot">data.json</code>, convert them to a Python object and restore the
component state. The same works for other types of data, of course â€“ for
instance, you could add a
<a class="link_root__1Me7D" href="/usage/layers-architectures#frameworks">wrapper for a model</a> trained with a
different library like TensorFlow or PyTorch and make spaCy load its weights
automatically when you load the pipeline package.</p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note on loading custom components</span></h4><p>When you load back a pipeline with custom components, make sure that the
components are <strong>available</strong> and that the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#component"><code class="code_inline-code__Bq7ot">@Language.component</code></a> or
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#factory"><code class="code_inline-code__Bq7ot">@Language.factory</code></a> decorators are executed <em>before</em>
your pipeline is loaded back. Otherwise, spaCy wonâ€™t know how to resolve the
string name of a component factory like <code class="code_inline-code__Bq7ot">&quot;my_component&quot;</code> back to a function. For
more details, see the documentation on
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components-factories">adding factories</a> or
use <a class="link_root__1Me7D" href="/usage/saving-loading#entry-points">entry points</a> to make your extension package expose your
custom components to spaCy automatically.</p></aside></section>
<section id="section-entry-points" class="section_root__k1hUl"><h2 id="entry-points" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#entry-points" class="heading-text typography_permalink__UiIRy">Using entry points <!-- --> </a></h2><p>Entry points let you expose parts of a Python package you write to other Python
packages. This lets one application easily customize the behavior of another, by
exposing an entry point in its <code class="code_inline-code__Bq7ot">setup.py</code>. For a quick and fun intro to entry
points in Python, check out
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://amir.rachum.com/blog/2017/07/28/python-entry-points/">this excellent blog post</a>.
spaCy can load custom functions from several different entry points to add
pipeline component factories, language classes and other settings. To make spaCy
use your entry points, your package needs to expose them and it needs to be
installed in the same environment â€“ thatâ€™s it.</p><table class="table_root__ZlA_w"><thead><tr class="table_tr__K_tkF"><th class="table_th__QJ9F8">Entry point</th><th class="table_th__QJ9F8">Description</th></tr></thead><tbody><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D" href="/usage/saving-loading#entry-points-components"><code class="code_inline-code__Bq7ot">spacy_factories</code></a></td><td class="table_td__rmpJx">Group of entry points for pipeline component factories, keyed by component name. Can be used to expose custom components defined by another package.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D" href="/usage/saving-loading#entry-points-languages"><code class="code_inline-code__Bq7ot">spacy_languages</code></a></td><td class="table_td__rmpJx">Group of entry points for custom <a class="link_root__1Me7D" href="/usage/linguistic-features#language-data"><code class="code_inline-code__Bq7ot">Language</code> subclasses</a>, keyed by language shortcut.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><code class="code_inline-code__Bq7ot">spacy_lookups</code></td><td class="table_td__rmpJx">Group of entry points for custom <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/lookups"><code class="code_inline-code__Bq7ot">Lookups</code></a>, including lemmatizer data. Used by spaCyâ€™s <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><code class="code_inline-code__Bq7ot">spacy-lookups-data</code></a> package.</td></tr><tr class="table_tr__K_tkF"><td class="table_td__rmpJx"><a class="link_root__1Me7D" href="/usage/saving-loading#entry-points-displacy"><code class="code_inline-code__Bq7ot">spacy_displacy_colors</code></a></td><td class="table_td__rmpJx">Group of entry points of custom label colors for the <a class="link_root__1Me7D" href="/usage/visualizers#ent">displaCy visualizer</a>. The key name doesnâ€™t matter, but it should point to a dict of labels and color values. Useful for custom models that predict different entity types.</td></tr></tbody></table><h3 class="typography_heading__D82WZ typography_h3__mPKmB"><span class="heading-text">Loading probability tables into existing models<!-- --> </span></h3><p>You can load a probability table from <a class="link_root__1Me7D link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy-lookups-data"><span class="link_source-text__VDP74">spacy-lookups-data</span></a> into an existing spaCy model like <code class="code_inline-code__Bq7ot">en_core_web_sm</code>.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>When training a model from scratch you can also specify probability tables in the <code class="code_inline-code__Bq7ot">config.cfg</code>.</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">config.cfg (excerpt)</h4><code class="code_code__CILJL language-ini language-ini"></code></pre><h3 id="entry-points-components" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#entry-points-components" class="heading-text typography_permalink__UiIRy">Custom components via entry points <!-- --> </a></h3><p>When you load a pipeline, spaCy will generally use its <code class="code_inline-code__Bq7ot">config.cfg</code> to set up
the language class and construct the pipeline. The pipeline is specified as a
list of strings, e.g. <code class="code_inline-code__Bq7ot code_wrap__b41os">pipeline = [&quot;tagger&quot;, &quot;parser&quot;, &quot;ner&quot;]</code>. For each of
those strings, spaCy will call <code class="code_inline-code__Bq7ot">nlp.add_pipe</code> and look up the name in all
factories defined by the decorators
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#component"><code class="code_inline-code__Bq7ot">@Language.component</code></a> and
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#factory"><code class="code_inline-code__Bq7ot">@Language.factory</code></a>. This means that you have to import
your custom components <em>before</em> loading the pipeline.</p><p>Using entry points, pipeline packages and extension packages can define their
own <code class="code_inline-code__Bq7ot">&quot;spacy_factories&quot;</code>, which will be loaded automatically in the background
when the <code class="code_inline-code__Bq7ot">Language</code> class is initialized. So if a user has your package
installed, theyâ€™ll be able to use your components â€“ even if they <strong>donâ€™t import
them</strong>!</p><p>To stick with the theme of
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://amir.rachum.com/blog/2017/07/28/python-entry-points/">this entry points blog post</a>,
consider the following custom spaCy
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-coponents">pipeline component</a> that prints a
snake when itâ€™s called:</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Package directory structure<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-yaml language-yaml"></code></pre>
</div></div></aside><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">snek.py</h4><code class="code_code__CILJL language-python language-python"></code></pre><p>Since itâ€™s a very complex and sophisticated module, you want to split it off
into its own package so you can version it and upload it to PyPi. You also want
your custom package to be able to define <code class="code_inline-code__Bq7ot">pipeline = [&quot;snek&quot;]</code> in its
<code class="code_inline-code__Bq7ot">config.cfg</code>. For that, you need to be able to tell spaCy where to find the
component <code class="code_inline-code__Bq7ot">&quot;snek&quot;</code>. If you donâ€™t do this, spaCy will raise an error when you try
to load the pipeline because thereâ€™s no built-in <code class="code_inline-code__Bq7ot">&quot;snek&quot;</code> component. To add an
entry to the factories, you can now expose it in your <code class="code_inline-code__Bq7ot">setup.py</code> via the
<code class="code_inline-code__Bq7ot">entry_points</code> dictionary:</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Entry point syntax<!-- --> </span></h4>
<p>Python entry points for a group are formatted as a <strong>list of strings</strong>, with
each string following the syntax of <code class="code_inline-code__Bq7ot">name = module:object</code>. In this example,
the created entry point is named <code class="code_inline-code__Bq7ot">snek</code> and points to the function
<code class="code_inline-code__Bq7ot">snek_component</code> in the module <code class="code_inline-code__Bq7ot">snek</code>, i.e. <code class="code_inline-code__Bq7ot">snek.py</code>.</p>
</div></div></aside><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">setup.py</h4><code class="code_code__CILJL language-python language-python code_wrap__b41os"></code></pre><p>The same package can expose multiple entry points, by the way. To make them
available to spaCy, all you need to do is install the package in your
environment:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre><p>spaCy is now able to create the pipeline component <code class="code_inline-code__Bq7ot">&quot;snek&quot;</code> â€“ even though you
never imported <code class="code_inline-code__Bq7ot">snek_component</code>. When you save the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#config"><code class="code_inline-code__Bq7ot">nlp.config</code></a> to disk, it includes an entry for your
<code class="code_inline-code__Bq7ot">&quot;snek&quot;</code> component and any pipeline you train with this config will include the
component and know how to load it â€“ if your <code class="code_inline-code__Bq7ot">snek</code> package is installed.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">config.cfg (excerpt)<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre>
</div></div></aside><pre class="code_pre__kzg60"><code class="code_code__CILJL language-none"></code></pre><p>Instead of making your snek component a simple
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components-simple">stateless component</a>, you
could also make it a
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components-factories">factory</a> that takes
settings. Your users can then pass in an optional <code class="code_inline-code__Bq7ot">config</code> when they add your
component to the pipeline and customize its appearance â€“ for example, the
<code class="code_inline-code__Bq7ot">snek_style</code>.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">config.cfg (excerpt)<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-diff language-diff"></code></pre>
</div></div></aside><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">setup.py</h4><code class="code_code__CILJL language-diff language-diff"></code></pre><p>The factory can also implement other pipeline component methods like <code class="code_inline-code__Bq7ot">to_disk</code>
and <code class="code_inline-code__Bq7ot">from_disk</code> for serialization, or even <code class="code_inline-code__Bq7ot">update</code> to make the component
trainable. If a component exposes a <code class="code_inline-code__Bq7ot">from_disk</code> method and is included in a
pipeline, spaCy will call it on load. This lets you ship custom data with your
pipeline package. When you save out a pipeline using <code class="code_inline-code__Bq7ot">nlp.to_disk</code> and the
component exposes a <code class="code_inline-code__Bq7ot">to_disk</code> method, it will be called with the disk path.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>The above example will serialize the current snake in a <code class="code_inline-code__Bq7ot">snek.txt</code> in the data
directory. When a pipeline using the <code class="code_inline-code__Bq7ot">snek</code> component is loaded, it will open
the <code class="code_inline-code__Bq7ot">snek.txt</code> and make it available to the component.</p><h3 id="entry-points-languages" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#entry-points-languages" class="heading-text typography_permalink__UiIRy">Custom language classes via entry points <!-- --> </a></h3><p>To stay with the theme of the previous example and
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://amir.rachum.com/blog/2017/07/28/python-entry-points/">this blog post on entry points</a>,
letâ€™s imagine you wanted to implement your own <code class="code_inline-code__Bq7ot">SnekLanguage</code> class for your
custom pipeline â€“Â but you donâ€™t necessarily want to modify spaCyâ€™s code to add a
language. In your package, you could then implement the following
<a class="link_root__1Me7D" href="/usage/linguistic-features#language-subclass">custom language subclass</a>:</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">snek.py</h4><code class="code_code__CILJL language-python language-python"></code></pre><p>Alongside the <code class="code_inline-code__Bq7ot">spacy_factories</code>, thereâ€™s also an entry point option for
<code class="code_inline-code__Bq7ot">spacy_languages</code>, which maps language codes to language-specific <code class="code_inline-code__Bq7ot">Language</code>
subclasses:</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">setup.py</h4><code class="code_code__CILJL language-diff language-diff"></code></pre><p>In spaCy, you can then load the custom <code class="code_inline-code__Bq7ot">snk</code> language and it will be resolved to
<code class="code_inline-code__Bq7ot">SnekLanguage</code> via the custom entry point. This is especially relevant for
pipeline packages you <a class="link_root__1Me7D" href="/usage/training">train</a>, which could then specify
<code class="code_inline-code__Bq7ot">lang = snk</code> in their <code class="code_inline-code__Bq7ot">config.cfg</code> without spaCy raising an error because the
language is not available in the core library.</p><h3 id="entry-points-displacy" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#entry-points-displacy" class="heading-text typography_permalink__UiIRy">Custom displaCy colors via entry points <!-- --> </a></h3><p>If youâ€™re training a named entity recognition model for a custom domain, you may
end up training different labels that donâ€™t have pre-defined colors in the
<a class="link_root__1Me7D" href="/usage/visualizers#ent"><code class="code_inline-code__Bq7ot">displacy</code> visualizer</a>. The <code class="code_inline-code__Bq7ot">spacy_displacy_colors</code>
entry point lets you define a dictionary of entity labels mapped to their color
values. Itâ€™s added to the pre-defined colors and can also overwrite existing
values.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">Domain-specific NER labels<!-- --> </span></h4>
<p>Good examples of pipelines with domain-specific label schemes are
<a class="link_root__1Me7D" href="/universe/project/scispacy">scispaCy</a> and
<a class="link_root__1Me7D" href="/universe/project/blackstone">Blackstone</a>.</p>
</div></div></aside><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">snek.py</h4><code class="code_code__CILJL language-python language-python"></code></pre><p>Given the above colors, the entry point can be defined as follows. Entry points
need to have a name, so we use the key <code class="code_inline-code__Bq7ot">colors</code>. However, the name doesnâ€™t
matter and whatever is defined in the entry point group will be used.</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">setup.py</h4><code class="code_code__CILJL language-diff language-diff"></code></pre><p>After installing the package, the custom colors will be used when visualizing
text with <code class="code_inline-code__Bq7ot">displacy</code>. Whenever the label <code class="code_inline-code__Bq7ot">SNEK</code> is assigned, it will be
displayed in <code class="code_inline-code__Bq7ot">#3dff74</code>.</p><iframe class="embed_standalone__RHbIL" title="displaCy visualization of entities" src="/images/displacy-ent-snek.html" width="800" height="100" allowfullscreen="" frameBorder="0"></iframe></section>
<section id="section-models" class="section_root__k1hUl"><h2 id="models" class="typography_heading__D82WZ typography_h2__hzV3h"><a href="#models" class="heading-text typography_permalink__UiIRy">Saving, loading and distributing trained pipelines <!-- --> </a></h2><p>After training your pipeline, youâ€™ll usually want to save its state, and load it
back later. You can do this with the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#to_disk"><code class="code_inline-code__Bq7ot">Language.to_disk</code></a>
method:</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>The directory will be created if it doesnâ€™t exist, and the whole pipeline data,
meta and configuration will be written out. To make the pipeline more convenient
to deploy, we recommend wrapping it as a <a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/cli#package"><span class="link_source-text__VDP74">Python package</span></a>.</p><section class="accordion" id="models-meta-vs-config"><div class="accordion_root__pPltq accordion_spaced__Ebyjn"><h4><button class="accordion_button__IPO0E" aria-expanded="true"><span><span class="heading-text">Whatâ€™s the difference between the config.cfg and meta.json?</span><a class="link_root__1Me7D accordion_anchor__kidBh link_no-link-layout__RPvod" href="/usage/saving-loading#models-meta-vs-config">Â¶</a></span><svg class="accordion_icon__fpBl7" width="20" height="20" viewBox="0 0 10 10" aria-hidden="true" focusable="false"><rect class="accordion_hidden__tgILw" height="8" width="2" x="4" y="1"></rect><rect height="2" width="8" x="1" y="4"></rect></svg></button></h4><div class="accordion_content__divKS"><p>When you save a pipeline in spaCy v3.0+, two files will be exported: a
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/data-formats#config"><code class="code_inline-code__Bq7ot">config.cfg</code></a> based on
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#config"><code class="code_inline-code__Bq7ot">nlp.config</code></a> and a <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/data-formats#meta"><code class="code_inline-code__Bq7ot">meta.json</code></a>
based on <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#meta"><code class="code_inline-code__Bq7ot">nlp.meta</code></a>.</p><ul class="list_ul__fe_HF">
<li class="list_li__sfx_z"><strong>config</strong>: Configuration used to create the current <code class="code_inline-code__Bq7ot">nlp</code> object, its
pipeline components and models, as well as training settings and
hyperparameters. Can include references to registered functions like
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components">pipeline components</a> or
<a class="link_root__1Me7D link_with-icon__NAVDA" href="/api/architectures"><span class="link_source-text__VDP74">model architectures</span></a>. Given a config, spaCy is able
reconstruct the whole tree of objects and the <code class="code_inline-code__Bq7ot">nlp</code> object. An exported config
can also be used to <a class="link_root__1Me7D" href="/usage/training#config">train a pipeline</a> with the same
settings.</li>
<li class="list_li__sfx_z"><strong>meta</strong>: Meta information about the pipeline and the Python package, such as
the author information, license, version, data sources and label scheme. This
is mostly used for documentation purposes and for packaging pipelines. It has
no impact on the functionality of the <code class="code_inline-code__Bq7ot">nlp</code> object.</li>
</ul></div></div></section><aside class="infobox_root__yNIMg"><h4 class="infobox_title__uDT7C"><span><span class="infobox_emoji__6_YUY" aria-hidden="true">ðŸª</span>Get started with a project template<!-- -->:<!-- --> <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/projects/tree/v3/pipelines/tagger_parser_ud"><code class="code_inline-code__Bq7ot">pipelines/tagger_parser_ud</code></a></span></h4><p>The easiest way to get started with an end-to-end workflow is to clone a
<a class="link_root__1Me7D" href="/usage/projects">project template</a> and run it â€“Â for example, this template that
lets you train a <strong>part-of-speech tagger</strong> and <strong>dependency parser</strong> on a
Universal Dependencies treebank and generates an installable Python package.</p><div class="copy_root__9E6qI"><span class="copy_prefix__p_JKI">$</span><textarea readonly="" class="copy_textarea__ATeHi" rows="1" aria-label="Example bash command to start with an end-to-end template">python -m spacy project clone pipelines/tagger_parser_ud</textarea></div></aside><h3 id="models-generating" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#models-generating" class="heading-text typography_permalink__UiIRy">Generating a pipeline package <!-- --> </a></h3><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note</span></h4><p>Pipeline packages are typically <strong>not suitable</strong> for the public
<a class="link_root__1Me7D" rel="noopener nofollow noreferrer" target="_blank" href="https://pypi.python.org">pypi.python.org</a> directory, which is not designed for
binary data and files over 50 MB. However, if your company is running an
<strong>internal installation</strong> of PyPi, publishing your pipeline packages on there
can be a convenient way to share them with your team.</p></aside><p>spaCy comes with a handy CLI command that will create all required files, and
walk you through generating the meta data. You can also create the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/data-formats#meta"><code class="code_inline-code__Bq7ot">meta.json</code></a> manually and place it in the data
directory, or supply a path to it using the <code class="code_inline-code__Bq7ot">--meta</code> flag. For more info on
this, see the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#package"><code class="code_inline-code__Bq7ot">package</code></a> docs.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">meta.json (example)<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-json language-json"></code></pre>
</div></div></aside><pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre><p>This command will create a pipeline package directory and will run
<code class="code_inline-code__Bq7ot">python setup.py sdist</code> in that directory to create a binary <code class="code_inline-code__Bq7ot">.whl</code> file or
<code class="code_inline-code__Bq7ot">.tar.gz</code> archive of your package that can be installed using <code class="code_inline-code__Bq7ot">pip install</code>.
Installing the binary wheel is usually more efficient.</p><pre class="code_pre__kzg60"><h4 class="code_title__Zz9rs">Directory structure</h4><code class="code_code__CILJL language-yaml language-yaml"></code></pre><p>You can also find templates for all files in the
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spacy/tree/master/spacy/cli/package.py"><code class="code_inline-code__Bq7ot">cli/package.py</code> source</a>.
If youâ€™re creating the package manually, keep in mind that the directories need
to be named according to the naming conventions of <code class="code_inline-code__Bq7ot">lang_name</code> and
<code class="code_inline-code__Bq7ot">lang_name-version</code>.</p><h3 id="models-custom" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#models-custom" class="heading-text typography_permalink__UiIRy">Including custom functions and components <!-- --> </a></h3><p>If your pipeline includes
<a class="link_root__1Me7D" href="/usage/processing-pipelines#custom-components">custom components</a>, model
architectures or other <a class="link_root__1Me7D" href="/usage/training#custom-code">code</a>, those functions need
to be registered <strong>before</strong> your pipeline is loaded. Otherwise, spaCy wonâ€™t know
how to create the objects referenced in the config. If youâ€™re loading your own
pipeline in Python, you can make custom components available just by importing
the code that defines them before calling
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/top-level#spacy.load"><code class="code_inline-code__Bq7ot">spacy.load</code></a>. This is also how the <code class="code_inline-code__Bq7ot">--code</code>
argument to CLI commands works.</p><p>With the <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/cli#package"><code class="code_inline-code__Bq7ot">spacy package</code></a> command, you can provide one or
more paths to Python files containing custom registered functions using the
<code class="code_inline-code__Bq7ot">--code</code> argument.</p><aside class="aside_root__667WA"><div class="aside_content__ZN6qm" role="complementary"><div class="aside_text__LFH_Q">
<h4 class="typography_heading__D82WZ typography_h4__CDRaM"><span class="heading-text">__init__.py (excerpt)<!-- --> </span></h4>
<pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre>
</div></div></aside><pre class="code_pre__kzg60"><code class="code_code__CILJL language-bash language-bash"></code></pre><p>The Python files will be copied over into the root of the package, and the
packageâ€™s <code class="code_inline-code__Bq7ot">__init__.py</code> will import them as modules. This ensures that functions
are registered when the pipeline is imported, e.g. when you call <code class="code_inline-code__Bq7ot">spacy.load</code>. A
simple import is all thatâ€™s needed to make registered functions available.</p><p>Make sure to include <strong>all Python files</strong> that are referenced in your custom
code, including modules imported by others. If your custom code depends on
<strong>external packages</strong>, make sure theyâ€™re listed in the list of <code class="code_inline-code__Bq7ot">&quot;requirements&quot;</code>
in your <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/data-formats#meta"><code class="code_inline-code__Bq7ot">meta.json</code></a>. For the majority of use cases,
registered functions should provide you with all customizations you need, from
custom components to custom model architectures and lifecycle hooks. However, if
you do want to customize the setup in more detail, you can edit the packageâ€™s
<code class="code_inline-code__Bq7ot">__init__.py</code> and the packageâ€™s <code class="code_inline-code__Bq7ot">load</code> function thatâ€™s called by
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/top-level#spacy.load"><code class="code_inline-code__Bq7ot">spacy.load</code></a>.</p><aside class="infobox_root__yNIMg infobox_warning__SKl67"><h4 class="infobox_title__uDT7C"><span>Important note on making manual edits</span></h4><p>While itâ€™s no problem to edit the package code or meta information, avoid making
edits to the <code class="code_inline-code__Bq7ot">config.cfg</code> <strong>after</strong> training, as this can easily lead to data
incompatibility. For instance, changing an architecture or hyperparameter can
mean that the trained weights are now incompatible. If you want to make
adjustments, you can do so before training. Otherwise, you should always trust
spaCy to export the current state of its <code class="code_inline-code__Bq7ot">nlp</code> objects via
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#config"><code class="code_inline-code__Bq7ot">nlp.config</code></a>.</p></aside><h3 id="loading" class="typography_heading__D82WZ typography_h3__mPKmB"><a href="#loading" class="heading-text typography_permalink__UiIRy">Loading a custom pipeline package <!-- --> </a></h3><p>To load a pipeline from a data directory, you can use
<a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/top-level#spacy.load"><code class="code_inline-code__Bq7ot">spacy.load()</code></a> with the local path. This will look
for a <code class="code_inline-code__Bq7ot">config.cfg</code> in the directory and use the <code class="code_inline-code__Bq7ot">lang</code> and <code class="code_inline-code__Bq7ot">pipeline</code> settings
to initialize a <code class="code_inline-code__Bq7ot">Language</code> class with a processing pipeline and load in the
model data.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre><p>If you want to <strong>load only the binary data</strong>, youâ€™ll have to create a <code class="code_inline-code__Bq7ot">Language</code>
class and call <a class="link_root__1Me7D link_nowrap__H7Oxl link_with-icon__NAVDA" href="/api/language#from_disk"><code class="code_inline-code__Bq7ot">from_disk</code></a> instead.</p><pre class="code_pre__kzg60"><code class="code_code__CILJL language-python language-python"></code></pre></section><div class="grid_root__EfDZl grid_spacing__fhBCv grid_half__xoJZs"><div style="margin-top:var(--spacing-lg)"><a class="link_root__1Me7D button_root__jwipc button_secondary__ukZAk" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/tree/master/website/docs/usage/saving-loading.mdx">Suggest edits</a></div><a class="link_root__1Me7D readnext_root__JNzwZ link_no-link-layout__RPvod" href="/usage/visualizers"><span><span class="typography_label__l_oVJ">Read next</span>Visualizers</span><span class="readnext_icon__jfRnJ"></span></a></div></article><div class="main_asides__RITE5" style="background-image:url(/_next/static/media/pattern_blue.d167bed5.png"></div><footer class="footer_root__zlkjP"><div class="grid_root__EfDZl footer_content__LaE1F grid_narrow__x_6xS grid_spacing__fhBCv grid_third__edHuB"><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">spaCy</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/usage">Usage</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/models">Models</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/api">API Reference</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://course.spacy.io">Online Course</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/custom-solutions">Custom Solutions</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Community</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="/universe">Universe</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/discussions">GitHub Discussions</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy/issues">Issue Tracker</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="http://stackoverflow.com/questions/tagged/spacy">Stack Overflow</a></li></ul></section><section><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Connect</li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/spacy_io">Twitter</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/explosion/spaCy">GitHub</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" rel="noopener nofollow noreferrer" target="_blank" href="https://youtube.com/c/ExplosionAI">YouTube</a></li><li><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/blog">Blog</a></li></ul></section><section class="footer_full___icln"><ul class="footer_column__DPe22"><li class="footer_label__xK7_s">Stay in the loop!</li><li>Receive updates about new releases, tutorials and more.</li><li><form id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" action="//spacy.us12.list-manage.com/subscribe/post?u=83b0498b1e7fa3c91ce68c3f1&amp;amp;id=ecc82e0493" method="post" target="_blank" novalidate=""><div style="position:absolute;left:-5000px" aria-hidden="true"><input type="text" name="b_83b0498b1e7fa3c91ce68c3f1_ecc82e0493" tabindex="-1" value=""/></div><div class="newsletter_root__uh6MU"><input class="newsletter_input___SMSB" id="mce-EMAIL" type="email" name="EMAIL" placeholder="Your email" aria-label="Your email"/><button class="newsletter_button__gKW8E" id="mc-embedded-subscribe" type="submit" name="subscribe">Sign up</button></div></form></li></ul></section></div><div class="footer_content__LaE1F footer_copy__rbjvc"><span>Â© 2016-<!-- -->2023<!-- --> <a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai">Explosion</a></span><a class="link_root__1Me7D footer_logo__BthsJ link_no-link-layout__RPvod" aria-label="Explosion" href="https://explosion.ai"></a><a class="link_root__1Me7D link_no-link-layout__RPvod" href="https://explosion.ai/legal">Legal / Imprint</a></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Saving and Loading","menu":[["Basics","basics"],["Serializing Docs","docs"],["Serialization Methods","serialization-methods"],["Entry Points","entry-points"],["Trained Pipelines","models"]],"slug":"/usage/saving-loading","mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\n/*## Initializing components with data {id=\"initialization\",version=\"3\"}*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    section: \"section\",\n    h2: \"h2\",\n    h3: \"h3\",\n    p: \"p\",\n    strong: \"strong\",\n    blockquote: \"blockquote\",\n    h4: \"h4\",\n    a: \"a\",\n    pre: \"pre\",\n    code: \"code\",\n    em: \"em\",\n    table: \"table\",\n    thead: \"thead\",\n    tr: \"tr\",\n    th: \"th\",\n    tbody: \"tbody\",\n    td: \"td\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components), {Serialization101, InlineCode, Infobox, Iframe, Accordion, Project} = _components;\n  if (!Accordion) _missingMdxReference(\"Accordion\", true);\n  if (!Iframe) _missingMdxReference(\"Iframe\", true);\n  if (!Infobox) _missingMdxReference(\"Infobox\", true);\n  if (!InlineCode) _missingMdxReference(\"InlineCode\", true);\n  if (!Project) _missingMdxReference(\"Project\", true);\n  if (!Serialization101) _missingMdxReference(\"Serialization101\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.section, {\n      id: \"section-basics\",\n      children: [_jsx(_components.h2, {\n        id: \"basics\",\n        hidden: \"true\",\n        children: \"Basics \"\n      }), _jsx(Serialization101, {}), _jsx(_components.h3, {\n        id: \"pipeline\",\n        children: \"Serializing the pipeline \"\n      }), _jsxs(_components.p, {\n        children: [\"When serializing the pipeline, keep in mind that this will only save out the\\n\", _jsx(_components.strong, {\n          children: \"binary data for the individual components\"\n        }), \" to allow spaCy to restore them â€“\\nnot the entire objects. This is a good thing, because it makes serialization\\nsafe. But it also means that you have to take care of storing the config, which\\ncontains the pipeline configuration and all the relevant settings.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Saving the meta and config\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"The \", _jsx(_components.a, {\n            href: \"/api/language#meta\",\n            children: _jsx(InlineCode, {\n              children: \"nlp.meta\"\n            })\n          }), \" attribute is a JSON-serializable\\ndictionary and contains all pipeline meta information like the author and\\nlicense information. The \", _jsx(_components.a, {\n            href: \"/api/language#config\",\n            children: _jsx(InlineCode, {\n              children: \"nlp.config\"\n            })\n          }), \" attribute is a\\ndictionary containing the training configuration, pipeline component factories\\nand other settings. It is saved out with a pipeline as the \", _jsx(InlineCode, {\n            children: \"config.cfg\"\n          }), \".\"]\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"Serialize\",\n          children: \"config = nlp.config\\nbytes_data = nlp.to_bytes()\\n\"\n        })\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"Deserialize\",\n          children: \"lang_cls = spacy.util.get_lang_class(config[\\\"nlp\\\"][\\\"lang\\\"])\\nnlp = lang_cls.from_config(config)\\nnlp.from_bytes(bytes_data)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"This is also how spaCy does it under the hood when loading a pipeline: it loads\\nthe \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" containing the language and pipeline information, initializes\\nthe language class, creates and adds the pipeline components based on the config\\nand \", _jsx(_components.em, {\n          children: \"then\"\n        }), \" loads in the binary data. You can read more about this process\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#pipelines\",\n          children: \"here\"\n        }), \".\"]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-docs\",\n      children: [_jsx(_components.h2, {\n        id: \"docs\",\n        version: \"2.2\",\n        children: \"Serializing Doc objects efficiently \"\n      }), _jsxs(_components.p, {\n        children: [\"If youâ€™re working with lots of data, youâ€™ll probably need to pass analyses\\nbetween machines, either to use something like \", _jsx(_components.a, {\n          href: \"https://dask.org\",\n          children: \"Dask\"\n        }), \" or\\n\", _jsx(_components.a, {\n          href: \"https://spark.apache.org\",\n          children: \"Spark\"\n        }), \", or even just to save out work to disk. Often\\nitâ€™s sufficient to use the \", _jsx(_components.a, {\n          href: \"/api/doc#to_array\",\n          children: _jsx(InlineCode, {\n            children: \"Doc.to_array\"\n          })\n        }), \" functionality for\\nthis, and just serialize the numpy arrays â€“ but other times you want a more\\ngeneral way to save and restore \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects.\"]\n      }), _jsxs(_components.p, {\n        children: [\"The \", _jsx(_components.a, {\n          href: \"/api/docbin\",\n          children: _jsx(InlineCode, {\n            children: \"DocBin\"\n          })\n        }), \" class makes it easy to serialize and deserialize a\\ncollection of \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects together, and is much more efficient than calling\\n\", _jsx(_components.a, {\n          href: \"/api/doc#to_bytes\",\n          children: _jsx(InlineCode, {\n            children: \"Doc.to_bytes\"\n          })\n        }), \" on each individual \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" object. You can\\nalso control what data gets saved, and you can merge pallets together for easy\\nmap/reduce-style processing.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          highlight: \"4,8,9,13,14\",\n          children: \"import spacy\\nfrom spacy.tokens import DocBin\\n\\ndoc_bin = DocBin(attrs=[\\\"LEMMA\\\", \\\"ENT_IOB\\\", \\\"ENT_TYPE\\\"], store_user_data=True)\\ntexts = [\\\"Some text\\\", \\\"Lots of texts...\\\", \\\"...\\\"]\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nfor doc in nlp.pipe(texts):\\n    doc_bin.add(doc)\\nbytes_data = doc_bin.to_bytes()\\n\\n# Deserialize later, e.g. in a new process\\nnlp = spacy.blank(\\\"en\\\")\\ndoc_bin = DocBin().from_bytes(bytes_data)\\ndocs = list(doc_bin.get_docs(nlp.vocab))\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If \", _jsx(InlineCode, {\n          children: \"store_user_data\"\n        }), \" is set to \", _jsx(InlineCode, {\n          children: \"True\"\n        }), \", the \", _jsx(InlineCode, {\n          children: \"Doc.user_data\"\n        }), \" will be serialized as\\nwell, which includes the values of\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components-attributes\",\n          children: \"extension attributes\"\n        }), \"\\n(if theyâ€™re serializable with msgpack).\"]\n      }), _jsxs(Infobox, {\n        title: \"Important note on serializing extension attributes\",\n        variant: \"warning\",\n        children: [_jsxs(_components.p, {\n          children: [\"Including the \", _jsx(InlineCode, {\n            children: \"Doc.user_data\"\n          }), \" and extension attributes will only serialize the\\n\", _jsx(_components.strong, {\n            children: \"values\"\n          }), \" of the attributes. To restore the values and access them via the\\n\", _jsx(InlineCode, {\n            children: \"doc._.\"\n          }), \" property, you need to register the global attribute on the \", _jsx(InlineCode, {\n            children: \"Doc\"\n          }), \" again.\"]\n        }), _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"docs = list(doc_bin.get_docs(nlp.vocab))\\nDoc.set_extension(\\\"my_custom_attr\\\", default=None)\\nprint([doc._.my_custom_attr for doc in docs])\\n\"\n          })\n        })]\n      }), _jsx(_components.h3, {\n        id: \"pickle\",\n        children: \"Using Pickle \"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Example\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"doc = nlp(\\\"This is a text.\\\")\\ndata = pickle.dumps(doc)\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsxs(_components.p, {\n        children: [\"When pickling spaCyâ€™s objects like the \", _jsx(_components.a, {\n          href: \"/api/doc\",\n          children: _jsx(InlineCode, {\n            children: \"Doc\"\n          })\n        }), \" or the\\n\", _jsx(_components.a, {\n          href: \"/api/entityrecognizer\",\n          children: _jsx(InlineCode, {\n            children: \"EntityRecognizer\"\n          })\n        }), \", keep in mind that they all require\\nthe shared \", _jsx(_components.a, {\n          href: \"/api/vocab\",\n          children: _jsx(InlineCode, {\n            children: \"Vocab\"\n          })\n        }), \" (which includes the string to hash mappings,\\nlabel schemes and optional vectors). This means that their pickled\\nrepresentations can become very large, especially if you have word vectors\\nloaded, because it wonâ€™t only include the object itself, but also the entire\\nshared vocab it depends on.\"]\n      }), _jsxs(_components.p, {\n        children: [\"If you need to pickle multiple objects, try to pickle them \", _jsx(_components.strong, {\n          children: \"together\"\n        }), \" instead\\nof separately. For instance, instead of pickling all pipeline components, pickle\\nthe entire pipeline once. And instead of pickling several \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects\\nseparately, pickle a list of \", _jsx(InlineCode, {\n          children: \"Doc\"\n        }), \" objects. Since they all share a reference to\\nthe \", _jsx(_components.em, {\n          children: \"same\"\n        }), \" \", _jsx(InlineCode, {\n          children: \"Vocab\"\n        }), \" object, it will only be included once.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"Pickling objects with shared data\",\n          highlight: \"8-9\",\n          children: \"doc1 = nlp(\\\"Hello world\\\")\\ndoc2 = nlp(\\\"This is a test\\\")\\n\\ndoc1_data = pickle.dumps(doc1)\\ndoc2_data = pickle.dumps(doc2)\\nprint(len(doc1_data) + len(doc2_data))  # 6636116 ðŸ˜ž\\n\\ndoc_data = pickle.dumps([doc1, doc2])\\nprint(len(doc_data))  # 3319761 ðŸ˜ƒ\\n\"\n        })\n      }), _jsxs(Infobox, {\n        title: \"Pickling spans and tokens\",\n        variant: \"warning\",\n        children: [_jsxs(_components.p, {\n          children: [\"Pickling \", _jsx(InlineCode, {\n            children: \"Token\"\n          }), \" and \", _jsx(InlineCode, {\n            children: \"Span\"\n          }), \" objects isnâ€™t supported. Theyâ€™re only views of the\\n\", _jsx(InlineCode, {\n            children: \"Doc\"\n          }), \" and canâ€™t exist on their own. Pickling them would always mean pulling in\\nthe parent document and its vocabulary, which has practically no advantage over\\npickling the parent \", _jsx(InlineCode, {\n            children: \"Doc\"\n          }), \".\"]\n        }), _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-diff\",\n            lang: \"diff\",\n            children: \"- data = pickle.dumps(doc[10:20])\\n+ data = pickle.dumps(doc)\\n\"\n          })\n        }), _jsxs(_components.p, {\n          children: [\"If you really only need a span â€“ for example, a particular sentence â€“ you can\\nuse \", _jsx(_components.a, {\n            href: \"/api/span#as_doc\",\n            children: _jsx(InlineCode, {\n              children: \"Span.as_doc\"\n            })\n          }), \" to make a copy of it and convert it to a\\n\", _jsx(InlineCode, {\n            children: \"Doc\"\n          }), \" object. However, note that this will not let you recover contextual\\ninformation from \", _jsx(_components.em, {\n            children: \"outside\"\n          }), \" the span.\"]\n        }), _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-diff\",\n            lang: \"diff\",\n            children: \"+ span_doc = doc[10:20].as_doc()\\ndata = pickle.dumps(span_doc)\\n\"\n          })\n        })]\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-serialization-methods\",\n      children: [_jsx(_components.h2, {\n        id: \"serialization-methods\",\n        children: \"Implementing serialization methods \"\n      }), _jsxs(_components.p, {\n        children: [\"When you call \", _jsx(_components.a, {\n          href: \"/api/language#to_disk\",\n          children: _jsx(InlineCode, {\n            children: \"nlp.to_disk\"\n          })\n        }), \",\\n\", _jsx(_components.a, {\n          href: \"/api/language#from_disk\",\n          children: _jsx(InlineCode, {\n            children: \"nlp.from_disk\"\n          })\n        }), \" or load a pipeline package, spaCy\\nwill iterate over the components in the pipeline, check if they expose a\\n\", _jsx(InlineCode, {\n          children: \"to_disk\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"from_disk\"\n        }), \" method and if so, call it with the path to the pipeline\\ndirectory plus the string name of the component. For example, if youâ€™re calling\\n\", _jsx(InlineCode, {\n          children: \"nlp.to_disk(\\\"/path\\\")\"\n        }), \", the data for the named entity recognizer will be saved\\nin \", _jsx(InlineCode, {\n          children: \"/path/ner\"\n        }), \".\"]\n      }), _jsxs(_components.p, {\n        children: [\"If youâ€™re using custom pipeline components that depend on external data â€“ for\\nexample, model weights or terminology lists â€“ you can take advantage of spaCyâ€™s\\nbuilt-in component serialization by making your custom component expose its own\\n\", _jsx(InlineCode, {\n          children: \"to_disk\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"from_disk\"\n        }), \" or \", _jsx(InlineCode, {\n          children: \"to_bytes\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"from_bytes\"\n        }), \" methods. When an \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \"\\nobject with the component in its pipeline is saved or loaded, the component will\\nthen be able to serialize and deserialize itself.\"]\n      }), _jsx(Infobox, {\n        title: \"Custom components and data\",\n        emoji: \"ðŸ“–\",\n        children: _jsxs(_components.p, {\n          children: [\"For more details on how to work with pipeline components that depend on data\\nresources and manage data loading and initialization at training and runtime,\\nsee the usage guide on initializing and serializing\\n\", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines#component-data\",\n            children: \"component data\"\n          }), \".\"]\n        })\n      }), _jsx(_components.p, {\n        children: \"The following example shows a custom component that keeps arbitrary\\nJSON-serializable data, allows the user to add to that data and saves and loads\\nthe data to and from a JSON file.\"\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Real-world example\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"To see custom serialization methods in action, check out the new\\n\", _jsx(_components.a, {\n            href: \"/api/entityruler\",\n            children: _jsx(InlineCode, {\n              children: \"EntityRuler\"\n            })\n          }), \" component and its\\n\", _jsx(_components.a, {\n            href: \"https://github.com/explosion/spaCy/tree/master/spacy/pipeline/entityruler.py\",\n            children: \"source\"\n          }), \". Patterns added to the\\ncomponent will be saved to a \", _jsx(InlineCode, {\n            children: \".jsonl\"\n          }), \" file if the pipeline is serialized to\\ndisk, and to a bytestring if the pipeline is serialized to bytes. This allows\\nsaving out a pipeline with a rule-based entity recognizer and including all\\nrules \", _jsx(_components.em, {\n            children: \"with\"\n          }), \" the component data.\"]\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          highlight: \"16-23,25-30\",\n          children: \"import json\\nfrom spacy import Language\\nfrom spacy.util import ensure_path\\n\\n@Language.factory(\\\"my_component\\\")\\nclass CustomComponent:\\n    def __init__(self, nlp: Language, name: str = \\\"my_component\\\"):\\n        self.name = name\\n        self.data = []\\n\\n    def __call__(self, doc):\\n        # Do something to the doc here\\n        return doc\\n\\n    def add(self, data):\\n        # Add something to the component's data\\n        self.data.append(data)\\n\\n    def to_disk(self, path, exclude=tuple()):\\n        # This will receive the directory path + /my_component\\n        path = ensure_path(path)\\n        if not path.exists():\\n            path.mkdir()\\n        data_path = path / \\\"data.json\\\"\\n        with data_path.open(\\\"w\\\", encoding=\\\"utf8\\\") as f:\\n            f.write(json.dumps(self.data))\\n\\n    def from_disk(self, path, exclude=tuple()):\\n        # This will receive the directory path + /my_component\\n        data_path = path / \\\"data.json\\\"\\n        with data_path.open(\\\"r\\\", encoding=\\\"utf8\\\") as f:\\n            self.data = json.load(f)\\n        return self\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"After adding the component to the pipeline and adding some data to it, we can\\nserialize the \", _jsx(InlineCode, {\n          children: \"nlp\"\n        }), \" object to a directory, which will call the custom\\ncomponentâ€™s \", _jsx(InlineCode, {\n          children: \"to_disk\"\n        }), \" method.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          highlight: \"2-4\",\n          children: \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\nmy_component = nlp.add_pipe(\\\"my_component\\\")\\nmy_component.add({\\\"hello\\\": \\\"world\\\"})\\nnlp.to_disk(\\\"/path/to/pipeline\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"The contents of the directory would then look like this.\\n\", _jsx(InlineCode, {\n          children: \"CustomComponent.to_disk\"\n        }), \" converted the data to a JSON string and saved it to a\\nfile \", _jsx(InlineCode, {\n          children: \"data.json\"\n        }), \" in its subdirectory:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-yaml\",\n          lang: \"yaml\",\n          title: \"Directory structure\",\n          highlight: \"2-3\",\n          children: \"â””â”€â”€ /path/to/pipeline\\n    â”œâ”€â”€ my_component     # data serialized by \\\"my_component\\\"\\n    â”‚   â””â”€â”€ data.json\\n    â”œâ”€â”€ ner              # data for \\\"ner\\\" component\\n    â”œâ”€â”€ parser           # data for \\\"parser\\\" component\\n    â”œâ”€â”€ tagger           # data for \\\"tagger\\\" component\\n    â”œâ”€â”€ vocab            # pipeline vocabulary\\n    â”œâ”€â”€ meta.json        # pipeline meta.json\\n    â”œâ”€â”€ config.cfg       # pipeline config\\n    â””â”€â”€ tokenizer        # tokenization rules\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"When you load the data back in, spaCy will call the custom componentâ€™s\\n\", _jsx(InlineCode, {\n          children: \"from_disk\"\n        }), \" method with the given file path, and the component can then load the\\ncontents of \", _jsx(InlineCode, {\n          children: \"data.json\"\n        }), \", convert them to a Python object and restore the\\ncomponent state. The same works for other types of data, of course â€“ for\\ninstance, you could add a\\n\", _jsx(_components.a, {\n          href: \"/usage/layers-architectures#frameworks\",\n          children: \"wrapper for a model\"\n        }), \" trained with a\\ndifferent library like TensorFlow or PyTorch and make spaCy load its weights\\nautomatically when you load the pipeline package.\"]\n      }), _jsx(Infobox, {\n        title: \"Important note on loading custom components\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"When you load back a pipeline with custom components, make sure that the\\ncomponents are \", _jsx(_components.strong, {\n            children: \"available\"\n          }), \" and that the\\n\", _jsx(_components.a, {\n            href: \"/api/language#component\",\n            children: _jsx(InlineCode, {\n              children: \"@Language.component\"\n            })\n          }), \" or\\n\", _jsx(_components.a, {\n            href: \"/api/language#factory\",\n            children: _jsx(InlineCode, {\n              children: \"@Language.factory\"\n            })\n          }), \" decorators are executed \", _jsx(_components.em, {\n            children: \"before\"\n          }), \"\\nyour pipeline is loaded back. Otherwise, spaCy wonâ€™t know how to resolve the\\nstring name of a component factory like \", _jsx(InlineCode, {\n            children: \"\\\"my_component\\\"\"\n          }), \" back to a function. For\\nmore details, see the documentation on\\n\", _jsx(_components.a, {\n            href: \"/usage/processing-pipelines#custom-components-factories\",\n            children: \"adding factories\"\n          }), \" or\\nuse \", _jsx(_components.a, {\n            href: \"#entry-points\",\n            children: \"entry points\"\n          }), \" to make your extension package expose your\\ncustom components to spaCy automatically.\"]\n        })\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-entry-points\",\n      children: [_jsx(_components.h2, {\n        id: \"entry-points\",\n        version: \"2.1\",\n        children: \"Using entry points \"\n      }), _jsxs(_components.p, {\n        children: [\"Entry points let you expose parts of a Python package you write to other Python\\npackages. This lets one application easily customize the behavior of another, by\\nexposing an entry point in its \", _jsx(InlineCode, {\n          children: \"setup.py\"\n        }), \". For a quick and fun intro to entry\\npoints in Python, check out\\n\", _jsx(_components.a, {\n          href: \"https://amir.rachum.com/blog/2017/07/28/python-entry-points/\",\n          children: \"this excellent blog post\"\n        }), \".\\nspaCy can load custom functions from several different entry points to add\\npipeline component factories, language classes and other settings. To make spaCy\\nuse your entry points, your package needs to expose them and it needs to be\\ninstalled in the same environment â€“ thatâ€™s it.\"]\n      }), _jsxs(_components.table, {\n        children: [_jsx(_components.thead, {\n          children: _jsxs(_components.tr, {\n            children: [_jsx(_components.th, {\n              children: \"Entry point\"\n            }), _jsx(_components.th, {\n              children: \"Description\"\n            })]\n          })\n        }), _jsxs(_components.tbody, {\n          children: [_jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"#entry-points-components\",\n                children: _jsx(InlineCode, {\n                  children: \"spacy_factories\"\n                })\n              })\n            }), _jsx(_components.td, {\n              children: \"Group of entry points for pipeline component factories, keyed by component name. Can be used to expose custom components defined by another package.\"\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"#entry-points-languages\",\n                children: _jsx(InlineCode, {\n                  children: \"spacy_languages\"\n                })\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Group of entry points for custom \", _jsxs(_components.a, {\n                href: \"/usage/linguistic-features#language-data\",\n                children: [_jsx(InlineCode, {\n                  children: \"Language\"\n                }), \" subclasses\"]\n              }), \", keyed by language shortcut.\"]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(InlineCode, {\n                children: \"spacy_lookups\"\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Group of entry points for custom \", _jsx(_components.a, {\n                href: \"/api/lookups\",\n                children: _jsx(InlineCode, {\n                  children: \"Lookups\"\n                })\n              }), \", including lemmatizer data. Used by spaCyâ€™s \", _jsx(_components.a, {\n                href: \"https://github.com/explosion/spacy-lookups-data\",\n                children: _jsx(InlineCode, {\n                  children: \"spacy-lookups-data\"\n                })\n              }), \" package.\"]\n            })]\n          }), _jsxs(_components.tr, {\n            children: [_jsx(_components.td, {\n              children: _jsx(_components.a, {\n                href: \"#entry-points-displacy\",\n                children: _jsx(InlineCode, {\n                  children: \"spacy_displacy_colors\"\n                })\n              })\n            }), _jsxs(_components.td, {\n              children: [\"Group of entry points of custom label colors for the \", _jsx(_components.a, {\n                href: \"/usage/visualizers#ent\",\n                children: \"displaCy visualizer\"\n              }), \". The key name doesnâ€™t matter, but it should point to a dict of labels and color values. Useful for custom models that predict different entity types.\"]\n            })]\n          })]\n        })]\n      }), _jsx(_components.h3, {\n        children: \"Loading probability tables into existing models\"\n      }), _jsxs(_components.p, {\n        children: [\"You can load a probability table from \", _jsx(_components.a, {\n          href: \"https://github.com/explosion/spacy-lookups-data\",\n          children: \"spacy-lookups-data\"\n        }), \" into an existing spaCy model like \", _jsx(InlineCode, {\n          children: \"en_core_web_sm\"\n        }), \".\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"# Requirements: pip install spacy-lookups-data\\nimport spacy\\nfrom spacy.lookups import load_lookups\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nlookups = load_lookups(\\\"en\\\", [\\\"lexeme_prob\\\"])\\nnlp.vocab.lookups.add_table(\\\"lexeme_prob\\\", lookups.get_table(\\\"lexeme_prob\\\"))\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"When training a model from scratch you can also specify probability tables in the \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \".\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-ini\",\n          lang: \"ini\",\n          title: \"config.cfg (excerpt)\",\n          children: \"[initialize.lookups]\\n@misc = \\\"spacy.LookupsDataLoader.v1\\\"\\nlang = ${nlp.lang}\\ntables = [\\\"lexeme_prob\\\"]\\n\"\n        })\n      }), _jsx(_components.h3, {\n        id: \"entry-points-components\",\n        children: \"Custom components via entry points \"\n      }), _jsxs(_components.p, {\n        children: [\"When you load a pipeline, spaCy will generally use its \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" to set up\\nthe language class and construct the pipeline. The pipeline is specified as a\\nlist of strings, e.g. \", _jsx(InlineCode, {\n          children: \"pipeline = [\\\"tagger\\\", \\\"parser\\\", \\\"ner\\\"]\"\n        }), \". For each of\\nthose strings, spaCy will call \", _jsx(InlineCode, {\n          children: \"nlp.add_pipe\"\n        }), \" and look up the name in all\\nfactories defined by the decorators\\n\", _jsx(_components.a, {\n          href: \"/api/language#component\",\n          children: _jsx(InlineCode, {\n            children: \"@Language.component\"\n          })\n        }), \" and\\n\", _jsx(_components.a, {\n          href: \"/api/language#factory\",\n          children: _jsx(InlineCode, {\n            children: \"@Language.factory\"\n          })\n        }), \". This means that you have to import\\nyour custom components \", _jsx(_components.em, {\n          children: \"before\"\n        }), \" loading the pipeline.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Using entry points, pipeline packages and extension packages can define their\\nown \", _jsx(InlineCode, {\n          children: \"\\\"spacy_factories\\\"\"\n        }), \", which will be loaded automatically in the background\\nwhen the \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" class is initialized. So if a user has your package\\ninstalled, theyâ€™ll be able to use your components â€“ even if they \", _jsx(_components.strong, {\n          children: \"donâ€™t import\\nthem\"\n        }), \"!\"]\n      }), _jsxs(_components.p, {\n        children: [\"To stick with the theme of\\n\", _jsx(_components.a, {\n          href: \"https://amir.rachum.com/blog/2017/07/28/python-entry-points/\",\n          children: \"this entry points blog post\"\n        }), \",\\nconsider the following custom spaCy\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-coponents\",\n          children: \"pipeline component\"\n        }), \" that prints a\\nsnake when itâ€™s called:\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Package directory structure\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-yaml\",\n            lang: \"yaml\",\n            children: \"â”œâ”€â”€ snek.py   # the extension code\\nâ””â”€â”€ setup.py  # setup file for pip installation\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"snek.py\",\n          children: \"from spacy.language import Language\\n\\nsnek = \\\"\\\"\\\"\\n    --..,_                     _,.--.\\n       `'.'.                .'`__ o  `;__. {text}\\n          '.'.            .'.'`  '---'`  `\\n            '.`'--....--'`.'\\n              `'--....--'`\\n\\\"\\\"\\\"\\n\\n@Language.component(\\\"snek\\\")\\ndef snek_component(doc):\\n    print(snek.format(text=doc.text))\\n    return doc\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Since itâ€™s a very complex and sophisticated module, you want to split it off\\ninto its own package so you can version it and upload it to PyPi. You also want\\nyour custom package to be able to define \", _jsx(InlineCode, {\n          children: \"pipeline = [\\\"snek\\\"]\"\n        }), \" in its\\n\", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \". For that, you need to be able to tell spaCy where to find the\\ncomponent \", _jsx(InlineCode, {\n          children: \"\\\"snek\\\"\"\n        }), \". If you donâ€™t do this, spaCy will raise an error when you try\\nto load the pipeline because thereâ€™s no built-in \", _jsx(InlineCode, {\n          children: \"\\\"snek\\\"\"\n        }), \" component. To add an\\nentry to the factories, you can now expose it in your \", _jsx(InlineCode, {\n          children: \"setup.py\"\n        }), \" via the\\n\", _jsx(InlineCode, {\n          children: \"entry_points\"\n        }), \" dictionary:\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Entry point syntax\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Python entry points for a group are formatted as a \", _jsx(_components.strong, {\n            children: \"list of strings\"\n          }), \", with\\neach string following the syntax of \", _jsx(InlineCode, {\n            children: \"name = module:object\"\n          }), \". In this example,\\nthe created entry point is named \", _jsx(InlineCode, {\n            children: \"snek\"\n          }), \" and points to the function\\n\", _jsx(InlineCode, {\n            children: \"snek_component\"\n          }), \" in the module \", _jsx(InlineCode, {\n            children: \"snek\"\n          }), \", i.e. \", _jsx(InlineCode, {\n            children: \"snek.py\"\n          }), \".\"]\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"setup.py\",\n          highlight: \"5-7\",\n          children: \"from setuptools import setup\\n\\nsetup(\\n    name=\\\"snek\\\",\\n    entry_points={\\n        \\\"spacy_factories\\\": [\\\"snek = snek:snek_component\\\"]\\n    }\\n)\\n\"\n        })\n      }), _jsx(_components.p, {\n        children: \"The same package can expose multiple entry points, by the way. To make them\\navailable to spaCy, all you need to do is install the package in your\\nenvironment:\"\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-bash\",\n          lang: \"bash\",\n          children: \"$ python setup.py develop\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"spaCy is now able to create the pipeline component \", _jsx(InlineCode, {\n          children: \"\\\"snek\\\"\"\n        }), \" â€“ even though you\\nnever imported \", _jsx(InlineCode, {\n          children: \"snek_component\"\n        }), \". When you save the\\n\", _jsx(_components.a, {\n          href: \"/api/language#config\",\n          children: _jsx(InlineCode, {\n            children: \"nlp.config\"\n          })\n        }), \" to disk, it includes an entry for your\\n\", _jsx(InlineCode, {\n          children: \"\\\"snek\\\"\"\n        }), \" component and any pipeline you train with this config will include the\\ncomponent and know how to load it â€“ if your \", _jsx(InlineCode, {\n          children: \"snek\"\n        }), \" package is installed.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"config.cfg (excerpt)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-diff\",\n            lang: \"diff\",\n            children: \"[nlp]\\nlang = \\\"en\\\"\\n+ pipeline = [\\\"snek\\\"]\\n\\n[components]\\n\\n+ [components.snek]\\n+ factory = \\\"snek\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          lang: \"none\",\n          children: \"\u003e\u003e\u003e from spacy.lang.en import English\\n\u003e\u003e\u003e nlp = English()\\n\u003e\u003e\u003e nlp.add_pipe(\\\"snek\\\")  # this now works! ðŸðŸŽ‰\\n\u003e\u003e\u003e doc = nlp(\\\"I am snek\\\")\\n    --..,_                     _,.--.\\n       `'.'.                .'`__ o  `;__. I am snek\\n          '.'.            .'.'`  '---'`  `\\n            '.`'--....--'`.'\\n              `'--....--'`\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Instead of making your snek component a simple\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components-simple\",\n          children: \"stateless component\"\n        }), \", you\\ncould also make it a\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components-factories\",\n          children: \"factory\"\n        }), \" that takes\\nsettings. Your users can then pass in an optional \", _jsx(InlineCode, {\n          children: \"config\"\n        }), \" when they add your\\ncomponent to the pipeline and customize its appearance â€“ for example, the\\n\", _jsx(InlineCode, {\n          children: \"snek_style\"\n        }), \".\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"config.cfg (excerpt)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-diff\",\n            lang: \"diff\",\n            children: \"[components.snek]\\nfactory = \\\"snek\\\"\\n+ snek_style = \\\"basic\\\"\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"SNEKS = {\\\"basic\\\": snek, \\\"cute\\\": cute_snek}  # collection of sneks\\n\\n@Language.factory(\\\"snek\\\", default_config={\\\"snek_style\\\": \\\"basic\\\"})\\nclass SnekFactory:\\n    def __init__(self, nlp: Language, name: str, snek_style: str):\\n        self.nlp = nlp\\n        self.snek_style = snek_style\\n        self.snek = SNEKS[self.snek_style]\\n\\n    def __call__(self, doc):\\n        print(self.snek)\\n        return doc\\n\"\n        })\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          title: \"setup.py\",\n          children: \"entry_points={\\n-   \\\"spacy_factories\\\": [\\\"snek = snek:snek_component\\\"]\\n+   \\\"spacy_factories\\\": [\\\"snek = snek:SnekFactory\\\"]\\n}\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"The factory can also implement other pipeline component methods like \", _jsx(InlineCode, {\n          children: \"to_disk\"\n        }), \"\\nand \", _jsx(InlineCode, {\n          children: \"from_disk\"\n        }), \" for serialization, or even \", _jsx(InlineCode, {\n          children: \"update\"\n        }), \" to make the component\\ntrainable. If a component exposes a \", _jsx(InlineCode, {\n          children: \"from_disk\"\n        }), \" method and is included in a\\npipeline, spaCy will call it on load. This lets you ship custom data with your\\npipeline package. When you save out a pipeline using \", _jsx(InlineCode, {\n          children: \"nlp.to_disk\"\n        }), \" and the\\ncomponent exposes a \", _jsx(InlineCode, {\n          children: \"to_disk\"\n        }), \" method, it will be called with the disk path.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"from spacy.util import ensure_path\\n\\ndef to_disk(self, path, exclude=tuple()):\\n    path = ensure_path(path)\\n    if not path.exists():\\n        path.mkdir()\\n    snek_path = path / \\\"snek.txt\\\"\\n    with snek_path.open(\\\"w\\\", encoding=\\\"utf8\\\") as snek_file:\\n        snek_file.write(self.snek)\\n\\ndef from_disk(self, path, exclude=tuple()):\\n    snek_path = path / \\\"snek.txt\\\"\\n    with snek_path.open(\\\"r\\\", encoding=\\\"utf8\\\") as snek_file:\\n        self.snek = snek_file.read()\\n    return self\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"The above example will serialize the current snake in a \", _jsx(InlineCode, {\n          children: \"snek.txt\"\n        }), \" in the data\\ndirectory. When a pipeline using the \", _jsx(InlineCode, {\n          children: \"snek\"\n        }), \" component is loaded, it will open\\nthe \", _jsx(InlineCode, {\n          children: \"snek.txt\"\n        }), \" and make it available to the component.\"]\n      }), _jsx(_components.h3, {\n        id: \"entry-points-languages\",\n        children: \"Custom language classes via entry points \"\n      }), _jsxs(_components.p, {\n        children: [\"To stay with the theme of the previous example and\\n\", _jsx(_components.a, {\n          href: \"https://amir.rachum.com/blog/2017/07/28/python-entry-points/\",\n          children: \"this blog post on entry points\"\n        }), \",\\nletâ€™s imagine you wanted to implement your own \", _jsx(InlineCode, {\n          children: \"SnekLanguage\"\n        }), \" class for your\\ncustom pipeline â€“Â but you donâ€™t necessarily want to modify spaCyâ€™s code to add a\\nlanguage. In your package, you could then implement the following\\n\", _jsx(_components.a, {\n          href: \"/usage/linguistic-features#language-subclass\",\n          children: \"custom language subclass\"\n        }), \":\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"snek.py\",\n          children: \"from spacy.language import Language\\n\\nclass SnekDefaults(Language.Defaults):\\n    stop_words = set([\\\"sss\\\", \\\"hiss\\\"])\\n\\nclass SnekLanguage(Language):\\n    lang = \\\"snk\\\"\\n    Defaults = SnekDefaults\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Alongside the \", _jsx(InlineCode, {\n          children: \"spacy_factories\"\n        }), \", thereâ€™s also an entry point option for\\n\", _jsx(InlineCode, {\n          children: \"spacy_languages\"\n        }), \", which maps language codes to language-specific \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \"\\nsubclasses:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          title: \"setup.py\",\n          children: \"from setuptools import setup\\n\\nsetup(\\n    name=\\\"snek\\\",\\n    entry_points={\\n        \\\"spacy_factories\\\": [\\\"snek = snek:SnekFactory\\\"],\\n+       \\\"spacy_languages\\\": [\\\"snk = snek:SnekLanguage\\\"]\\n    }\\n)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"In spaCy, you can then load the custom \", _jsx(InlineCode, {\n          children: \"snk\"\n        }), \" language and it will be resolved to\\n\", _jsx(InlineCode, {\n          children: \"SnekLanguage\"\n        }), \" via the custom entry point. This is especially relevant for\\npipeline packages you \", _jsx(_components.a, {\n          href: \"/usage/training\",\n          children: \"train\"\n        }), \", which could then specify\\n\", _jsx(InlineCode, {\n          children: \"lang = snk\"\n        }), \" in their \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" without spaCy raising an error because the\\nlanguage is not available in the core library.\"]\n      }), _jsx(_components.h3, {\n        id: \"entry-points-displacy\",\n        version: \"2.2\",\n        children: \"Custom displaCy colors via entry points \"\n      }), _jsxs(_components.p, {\n        children: [\"If youâ€™re training a named entity recognition model for a custom domain, you may\\nend up training different labels that donâ€™t have pre-defined colors in the\\n\", _jsxs(_components.a, {\n          href: \"/usage/visualizers#ent\",\n          children: [_jsx(InlineCode, {\n            children: \"displacy\"\n          }), \" visualizer\"]\n        }), \". The \", _jsx(InlineCode, {\n          children: \"spacy_displacy_colors\"\n        }), \"\\nentry point lets you define a dictionary of entity labels mapped to their color\\nvalues. Itâ€™s added to the pre-defined colors and can also overwrite existing\\nvalues.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"Domain-specific NER labels\"\n        }), \"\\n\", _jsxs(_components.p, {\n          children: [\"Good examples of pipelines with domain-specific label schemes are\\n\", _jsx(_components.a, {\n            href: \"/universe/project/scispacy\",\n            children: \"scispaCy\"\n          }), \" and\\n\", _jsx(_components.a, {\n            href: \"/universe/project/blackstone\",\n            children: \"Blackstone\"\n          }), \".\"]\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          title: \"snek.py\",\n          children: \"displacy_colors = {\\\"SNEK\\\": \\\"#3dff74\\\", \\\"HUMAN\\\": \\\"#cfc5ff\\\"}\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"Given the above colors, the entry point can be defined as follows. Entry points\\nneed to have a name, so we use the key \", _jsx(InlineCode, {\n          children: \"colors\"\n        }), \". However, the name doesnâ€™t\\nmatter and whatever is defined in the entry point group will be used.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-diff\",\n          lang: \"diff\",\n          title: \"setup.py\",\n          children: \"from setuptools import setup\\n\\nsetup(\\n    name=\\\"snek\\\",\\n    entry_points={\\n+       \\\"spacy_displacy_colors\\\": [\\\"colors = snek:displacy_colors\\\"]\\n    }\\n)\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"After installing the package, the custom colors will be used when visualizing\\ntext with \", _jsx(InlineCode, {\n          children: \"displacy\"\n        }), \". Whenever the label \", _jsx(InlineCode, {\n          children: \"SNEK\"\n        }), \" is assigned, it will be\\ndisplayed in \", _jsx(InlineCode, {\n          children: \"#3dff74\"\n        }), \".\"]\n      }), _jsx(Iframe, {\n        title: \"displaCy visualization of entities\",\n        src: \"/images/displacy-ent-snek.html\",\n        height: 100\n      })]\n    }), \"\\n\", _jsxs(_components.section, {\n      id: \"section-models\",\n      children: [_jsx(_components.h2, {\n        id: \"models\",\n        children: \"Saving, loading and distributing trained pipelines \"\n      }), _jsxs(_components.p, {\n        children: [\"After training your pipeline, youâ€™ll usually want to save its state, and load it\\nback later. You can do this with the \", _jsx(_components.a, {\n          href: \"/api/language#to_disk\",\n          children: _jsx(InlineCode, {\n            children: \"Language.to_disk\"\n          })\n        }), \"\\nmethod:\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"nlp.to_disk(\\\"./en_example_pipeline\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"The directory will be created if it doesnâ€™t exist, and the whole pipeline data,\\nmeta and configuration will be written out. To make the pipeline more convenient\\nto deploy, we recommend wrapping it as a \", _jsx(_components.a, {\n          href: \"/api/cli#package\",\n          children: \"Python package\"\n        }), \".\"]\n      }), _jsxs(Accordion, {\n        title: \"Whatâ€™s the difference between the config.cfg and meta.json?\",\n        spaced: true,\n        id: \"models-meta-vs-config\",\n        spaced: true,\n        children: [_jsxs(_components.p, {\n          children: [\"When you save a pipeline in spaCy v3.0+, two files will be exported: a\\n\", _jsx(_components.a, {\n            href: \"/api/data-formats#config\",\n            children: _jsx(InlineCode, {\n              children: \"config.cfg\"\n            })\n          }), \" based on\\n\", _jsx(_components.a, {\n            href: \"/api/language#config\",\n            children: _jsx(InlineCode, {\n              children: \"nlp.config\"\n            })\n          }), \" and a \", _jsx(_components.a, {\n            href: \"/api/data-formats#meta\",\n            children: _jsx(InlineCode, {\n              children: \"meta.json\"\n            })\n          }), \"\\nbased on \", _jsx(_components.a, {\n            href: \"/api/language#meta\",\n            children: _jsx(InlineCode, {\n              children: \"nlp.meta\"\n            })\n          }), \".\"]\n        }), _jsxs(_components.ul, {\n          children: [\"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"config\"\n            }), \": Configuration used to create the current \", _jsx(InlineCode, {\n              children: \"nlp\"\n            }), \" object, its\\npipeline components and models, as well as training settings and\\nhyperparameters. Can include references to registered functions like\\n\", _jsx(_components.a, {\n              href: \"/usage/processing-pipelines#custom-components\",\n              children: \"pipeline components\"\n            }), \" or\\n\", _jsx(_components.a, {\n              href: \"/api/architectures\",\n              children: \"model architectures\"\n            }), \". Given a config, spaCy is able\\nreconstruct the whole tree of objects and the \", _jsx(InlineCode, {\n              children: \"nlp\"\n            }), \" object. An exported config\\ncan also be used to \", _jsx(_components.a, {\n              href: \"/usage/training#config\",\n              children: \"train a pipeline\"\n            }), \" with the same\\nsettings.\"]\n          }), \"\\n\", _jsxs(_components.li, {\n            children: [_jsx(_components.strong, {\n              children: \"meta\"\n            }), \": Meta information about the pipeline and the Python package, such as\\nthe author information, license, version, data sources and label scheme. This\\nis mostly used for documentation purposes and for packaging pipelines. It has\\nno impact on the functionality of the \", _jsx(InlineCode, {\n              children: \"nlp\"\n            }), \" object.\"]\n          }), \"\\n\"]\n        })]\n      }), _jsx(Project, {\n        id: \"pipelines/tagger_parser_ud\",\n        children: _jsxs(_components.p, {\n          children: [\"The easiest way to get started with an end-to-end workflow is to clone a\\n\", _jsx(_components.a, {\n            href: \"/usage/projects\",\n            children: \"project template\"\n          }), \" and run it â€“Â for example, this template that\\nlets you train a \", _jsx(_components.strong, {\n            children: \"part-of-speech tagger\"\n          }), \" and \", _jsx(_components.strong, {\n            children: \"dependency parser\"\n          }), \" on a\\nUniversal Dependencies treebank and generates an installable Python package.\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"models-generating\",\n        children: \"Generating a pipeline package \"\n      }), _jsx(Infobox, {\n        title: \"Important note\",\n        variant: \"warning\",\n        children: _jsxs(_components.p, {\n          children: [\"Pipeline packages are typically \", _jsx(_components.strong, {\n            children: \"not suitable\"\n          }), \" for the public\\n\", _jsx(_components.a, {\n            href: \"https://pypi.python.org\",\n            children: \"pypi.python.org\"\n          }), \" directory, which is not designed for\\nbinary data and files over 50 MB. However, if your company is running an\\n\", _jsx(_components.strong, {\n            children: \"internal installation\"\n          }), \" of PyPi, publishing your pipeline packages on there\\ncan be a convenient way to share them with your team.\"]\n        })\n      }), _jsxs(_components.p, {\n        children: [\"spaCy comes with a handy CLI command that will create all required files, and\\nwalk you through generating the meta data. You can also create the\\n\", _jsx(_components.a, {\n          href: \"/api/data-formats#meta\",\n          children: _jsx(InlineCode, {\n            children: \"meta.json\"\n          })\n        }), \" manually and place it in the data\\ndirectory, or supply a path to it using the \", _jsx(InlineCode, {\n          children: \"--meta\"\n        }), \" flag. For more info on\\nthis, see the \", _jsx(_components.a, {\n          href: \"/api/cli#package\",\n          children: _jsx(InlineCode, {\n            children: \"package\"\n          })\n        }), \" docs.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"meta.json (example)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-json\",\n            lang: \"json\",\n            children: \"{\\n  \\\"name\\\": \\\"example_pipeline\\\",\\n  \\\"lang\\\": \\\"en\\\",\\n  \\\"version\\\": \\\"1.0.0\\\",\\n  \\\"spacy_version\\\": \\\"\u003e=2.0.0,\u003c3.0.0\\\",\\n  \\\"description\\\": \\\"Example pipeline for spaCy\\\",\\n  \\\"author\\\": \\\"You\\\",\\n  \\\"email\\\": \\\"you@example.com\\\",\\n  \\\"license\\\": \\\"CC BY-SA 3.0\\\"\\n}\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-bash\",\n          lang: \"bash\",\n          children: \"$ python -m spacy package ./en_example_pipeline ./packages\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"This command will create a pipeline package directory and will run\\n\", _jsx(InlineCode, {\n          children: \"python setup.py sdist\"\n        }), \" in that directory to create a binary \", _jsx(InlineCode, {\n          children: \".whl\"\n        }), \" file or\\n\", _jsx(InlineCode, {\n          children: \".tar.gz\"\n        }), \" archive of your package that can be installed using \", _jsx(InlineCode, {\n          children: \"pip install\"\n        }), \".\\nInstalling the binary wheel is usually more efficient.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-yaml\",\n          lang: \"yaml\",\n          title: \"Directory structure\",\n          children: \"â””â”€â”€ /\\n    â”œâ”€â”€ MANIFEST.in                           # to include meta.json\\n    â”œâ”€â”€ meta.json                             # pipeline meta data\\n    â”œâ”€â”€ setup.py                              # setup file for pip installation\\n    â”œâ”€â”€ en_example_pipeline                   # pipeline directory\\n    â”‚    â”œâ”€â”€ __init__.py                      # init for pip installation\\n    â”‚    â””â”€â”€ en_example_pipeline-1.0.0        # pipeline data\\n    â”‚        â”œâ”€â”€ config.cfg                   # pipeline config\\n    â”‚        â”œâ”€â”€ meta.json                    # pipeline meta\\n    â”‚        â””â”€â”€ ...                          # directories with component data\\n    â””â”€â”€ dist\\n        â””â”€â”€ en_example_pipeline-1.0.0.tar.gz  # installable package\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"You can also find templates for all files in the\\n\", _jsxs(_components.a, {\n          href: \"https://github.com/explosion/spacy/tree/master/spacy/cli/package.py\",\n          children: [_jsx(InlineCode, {\n            children: \"cli/package.py\"\n          }), \" source\"]\n        }), \".\\nIf youâ€™re creating the package manually, keep in mind that the directories need\\nto be named according to the naming conventions of \", _jsx(InlineCode, {\n          children: \"lang_name\"\n        }), \" and\\n\", _jsx(InlineCode, {\n          children: \"lang_name-version\"\n        }), \".\"]\n      }), _jsx(_components.h3, {\n        id: \"models-custom\",\n        children: \"Including custom functions and components \"\n      }), _jsxs(_components.p, {\n        children: [\"If your pipeline includes\\n\", _jsx(_components.a, {\n          href: \"/usage/processing-pipelines#custom-components\",\n          children: \"custom components\"\n        }), \", model\\narchitectures or other \", _jsx(_components.a, {\n          href: \"/usage/training#custom-code\",\n          children: \"code\"\n        }), \", those functions need\\nto be registered \", _jsx(_components.strong, {\n          children: \"before\"\n        }), \" your pipeline is loaded. Otherwise, spaCy wonâ€™t know\\nhow to create the objects referenced in the config. If youâ€™re loading your own\\npipeline in Python, you can make custom components available just by importing\\nthe code that defines them before calling\\n\", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.load\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.load\"\n          })\n        }), \". This is also how the \", _jsx(InlineCode, {\n          children: \"--code\"\n        }), \"\\nargument to CLI commands works.\"]\n      }), _jsxs(_components.p, {\n        children: [\"With the \", _jsx(_components.a, {\n          href: \"/api/cli#package\",\n          children: _jsx(InlineCode, {\n            children: \"spacy package\"\n          })\n        }), \" command, you can provide one or\\nmore paths to Python files containing custom registered functions using the\\n\", _jsx(InlineCode, {\n          children: \"--code\"\n        }), \" argument.\"]\n      }), _jsxs(_components.blockquote, {\n        children: [\"\\n\", _jsx(_components.h4, {\n          children: \"__init__.py (excerpt)\"\n        }), \"\\n\", _jsx(_components.pre, {\n          children: _jsx(_components.code, {\n            className: \"language-python\",\n            lang: \"python\",\n            children: \"from . import functions\\n\\ndef load(**overrides):\\n   ...\\n\"\n          })\n        }), \"\\n\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-bash\",\n          lang: \"bash\",\n          children: \"$ python -m spacy package ./en_example_pipeline ./packages --code functions.py\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"The Python files will be copied over into the root of the package, and the\\npackageâ€™s \", _jsx(InlineCode, {\n          children: \"__init__.py\"\n        }), \" will import them as modules. This ensures that functions\\nare registered when the pipeline is imported, e.g. when you call \", _jsx(InlineCode, {\n          children: \"spacy.load\"\n        }), \". A\\nsimple import is all thatâ€™s needed to make registered functions available.\"]\n      }), _jsxs(_components.p, {\n        children: [\"Make sure to include \", _jsx(_components.strong, {\n          children: \"all Python files\"\n        }), \" that are referenced in your custom\\ncode, including modules imported by others. If your custom code depends on\\n\", _jsx(_components.strong, {\n          children: \"external packages\"\n        }), \", make sure theyâ€™re listed in the list of \", _jsx(InlineCode, {\n          children: \"\\\"requirements\\\"\"\n        }), \"\\nin your \", _jsx(_components.a, {\n          href: \"/api/data-formats#meta\",\n          children: _jsx(InlineCode, {\n            children: \"meta.json\"\n          })\n        }), \". For the majority of use cases,\\nregistered functions should provide you with all customizations you need, from\\ncustom components to custom model architectures and lifecycle hooks. However, if\\nyou do want to customize the setup in more detail, you can edit the packageâ€™s\\n\", _jsx(InlineCode, {\n          children: \"__init__.py\"\n        }), \" and the packageâ€™s \", _jsx(InlineCode, {\n          children: \"load\"\n        }), \" function thatâ€™s called by\\n\", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.load\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.load\"\n          })\n        }), \".\"]\n      }), _jsx(Infobox, {\n        variant: \"warning\",\n        title: \"Important note on making manual edits\",\n        children: _jsxs(_components.p, {\n          children: [\"While itâ€™s no problem to edit the package code or meta information, avoid making\\nedits to the \", _jsx(InlineCode, {\n            children: \"config.cfg\"\n          }), \" \", _jsx(_components.strong, {\n            children: \"after\"\n          }), \" training, as this can easily lead to data\\nincompatibility. For instance, changing an architecture or hyperparameter can\\nmean that the trained weights are now incompatible. If you want to make\\nadjustments, you can do so before training. Otherwise, you should always trust\\nspaCy to export the current state of its \", _jsx(InlineCode, {\n            children: \"nlp\"\n          }), \" objects via\\n\", _jsx(_components.a, {\n            href: \"/api/language#config\",\n            children: _jsx(InlineCode, {\n              children: \"nlp.config\"\n            })\n          }), \".\"]\n        })\n      }), _jsx(_components.h3, {\n        id: \"loading\",\n        children: \"Loading a custom pipeline package \"\n      }), _jsxs(_components.p, {\n        children: [\"To load a pipeline from a data directory, you can use\\n\", _jsx(_components.a, {\n          href: \"/api/top-level#spacy.load\",\n          children: _jsx(InlineCode, {\n            children: \"spacy.load()\"\n          })\n        }), \" with the local path. This will look\\nfor a \", _jsx(InlineCode, {\n          children: \"config.cfg\"\n        }), \" in the directory and use the \", _jsx(InlineCode, {\n          children: \"lang\"\n        }), \" and \", _jsx(InlineCode, {\n          children: \"pipeline\"\n        }), \" settings\\nto initialize a \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \" class with a processing pipeline and load in the\\nmodel data.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"nlp = spacy.load(\\\"/path/to/pipeline\\\")\\n\"\n        })\n      }), _jsxs(_components.p, {\n        children: [\"If you want to \", _jsx(_components.strong, {\n          children: \"load only the binary data\"\n        }), \", youâ€™ll have to create a \", _jsx(InlineCode, {\n          children: \"Language\"\n        }), \"\\nclass and call \", _jsx(_components.a, {\n          href: \"/api/language#from_disk\",\n          children: _jsx(InlineCode, {\n            children: \"from_disk\"\n          })\n        }), \" instead.\"]\n      }), _jsx(_components.pre, {\n        children: _jsx(_components.code, {\n          className: \"language-python\",\n          lang: \"python\",\n          children: \"nlp = spacy.blank(\\\"en\\\").from_disk(\\\"/path/to/data\\\")\\n\"\n        })\n      })]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{"title":"Saving and Loading","menu":[["Basics","basics"],["Serializing Docs","docs"],["Serialization Methods","serialization-methods"],["Entry Points","entry-points"],["Trained Pipelines","models"]]},"scope":{}},"sectionTitle":"Usage Documentation","theme":"blue","section":"usage","apiDetails":{"stringName":null,"baseClass":null,"trainable":null},"isIndex":false,"next":{"slug":"/usage/visualizers","title":"Visualizers"}},"__N_SSG":true},"page":"/[...listPathPage]","query":{"listPathPage":["usage","saving-loading"]},"buildId":"Ugre-usgT1EZhnSeYcBR9","isFallback":false,"dynamicIds":[728],"gsp":true,"scriptLoader":[]}</script></body></html>